name: SWE-Bench Evaluation

on:
  schedule:
    - cron: '0 1 * * *'  # Run daily at 1 AM UTC
  workflow_dispatch:
    inputs:
      reason:
        description: 'Reason for manual trigger'
        required: true
        default: ''

jobs:
  run-evaluation:
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'
    strategy:
      matrix:
        python-version: ['3.12']
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Install poetry via pipx
      run: pipx install poetry

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'poetry'

    - name: Install Python dependencies using Poetry
      run: poetry install

    - name: Run SWE-Bench evaluation
      env:
        ALLHANDS_API_KEY: ${{ secrets.ALLHANDS_API_KEY }}
        RUNTIME: remote
        SANDBOX_REMOTE_RUNTIME_API_URL: ${{ secrets.SANDBOX_REMOTE_RUNTIME_API_URL }}
        EVAL_DOCKER_IMAGE_PREFIX: ${{ secrets.EVAL_DOCKER_IMAGE_PREFIX }}
      run: |
        poetry run ./evaluation/swe_bench/scripts/run_infer.sh llm.eval HEAD CodeActAgent 300 30 16 "princeton-nlp/SWE-bench_Lite" test

    - name: Clean up remote runtime
      if: always()
      env:
        ALLHANDS_API_KEY: ${{ secrets.ALLHANDS_API_KEY }}
      run: |
        poetry run ./evaluation/swe_bench/scripts/cleanup_remote_runtime.sh

    - name: Authenticate to Google Cloud
      uses: 'google-github-actions/auth@v2'
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}

    - name: Upload evaluation results to Google Cloud Storage
      uses: 'google-github-actions/upload-cloud-storage@v2'
      with:
        path: 'evaluation/evaluation_outputs'
        destination: 'openhands-oss-eval-results/${{ github.repository_owner }}__${{ github.event.repository.name }}/${{ github.run_id }}/${{ github.sha }}'

    - name: Upload evaluation results as artifact
      uses: actions/upload-artifact@v2
      with:
        name: swe-bench-evaluation-results
        path: evaluation/evaluation_outputs/output.jsonl
