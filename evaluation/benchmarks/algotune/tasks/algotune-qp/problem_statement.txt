Apart from the default Python packages, you have access to the following additional packages:
- cryptography
- cvxpy
- cython
- dace
- dask
- diffrax
- ecos
- faiss-cpu
- hdbscan
- highspy
- jax
- networkx
- numba
- numpy
- ortools
- pandas
- pot
- psutil
- pulp
- pyomo
- python-sat
- pythran
- scikit-learn
- scipy
- sympy
- torch

Your objective is to define a class named `Solver` in `/workspace/solver.py` with a method:
```python
class Solver:
    def solve(self, problem, **kwargs) -> Any:
        # Your implementation goes here.
        ...
```

IMPORTANT: Compilation time of your init function will not count towards your function's runtime.

This `solve` function will be the entrypoint called by the evaluation harness. Strive to align your class and method implementation as closely as possible with the desired performance criteria.
For each instance, your function can run for at most 10x the reference runtime for that instance. Strive to have your implementation run as fast as possible, while returning the same output as the reference function (for the same given input). Be creative and optimize your approach!

**GOALS:**
Your primary objective is to optimize the `solve` function to run as as fast as possible, while returning the optimal solution.
You will receive better scores the quicker your solution runs, and you will be penalized for exceeding the time limit or returning non-optimal solutions.

Below you find the description of the task you will have to solve. Read it carefully and understand what the problem is and what your solver should do.

**TASK DESCRIPTION:**

QP Task:

Solve this convex quadratic optimization problem in standard form:

    minimize (1/2) x^T P x + q^T x
  subject to Gx <= h
             Ax == b

The matrix P is an (n x n)-dimensional positive semi-definite
for the quadratic term on the cost,
q is an n-dimensional real-valued vector for the linear term in the cost,
G is an (m x n)-dimensional real-valued matrix for the inequality constraints,
h is an m-dimensional real-valued vector for the inequality constraint,
A is a (p x n)-dimensional real-valued matrix for the equality constraint, and
b is a p-dimensional real-valued vector for the equality constraint.

Given input parameters (P, q, G, h, A, b), compute and return
the n-dimensional solution vector.

Input: A dictionary with keys:
  - "Q": An array representing the matrix Q.
  - "q": A list of n numbers representing the vector q.
  - "G": An array representing the matrix G.
  - "h": A list of m numbers representing the vector h.
  - "A": An array representing the matrix A.
  - "b": A list of p numbers representing the vector b.

Example input:
{
  "Q": [[1, 0], [0, 1]],
  "q": [0, 0],
  "G": [[-1, 0], [0, -1]],
  "h": [0, 0],
  "A": [[1, 1]],
  "b": [1]
}

Output: A dictionary with keys:
  - "solution": A list of n numbers representing the optimal (primal) solution.

Example output:
{
    "solution": [0.5, 0.5]
}

Category: convex_optimization

Below is the reference implementation. Your function should run much quicker.

```python
def solve(self, problem: dict[str, Any]) -> dict[str, Any]:
        P = np.asarray(problem["P"], float)
        q = np.asarray(problem["q"], float)
        G = np.asarray(problem["G"], float)
        h = np.asarray(problem["h"], float)
        A = np.asarray(problem["A"], float)
        b = np.asarray(problem["b"], float)
        n = P.shape[0]

        P = (P + P.T) / 2
        x = cp.Variable(n)
        objective = 0.5 * cp.quad_form(x, cp.psd_wrap(P)) + q @ x
        constraints = [G @ x <= h, A @ x == b]
        prob = cp.Problem(cp.Minimize(objective), constraints)
        optimal_value = prob.solve(solver=cp.OSQP, eps_abs=1e-8, eps_rel=1e-8)

        if prob.status not in (cp.OPTIMAL, cp.OPTIMAL_INACCURATE):
            raise ValueError(f"Solver failed (status = {prob.status})")

        return {"solution": x.value.tolist(), "objective": float(optimal_value)}
```

This function will be used to check if your solution is valid for a given problem. If it returns False, it means the solution is invalid:

```python
def is_solution(
        self, problem: dict[str, Any], solution: dict[str, list], atol: float = 1e-6
    ) -> bool:
        x = np.asarray(solution.get("solution", []), float)
        if x.ndim != 1:
            return False

        P = np.asarray(problem["P"], float)
        q = np.asarray(problem["q"], float)
        G = np.asarray(problem["G"], float)
        h = np.asarray(problem["h"], float)
        A = np.asarray(problem["A"], float)
        b = np.asarray(problem["b"], float)

        if x.shape[0] != P.shape[0]:
            return False

        # Feasibility
        if (G @ x - h > atol).any():
            return False
        if not np.allclose(A @ x, b, atol=atol):
            return False

        # Optimality: compare objective value to the true optimum
        true_obj = self.solve(problem)["objective"]
        candidate_obj = 0.5 * x @ P @ x + q @ x
        return bool(candidate_obj <= true_obj + 1e-4 * (1 + abs(true_obj)))
```

You can use python test_outputs.py to check the current speedup of reference solver.