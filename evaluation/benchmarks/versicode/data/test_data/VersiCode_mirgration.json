{
    "count": 800,
    "data": [
        {
            "dependency": "streamlit",
            "old_version": "==0.59.0",
            "new_version": "==1.1.0",
            "old_time": "2020-05-05",
            "new_time": "2021-10-21",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_31763"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.53.0",
            "new_version": "==0.88.0",
            "old_time": "2020-01-14",
            "new_time": "2021-09-02",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35351"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.44.0",
            "new_version": "==1.27.0",
            "old_time": "2019-07-27",
            "new_time": "2023-09-21",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30577"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.1.2",
            "old_time": "2021-01-21",
            "new_time": "2021-07-30",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a pipe command to run a Python script called \"my_script.py\".",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_9943"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.75.0",
            "new_version": "==1.3.0",
            "old_time": "2021-01-21",
            "new_time": "2021-12-16",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33039"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.35.0",
            "new_version": "==1.30.0",
            "old_time": "2019-04-27",
            "new_time": "2024-01-11",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_34000"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==0.9.0",
            "new_version": "==1.4.9",
            "old_time": "2020-08-20",
            "new_time": "2021-09-30",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21278"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.22.0",
            "new_version": "==1.1.0",
            "old_time": "2017-12-30",
            "new_time": "2020-07-28",
            "description": "The code creates an index object based on the input provided, which can be a list of single values, tuples, or lists.",
            "old_code": "_ensure_index(['a', 'b'])\nIndex(['a', 'b'], dtype='object')\n\n_ensure_index([('a', 'a'),  ('b', 'c')])\nIndex([('a', 'a'), ('b', 'c')], dtype='object')\n\n_ensure_index([['a', 'a'], ['b', 'c']])\nMultiIndex(levels=[['a'], ['b', 'c']],\n           labels=[[0, 0], [0, 1]])",
            "new_code": "ensure_index(['a', 'b'])\nIndex(['a', 'b'], dtype='object')\n\nensure_index([('a', 'a'),  ('b', 'c')])\nIndex([('a', 'a'), ('b', 'c')], dtype='object')\n\nensure_index([['a', 'a'], ['b', 'c']])\nMultiIndex(levels=[['a'], ['b', 'c']],\n           labels=[[0, 0], [0, 1]])",
            "old_name": "_ensure_index",
            "new_name": "ensure_index",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_15449"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.81.0",
            "new_version": "==1.4.0",
            "old_time": "2021-04-29",
            "new_time": "2022-01-11",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_43496"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.0",
            "new_version": "==1.5.1",
            "old_time": "2020-01-29",
            "new_time": "2022-10-18",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18187"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.37.0",
            "new_version": "==1.24.0",
            "old_time": "2019-05-11",
            "new_time": "2023-06-27",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30182"
        },
        {
            "dependency": "pyrsistent",
            "old_version": "==0.7.0",
            "new_version": "==0.11.1",
            "old_time": "2015-01-04",
            "new_time": "2015-08-24",
            "description": "The code defines a class named Point with attributes x, y, and id_. It creates an instance p of Point with x=1, y=2. It then updates the x attribute of p to 3. Another instance p is created with x=1, y=2, and id_=17. The id_ attribute of p is then updated to 18.",
            "old_code": "Point = pclass('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint = pclass('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\np.set(id_=18)",
            "new_code": "Point = immutable('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint = immutable('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\np.set(id_=18)",
            "old_name": "pclass",
            "new_name": "immutable",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20444"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.20.0",
            "new_version": "==1.0.0",
            "old_time": "2017-05-05",
            "new_time": "2020-01-29",
            "description": "The code creates a DataFrame using pandas with values and column names specified. It then creates an index object and retrieves its values. Next, it creates a MultiIndex object with two levels of indexes and retrieves its values. Finally, it checks the number of dimensions of the values in the MultiIndex object.",
            "old_code": "df = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n                   index=['a', 'b', 'c'], columns=['A', 'B', 'C'])\ndf.index.get_values()\nidx = pd.Index(['1', '2', '3'])\nidx.get_values()\nmidx = pd.MultiIndex.from_arrays([[1, 2, 3], ['a', 'b', 'c']],\n                                 names=('number', 'letter'))\nmidx.get_values()\nmidx.get_values().ndim",
            "new_code": "df = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n                   index=['a', 'b', 'c'], columns=['A', 'B', 'C'])\ndf.index._internal_get_values()\nidx = pd.Index(['1', '2', '3'])\nidx._internal_get_values()\nmidx = pd.MultiIndex.from_arrays([[1, 2, 3], ['a', 'b', 'c']],\n                                  names=('number', 'letter'))\nmidx._internal_get_values()\nmidx._internal_get_values().ndim",
            "old_name": "get_values",
            "new_name": "_internal_get_values",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_15766"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==0.10.0",
            "new_version": "==1.3.0",
            "old_time": "2020-10-07",
            "new_time": "2021-05-06",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21304"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.30.0",
            "new_version": "==0.88.0",
            "old_time": "2019-03-15",
            "new_time": "2021-09-02",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33671"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.1.0",
            "new_version": "==2.0.2",
            "old_time": "2017-04-21",
            "new_time": "2020-05-12",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45013"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.81.0",
            "new_version": "==1.29.0",
            "old_time": "2021-04-29",
            "new_time": "2023-11-30",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_43537"
        },
        {
            "dependency": "ray",
            "old_version": "==1.10.0",
            "new_version": "==2.1.0",
            "old_time": "2022-01-24",
            "new_time": "2022-11-02",
            "description": "The code generates a dataset with 1000 elements and then maps each element to a new dictionary with a key \"v2\" whose value is twice the original element's value. Finally, it displays the resulting dataset.",
            "old_code": "ds = ray.data.range_arrow(1000)\nds.map(lambda r: {\"v2\": r[\"value\"] * 2}).show()",
            "new_code": "import ray\nds = ray.data.range_table(1000)\nds.map(lambda r: {\"v2\": r[\"value\"] * 2}).show()",
            "old_name": "range_arrow",
            "new_name": "range_table",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29489"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.77.0",
            "new_version": "==1.17.0",
            "old_time": "2021-02-23",
            "new_time": "2023-01-12",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37509"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.15.0",
            "new_version": "==2.13.0",
            "old_time": "2019-10-14",
            "new_time": "2023-06-28",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46371"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.78.0",
            "new_version": "==1.31.1",
            "old_time": "2021-03-04",
            "new_time": "2024-02-09",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37586"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.81.0",
            "new_version": "==1.7.0",
            "old_time": "2021-04-29",
            "new_time": "2022-03-02",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37714"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.30.0",
            "new_version": "==1.11.1",
            "old_time": "2019-03-15",
            "new_time": "2022-07-27",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33690"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.3.2",
            "old_time": "2021-01-21",
            "new_time": "2022-08-15",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a custom pipe command for data processing.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_so_parser_name(\"./abc.so\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_so_parser_name",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10134"
        },
        {
            "dependency": "streamlit",
            "old_version": "==1.18.0",
            "new_version": "==1.29.0",
            "old_time": "2023-02-09",
            "new_time": "2023-11-30",
            "description": "The code generates a scatter plot chart using Streamlit and displays it using the Arrow Vega-Lite chart. The chart visualizes random data points with three variables 'a', 'b', and 'c', where 'a' and 'b' are plotted on the x and y axes as quantitative values, and 'c' is used for both the size and color of the data points.",
            "old_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n    np.random.randn(200, 3),\n    columns=['a', 'b', 'c'])\n\nst._arrow_vega_lite_chart(df, {\n    'mark': {'type': 'circle', 'tooltip': True},\n    'encoding': {\n        'x': {'field': 'a', 'type': 'quantitative'},\n        'y': {'field': 'b', 'type': 'quantitative'},\n        'size': {'field': 'c', 'type': 'quantitative'},\n        'color': {'field': 'c', 'type': 'quantitative'},\n    },\n})",
            "new_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\nchart_data = pd.DataFrame(np.random.randn(200, 3), columns=[\"a\", \"b\", \"c\"])\n\nst.vega_lite_chart(\n    chart_data,\n    {\n        \"mark\": {\"type\": \"circle\", \"tooltip\": True},\n        \"encoding\": {\n            \"x\": {\"field\": \"a\", \"type\": \"quantitative\"},\n            \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n            \"size\": {\"field\": \"c\", \"type\": \"quantitative\"},\n            \"color\": {\"field\": \"c\", \"type\": \"quantitative\"},\n        },\n    },\n)",
            "old_name": "_arrow_vega_lite_chart",
            "new_name": "vega_lite_chart",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44627"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.21.0",
            "new_version": "==0.25.1",
            "old_time": "2017-10-27",
            "new_time": "2019-08-22",
            "description": "The code creates an index object based on the input provided, which can be a list of single values, tuples, or lists.",
            "old_code": "_ensure_index(['a', 'b'])\nIndex(['a', 'b'], dtype='object')\n\n_ensure_index([('a', 'a'),  ('b', 'c')])\nIndex([('a', 'a'), ('b', 'c')], dtype='object')\n\n_ensure_index([['a', 'a'], ['b', 'c']])\nMultiIndex(levels=[['a'], ['b', 'c']],\n           labels=[[0, 0], [0, 1]])",
            "new_code": "ensure_index(['a', 'b'])\nIndex(['a', 'b'], dtype='object')\n\nensure_index([('a', 'a'),  ('b', 'c')])\nIndex([('a', 'a'), ('b', 'c')], dtype='object')\n\nensure_index([['a', 'a'], ['b', 'c']])\nMultiIndex(levels=[['a'], ['b', 'c']],\n           labels=[[0, 0], [0, 1]])",
            "old_name": "_ensure_index",
            "new_name": "ensure_index",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_15340"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.6.0",
            "old_time": "2021-01-21",
            "new_time": "2023-12-21",
            "description": "The code creates a dataset using PaddlePaddle's fluid framework and sets a pipe command to run a Python script called \"my_script.py\" for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "old_name": "set_pipe_command",
            "new_name": "_set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3687"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==0.10.0",
            "new_version": "==1.2.4",
            "old_time": "2020-10-07",
            "new_time": "2021-03-16",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21297"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.47.0",
            "new_version": "==1.11.1",
            "old_time": "2019-09-30",
            "new_time": "2022-07-27",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30701"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.34.0",
            "new_version": "==0.88.0",
            "old_time": "2019-04-19",
            "new_time": "2021-09-02",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29996"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.75.0",
            "new_version": "==0.86.0",
            "old_time": "2021-01-21",
            "new_time": "2021-08-05",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33032"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.73.0",
            "new_version": "==1.9.1",
            "old_time": "2020-12-17",
            "new_time": "2022-05-26",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_32853"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.2.1",
            "old_time": "2021-01-21",
            "new_time": "2021-11-30",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the variables 'data' and 'label' for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "new_code": "import paddle.base as base\npaddle.enable_static()\ndataset = base.DatasetFactory().create_dataset()\ndata = paddle.static.data(name=\"data\", shape=[None, 10, 10], dtype=\"int64\")\nlabel = paddle.static.data(name=\"label\", shape=[None, 1], dtype=\"int64\", lod_level=1)\ndataset.set_use_var([data, label])",
            "old_name": "_set_use_var",
            "new_name": "set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10685"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.22.0",
            "new_version": "==2.1.0",
            "old_time": "2017-12-30",
            "new_time": "2023-08-30",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17791"
        },
        {
            "dependency": "streamlit",
            "old_version": "==1.1.0",
            "new_version": "==1.30.0",
            "old_time": "2021-10-21",
            "new_time": "2024-01-11",
            "description": "This code generates a random 10x5 DataFrame using NumPy and Pandas, and then displays it as an arrow table using Streamlit.",
            "old_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n   np.random.randn(10, 5),\n   columns=(\"col %d\" % i for i in range(5)))\n\nst._arrow_table(df)",
            "new_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.random.randn(10, 5), columns=(\"col %d\" % i for i in range(5)))\n\nst.table(df)",
            "old_name": "_arrow_table",
            "new_name": "table",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44082"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.1.0",
            "new_version": "==2.6.0",
            "old_time": "2017-04-21",
            "new_time": "2021-08-09",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45039"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.77.0",
            "new_version": "==1.0.0",
            "old_time": "2021-02-23",
            "new_time": "2021-10-05",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33134"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.83.0",
            "new_version": "==1.21.0",
            "old_time": "2021-06-21",
            "new_time": "2023-04-06",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33510"
        },
        {
            "dependency": "datasets",
            "old_version": "==2.10.0",
            "new_version": "==2.14.4",
            "old_time": "2023-02-22",
            "new_time": "2023-08-08",
            "description": "This code resolves patterns locally or by URLs for YAML files in the \"src\" directory and its subdirectories.",
            "old_code": "from datasets.data_files import resolve_patterns_locally_or_by_urls\n\nbase_path = \".\"\nresolve_patterns_locally_or_by_urls(base_path, [\"src/**/*.yaml\"])",
            "new_code": "from datasets.data_files import resolve_pattern\nbase_path = \".\"\nresolve_pattern(\"docs/**/*.py\", base_path)",
            "old_name": "resolve_patterns_locally_or_by_urls",
            "new_name": "resolve_pattern",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_673"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.68.0",
            "new_version": "==1.3.0",
            "old_time": "2020-10-08",
            "new_time": "2021-12-16",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_42522"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.7.0",
            "new_version": "==1.13.1",
            "old_time": "2018-03-29",
            "new_time": "2019-02-25",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45606"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.30.0",
            "new_version": "==0.85.0",
            "old_time": "2019-03-15",
            "new_time": "2021-07-22",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29796"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.72.0",
            "new_version": "==1.25.0",
            "old_time": "2020-12-02",
            "new_time": "2023-07-20",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37128"
        },
        {
            "dependency": "streamlit",
            "old_version": "==1.3.0",
            "new_version": "==1.28.1",
            "old_time": "2021-12-16",
            "new_time": "2023-11-02",
            "description": "This code generates a random 10x5 DataFrame using NumPy and Pandas, and then displays it as an arrow table using Streamlit.",
            "old_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n   np.random.randn(10, 5),\n   columns=(\"col %d\" % i for i in range(5)))\n\nst._arrow_table(df)",
            "new_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.random.randn(10, 5), columns=(\"col %d\" % i for i in range(5)))\n\nst.table(df)",
            "old_name": "_arrow_table",
            "new_name": "table",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44093"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.88.0",
            "new_version": "==1.28.2",
            "old_time": "2021-09-02",
            "new_time": "2023-11-13",
            "description": "This code generates a random 10x5 DataFrame using NumPy and Pandas, and then displays it as an arrow table using Streamlit.",
            "old_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n   np.random.randn(10, 5),\n   columns=(\"col %d\" % i for i in range(5)))\n\nst._arrow_table(df)",
            "new_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.random.randn(10, 5), columns=(\"col %d\" % i for i in range(5)))\n\nst.table(df)",
            "old_name": "_arrow_table",
            "new_name": "table",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44059"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.53.0",
            "new_version": "==0.88.0",
            "old_time": "2020-01-14",
            "new_time": "2021-09-02",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_31270"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.82.0",
            "new_version": "==0.87.0",
            "old_time": "2021-05-13",
            "new_time": "2021-08-23",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33425"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.49.0",
            "new_version": "==1.10.0",
            "old_time": "2019-10-23",
            "new_time": "2022-06-01",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30944"
        },
        {
            "dependency": "streamlit",
            "old_version": "==1.21.0",
            "new_version": "==1.30.0",
            "old_time": "2023-04-06",
            "new_time": "2024-01-11",
            "description": "This code generates a random 10x5 DataFrame using NumPy and Pandas, and then displays it as an arrow table using Streamlit.",
            "old_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n   np.random.randn(10, 5),\n   columns=(\"col %d\" % i for i in range(5)))\n\nst._arrow_table(df)",
            "new_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.random.randn(10, 5), columns=(\"col %d\" % i for i in range(5)))\n\nst.table(df)",
            "old_name": "_arrow_table",
            "new_name": "table",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44306"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==2.0.0",
            "new_version": "==2.6.2",
            "old_time": "2019-09-27",
            "new_time": "2021-11-03",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46546"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.32.0",
            "new_version": "==1.16.0",
            "old_time": "2019-03-29",
            "new_time": "2022-12-14",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29927"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.44.0",
            "new_version": "==0.88.0",
            "old_time": "2019-07-27",
            "new_time": "2021-09-02",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30535"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.14.0",
            "new_version": "==0.16.0",
            "old_time": "2014-05-30",
            "new_time": "2015-03-22",
            "description": "The code calculates the difference between two index objects.",
            "old_code": "index - index2\nindex.diff(index2)",
            "new_code": "index.difference(index2)",
            "old_name": "diff",
            "new_name": "difference",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_15278"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.51.0",
            "new_version": "==1.23.0",
            "old_time": "2019-12-01",
            "new_time": "2023-06-01",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35220"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.6.0",
            "old_time": "2021-01-21",
            "new_time": "2023-12-21",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4067"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==0.6.0",
            "new_version": "==2.1.1",
            "old_time": "2020-01-21",
            "new_time": "2023-11-06",
            "description": "The code registers different distributed data parallel communication hooks for a deep learning model. The hooks include fp16_compress_hook for compressing gradients, powerSGD_hook for a specific communication optimization technique, and post_localSGD_hook for another communication optimization technique. Additionally, it demonstrates combining fp16_compress_wrapper with other communication hooks for further optimization.",
            "old_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "new_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "old_name": "register_ddp_comm_hook",
            "new_name": "_register_ddp_comm_hook",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_23744"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.42.0",
            "new_version": "==1.13.0",
            "old_time": "2019-07-02",
            "new_time": "2022-09-21",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30362"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.2.2",
            "old_time": "2021-01-21",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "old_name": "set_batch_size",
            "new_name": "_set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3867"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.78.0",
            "new_version": "==1.15.1",
            "old_time": "2021-03-04",
            "new_time": "2022-11-21",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33208"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.58.0",
            "new_version": "==1.10.0",
            "old_time": "2020-04-23",
            "new_time": "2022-06-01",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35872"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.15.0",
            "new_version": "==2.8.0",
            "old_time": "2019-10-14",
            "new_time": "2022-01-31",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46356"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.40.0",
            "new_version": "==1.6.0",
            "old_time": "2019-06-11",
            "new_time": "2022-02-24",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_34129"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.77.0",
            "new_version": "==1.21.0",
            "old_time": "2021-02-23",
            "new_time": "2023-04-06",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33167"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.64.0",
            "new_version": "==1.0.0",
            "old_time": "2020-07-23",
            "new_time": "2021-10-05",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36305"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.43.0",
            "new_version": "==0.87.0",
            "old_time": "2019-07-09",
            "new_time": "2021-08-23",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30387"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.25.0",
            "new_version": "==1.4.3",
            "old_time": "2019-07-18",
            "new_time": "2022-06-23",
            "description": "The code may potentially modify lambda functions named 'sum' to avoid conflicts.",
            "old_code": "_maybe_mangle_lambdas('sum')\\n\\n_maybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "new_code": "maybe_mangle_lambdas('sum')\n\nmaybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "old_name": "_maybe_mangle_lambdas",
            "new_name": "maybe_mangle_lambdas",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17105"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.84.0",
            "new_version": "==1.29.0",
            "old_time": "2021-07-01",
            "new_time": "2023-11-30",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37975"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.67.0",
            "new_version": "==1.10.0",
            "old_time": "2020-09-17",
            "new_time": "2022-06-01",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36600"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.24.0",
            "new_version": "==1.3.4",
            "old_time": "2019-01-25",
            "new_time": "2021-10-17",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17962"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.7.0",
            "new_version": "==2.0.2",
            "old_time": "2022-08-02",
            "new_time": "2023-04-24",
            "description": "The code registers different distributed data parallel communication hooks for a deep learning model. The hooks include fp16_compress_hook for compressing gradients, powerSGD_hook for a specific communication optimization technique, and post_localSGD_hook for another communication optimization technique. Additionally, it demonstrates combining fp16_compress_wrapper with other communication hooks for further optimization.",
            "old_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "new_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "old_name": "register_ddp_comm_hook",
            "new_name": "_register_ddp_comm_hook",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_24327"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.50.0",
            "new_version": "==1.29.0",
            "old_time": "2019-11-11",
            "new_time": "2023-11-30",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35063"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.0",
            "new_version": "==1.3.6",
            "old_time": "2020-10-13",
            "new_time": "2021-06-17",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21046"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.52.0",
            "new_version": "==1.11.1",
            "old_time": "2019-12-20",
            "new_time": "2022-07-27",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35258"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.84.0",
            "new_version": "==1.15.2",
            "old_time": "2021-07-01",
            "new_time": "2022-11-30",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37955"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.5.1",
            "old_time": "2021-01-21",
            "new_time": "2023-07-25",
            "description": "The code creates a dataset using PaddlePaddle framework and sets a download command to read data from AFS (Alibaba File System).",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "old_name": "set_download_cmd",
            "new_name": "_set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5395"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.65.0",
            "new_version": "==1.17.0",
            "old_time": "2020-08-12",
            "new_time": "2023-01-12",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36389"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.49.0",
            "new_version": "==1.18.1",
            "old_time": "2019-10-23",
            "new_time": "2023-02-10",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_34991"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.82.0",
            "new_version": "==1.9.0",
            "old_time": "2021-05-13",
            "new_time": "2022-05-02",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33440"
        },
        {
            "dependency": "torch",
            "old_version": "==1.0.0",
            "new_version": "==1.8.1",
            "old_time": "2018-12-06",
            "new_time": "2021-03-24",
            "description": "This code defines a function `bar` that creates a resolution callback with a parameter of 1 and then prints the result of calling the callback with the argument \"foo\". The function `baz` sets a variable `foo` to 2 and then calls the function `bar`. Finally, the code executes the function `baz`.",
            "old_code": "def bar():\n    cb = createResolutionCallback(1)\n    print(cb(\"foo\"))\n\ndef baz():\n    foo = 2\n    bar()\n\nbaz()",
            "new_code": "def bar():\n    cb = createResolutionCallbackFromFrame(1)\n    print(cb(\"foo\"))\n\ndef baz():\n    foo = 2\n    bar()\n\nbaz()",
            "old_name": "createResolutionCallback",
            "new_name": "createResolutionCallbackFromFrame",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_49171"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.81.0",
            "new_version": "==1.6.0",
            "old_time": "2021-04-29",
            "new_time": "2022-02-24",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33338"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.49.0",
            "new_version": "==0.85.1",
            "old_time": "2019-10-23",
            "new_time": "2021-07-27",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30924"
        },
        {
            "dependency": "datasets",
            "old_version": "==1.16.0",
            "new_version": "==2.14.6",
            "old_time": "2021-11-26",
            "new_time": "2023-10-24",
            "description": "This code resolves patterns locally or by URLs for YAML files in the \"src\" directory and its subdirectories.",
            "old_code": "from datasets.data_files import resolve_patterns_locally_or_by_urls\n\nbase_path = \".\"\nresolve_patterns_locally_or_by_urls(base_path, [\"src/**/*.yaml\"])",
            "new_code": "from datasets.data_files import resolve_pattern\nbase_path = \".\"\nresolve_pattern(\"docs/**/*.py\", base_path)",
            "old_name": "resolve_patterns_locally_or_by_urls",
            "new_name": "resolve_pattern",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_351"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.22.0",
            "new_version": "==1.4.0",
            "old_time": "2017-12-30",
            "new_time": "2022-01-22",
            "description": "The code performs resampling on a pandas Series or DataFrame with a specified frequency and backfills missing values within the resampled intervals.",
            "old_code": "s = pd.Series([1, 2, 3],\n              index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01-01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').backfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').backfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n                  index=pd.date_range('20180101', periods=3,\n                                      freq='h'))\ndf\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').backfill()\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 00:30:00  NaN  3\n2018-01-01 01:00:00  NaN  3\n2018-01-01 01:30:00  6.0  5\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('15min').backfill(limit=2)\n                   a    b\n2018-01-01 00:00:00  2.0  1.0\n2018-01-01 00:15:00  NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-01 02:00:00   6.0   5.0",
            "new_code": "s = pd.Series([1, 2, 3],\n...               index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01:01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').bfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').bfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n...                   index=pd.date_range('20180101', periods=3,\n...                                       freq='h'))\ndf\n                       a    b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').bfill()\n                       a    b\n2018-01-01 00:00:00  2.0   1\n2018-01-01 00:30:00   NaN   3\n2018-01-01 01:00:00   NaN   3\n2018-01-01 01:30:00   6.0   5\n2018-01-01 02:00:00   6.0   5\n\ndf.resample('15min').bfill(limit=2)\n                       a    b\n2018-01-01 00:00:00   2.0   1.0\n2018-01-01 00:15:00   NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-02 02:00:00   6.0   5.0",
            "old_name": "backfill",
            "new_name": "bfill",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18750"
        },
        {
            "dependency": "ray",
            "old_version": "==0.6.0",
            "new_version": "==2.3.1",
            "old_time": "2018-12-01",
            "new_time": "2023-03-25",
            "description": "This code filters nodes based on the node type \"worker\" in a provider.",
            "old_code": "provider.nodes({TAG_RAY_NODE_TYPE: \"worker\"})",
            "new_code": "provider.non_terminated_nodes({TAG_RAY_NODE_TYPE: \"worker\"})\n[\"node-1\", \"node-2\"]",
            "old_name": "nodes",
            "new_name": "non_terminated_nodes",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_25360"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.22.0",
            "new_version": "==1.1.5",
            "old_time": "2017-12-30",
            "new_time": "2020-12-07",
            "description": "The code creates an index object based on the input provided, which can be a list of single values, tuples, or lists.",
            "old_code": "_ensure_index(['a', 'b'])\nIndex(['a', 'b'], dtype='object')\n\n_ensure_index([('a', 'a'),  ('b', 'c')])\nIndex([('a', 'a'), ('b', 'c')], dtype='object')\n\n_ensure_index([['a', 'a'], ['b', 'c']])\nMultiIndex(levels=[['a'], ['b', 'c']],\n           labels=[[0, 0], [0, 1]])",
            "new_code": "ensure_index(['a', 'b'])\nIndex(['a', 'b'], dtype='object')\n\nensure_index([('a', 'a'),  ('b', 'c')])\nIndex([('a', 'a'), ('b', 'c')], dtype='object')\n\nensure_index([['a', 'a'], ['b', 'c']])\nMultiIndex(levels=[['a'], ['b', 'c']],\n           labels=[[0, 0], [0, 1]])",
            "old_name": "_ensure_index",
            "new_name": "ensure_index",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_15454"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.69.0",
            "new_version": "==1.28.2",
            "old_time": "2020-10-15",
            "new_time": "2023-11-13",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_42672"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.44.0",
            "new_version": "==1.22.0",
            "old_time": "2019-07-27",
            "new_time": "2023-04-27",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_34547"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.71.0",
            "new_version": "==1.30.0",
            "old_time": "2020-11-11",
            "new_time": "2024-01-11",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_42890"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.43.0",
            "new_version": "==1.4.0",
            "old_time": "2019-07-09",
            "new_time": "2022-01-11",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30395"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==2.2.0",
            "new_version": "==2.4.4",
            "old_time": "2020-05-05",
            "new_time": "2021-10-30",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46934"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.55.0",
            "new_version": "==1.18.1",
            "old_time": "2020-02-05",
            "new_time": "2023-02-10",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35495"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.31.0",
            "new_version": "==1.15.1",
            "old_time": "2019-03-21",
            "new_time": "2022-11-21",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29876"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.2.2",
            "old_time": "2021-05-13",
            "new_time": "2022-01-18",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11307"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.68.0",
            "new_version": "==1.0.0",
            "old_time": "2020-10-08",
            "new_time": "2021-10-05",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_32448"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.1.2",
            "old_time": "2021-01-21",
            "new_time": "2021-07-30",
            "description": "The code sets up an in-memory dataset for distributed training with a sleep time of 2 seconds for sending data between nodes.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "old_name": "_set_fleet_send_sleep_seconds",
            "new_name": "set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12202"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.40.0",
            "new_version": "==1.23.1",
            "old_time": "2019-06-11",
            "new_time": "2023-06-02",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_34157"
        },
        {
            "dependency": "ray",
            "old_version": "==0.6.0",
            "new_version": "==2.5.0",
            "old_time": "2018-12-01",
            "new_time": "2023-06-06",
            "description": "This code filters nodes based on the node type \"worker\" in a provider.",
            "old_code": "provider.nodes({TAG_RAY_NODE_TYPE: \"worker\"})",
            "new_code": "provider.non_terminated_nodes({TAG_RAY_NODE_TYPE: \"worker\"})\n[\"node-1\", \"node-2\"]",
            "old_name": "nodes",
            "new_name": "non_terminated_nodes",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_25364"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.55.0",
            "new_version": "==1.13.0",
            "old_time": "2020-02-05",
            "new_time": "2022-09-21",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35486"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.1.0",
            "new_version": "==2.2.3",
            "old_time": "2017-04-21",
            "new_time": "2021-06-10",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45024"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.11.0",
            "new_version": "==2.9.3",
            "old_time": "2018-09-25",
            "new_time": "2022-11-15",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46063"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.44.0",
            "new_version": "==1.25.0",
            "old_time": "2019-07-27",
            "new_time": "2023-07-20",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_34552"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.5.0",
            "new_version": "==2.5.0",
            "old_time": "2018-01-25",
            "new_time": "2021-05-12",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45437"
        },
        {
            "dependency": "streamlit",
            "old_version": "==1.15.0",
            "new_version": "==1.28.0",
            "old_time": "2022-11-14",
            "new_time": "2023-10-25",
            "description": "The code generates a scatter plot using Altair library based on a randomly generated DataFrame with 3 columns. The scatter plot displays the values of columns 'a' and 'b' as x and y coordinates, the size and color of the circles represent the values in column 'c'. The plot is displayed using Streamlit library.",
            "old_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport altair as alt\n\ndf = pd.DataFrame(\n    np.random.randn(200, 3),\n    columns=['a', 'b', 'c'])\n\nc = alt.Chart(df).mark_circle().encode(\n    x='a', y='b', size='c', color='c', tooltip=['a', 'b', 'c'])\n\nst._arrow_altair_chart(c, use_container_width=True)",
            "new_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport altair as alt\n\nchart_data = pd.DataFrame(np.random.randn(20, 3), columns=[\"a\", \"b\", \"c\"])\n\nc = (\n   alt.Chart(chart_data)\n   .mark_circle()\n   .encode(x=\"a\", y=\"b\", size=\"c\", color=\"c\", tooltip=[\"a\", \"b\", \"c\"])\n)\n\nst.altair_chart(c, use_container_width=True)",
            "old_name": "_arrow_altair_chart",
            "new_name": "altair_chart",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44456"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.72.0",
            "new_version": "==1.1.0",
            "old_time": "2020-12-02",
            "new_time": "2021-10-21",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_32792"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.56.0",
            "new_version": "==1.5.1",
            "old_time": "2020-02-15",
            "new_time": "2022-02-09",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35584"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.0",
            "new_version": "==1.1.1",
            "old_time": "2020-01-29",
            "new_time": "2020-08-20",
            "description": "The code may potentially modify lambda functions named 'sum' to avoid conflicts.",
            "old_code": "_maybe_mangle_lambdas('sum')\\n\\n_maybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "new_code": "maybe_mangle_lambdas('sum')\n\nmaybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "old_name": "_maybe_mangle_lambdas",
            "new_name": "maybe_mangle_lambdas",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17233"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.70.0",
            "new_version": "==1.9.2",
            "old_time": "2020-10-28",
            "new_time": "2022-05-27",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_32707"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.41.0",
            "new_version": "==1.25.0",
            "old_time": "2019-06-24",
            "new_time": "2023-07-20",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30331"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.67.0",
            "new_version": "==1.18.0",
            "old_time": "2020-09-17",
            "new_time": "2023-02-09",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36614"
        },
        {
            "dependency": "streamlit",
            "old_version": "==1.1.0",
            "new_version": "==1.31.0",
            "old_time": "2021-10-21",
            "new_time": "2024-02-01",
            "description": "This code generates a random 10x5 DataFrame using NumPy and Pandas, and then displays it as an arrow table using Streamlit.",
            "old_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n   np.random.randn(10, 5),\n   columns=(\"col %d\" % i for i in range(5)))\n\nst._arrow_table(df)",
            "new_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.random.randn(10, 5), columns=(\"col %d\" % i for i in range(5)))\n\nst.table(df)",
            "old_name": "_arrow_table",
            "new_name": "table",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44083"
        },
        {
            "dependency": "datasets",
            "old_version": "==1.17.0",
            "new_version": "==2.14.1",
            "old_time": "2021-12-21",
            "new_time": "2023-07-27",
            "description": "This code resolves patterns locally or by URLs for YAML files in the \"src\" directory and its subdirectories.",
            "old_code": "from datasets.data_files import resolve_patterns_locally_or_by_urls\n\nbase_path = \".\"\nresolve_patterns_locally_or_by_urls(base_path, [\"src/**/*.yaml\"])",
            "new_code": "from datasets.data_files import resolve_pattern\nbase_path = \".\"\nresolve_pattern(\"docs/**/*.py\", base_path)",
            "old_name": "resolve_patterns_locally_or_by_urls",
            "new_name": "resolve_pattern",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_370"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.75.0",
            "new_version": "==1.24.1",
            "old_time": "2021-01-21",
            "new_time": "2023-07-07",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37407"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.56.0",
            "new_version": "==1.8.1",
            "old_time": "2020-02-15",
            "new_time": "2022-03-29",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35588"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.47.0",
            "new_version": "==1.17.0",
            "old_time": "2019-09-30",
            "new_time": "2023-01-12",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_34709"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.0",
            "new_version": "==0.3.2",
            "old_time": "2020-09-24",
            "new_time": "2022-03-15",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2526"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.74.0",
            "new_version": "==1.31.1",
            "old_time": "2021-01-07",
            "new_time": "2024-02-09",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37306"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.76.0",
            "new_version": "==1.3.0",
            "old_time": "2021-02-04",
            "new_time": "2021-12-16",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_43224"
        },
        {
            "dependency": "torch",
            "old_version": "==1.2.0",
            "new_version": "==1.13.0",
            "old_time": "2019-08-08",
            "new_time": "2022-10-24",
            "description": "This code defines a function `bar` that creates a resolution callback with a parameter of 1 and then prints the result of calling the callback with the argument \"foo\". The function `baz` sets a variable `foo` to 2 and then calls the function `bar`. Finally, the code executes the function `baz`.",
            "old_code": "def bar():\n    cb = createResolutionCallback(1)\n    print(cb(\"foo\"))\n\ndef baz():\n    foo = 2\n    bar()\n\nbaz()",
            "new_code": "def bar():\n    cb = createResolutionCallbackFromFrame(1)\n    print(cb(\"foo\"))\n\ndef baz():\n    foo = 2\n    bar()\n\nbaz()",
            "old_name": "createResolutionCallback",
            "new_name": "createResolutionCallbackFromFrame",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_49252"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.77.0",
            "new_version": "==1.20.0",
            "old_time": "2021-02-23",
            "new_time": "2023-03-09",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37513"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.46.0",
            "new_version": "==1.22.0",
            "old_time": "2019-09-23",
            "new_time": "2023-04-27",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30669"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.5.2",
            "old_time": "2022-05-05",
            "new_time": "2023-10-19",
            "description": "This code initializes a dataset object for distributed training and sets the HDFS configuration for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "_set_hdfs_config",
            "new_name": "set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11020"
        },
        {
            "dependency": "imageio",
            "old_version": "==2.0.0",
            "new_version": "==2.24.0",
            "old_time": "2016-12-09",
            "new_time": "2023-01-09",
            "description": "The code parses a byte string containing information about ImageJ software and returns a dictionary with keys 'ImageJ', 'images', and 'hyperstack' mapped to their respective values.",
            "old_code": "description = b'ImageJ=1.11a\\nimages=510\\nhyperstack=true\\n'\nimagej_description_dict(description)  # doctest: +SKIP\n{'ImageJ': '1.11a', 'images': 510, 'hyperstack': True}",
            "new_code": "description = 'ImageJ=1.11a\\nimages=510\\nhyperstack=true\\n'\nimagej_description_metadata(description)\n{'ImageJ': '1.11a', 'images': 510, 'hyperstack': True}",
            "old_name": "imagej_description_dict",
            "new_name": "imagej_description_metadata",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1005"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.6.0",
            "old_time": "2021-11-02",
            "new_time": "2023-12-21",
            "description": "The code creates an in-memory dataset using the PaddlePaddle framework with the ability to parse content.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "old_name": "_set_parse_content",
            "new_name": "set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11941"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.73.0",
            "new_version": "==1.31.1",
            "old_time": "2020-12-17",
            "new_time": "2024-02-09",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37194"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.5.1",
            "old_time": "2021-01-21",
            "new_time": "2023-07-25",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the time interval for sending data to the distributed training fleet to 2 seconds.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "old_name": "set_fleet_send_sleep_seconds",
            "new_name": "_set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6535"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.4.0",
            "old_time": "2021-11-02",
            "new_time": "2022-11-16",
            "description": "The code sets up an in-memory dataset for distributed training with a sleep time of 2 seconds for sending data between nodes.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "old_name": "_set_fleet_send_sleep_seconds",
            "new_name": "set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12315"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.56.0",
            "new_version": "==1.23.1",
            "old_time": "2020-02-15",
            "new_time": "2023-06-02",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_31504"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.0.0",
            "new_version": "==2.9.1",
            "old_time": "2017-02-11",
            "new_time": "2022-05-22",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44922"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.10.0",
            "new_version": "==2.14.0",
            "old_time": "2018-08-07",
            "new_time": "2023-09-21",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45938"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.70.0",
            "new_version": "==1.16.0",
            "old_time": "2020-10-28",
            "new_time": "2022-12-14",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_32720"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.51.0",
            "new_version": "==1.22.0",
            "old_time": "2019-12-01",
            "new_time": "2023-04-27",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_31159"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.3.0",
            "new_version": "==2.1.4",
            "old_time": "2021-07-02",
            "new_time": "2023-12-08",
            "description": "The code ensures that the data type of the input numpy dtype is in nanoseconds precision.",
            "old_code": "ensure_nanosecond_dtype(np.dtype(\"M8[s]\"))\nensure_nanosecond_dtype(np.dtype(\"m8[ps]\"))",
            "new_code": "_ensure_nanosecond_dtype(np.dtype(\"M8[s]\"))\n_ensure_nanosecond_dtype(np.dtype(\"m8[ps]\"))",
            "old_name": "ensure_nanosecond_dtype",
            "new_name": "_ensure_nanosecond_dtype",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20114"
        },
        {
            "dependency": "torch",
            "old_version": "==1.2.0",
            "new_version": "==1.5.1",
            "old_time": "2019-08-08",
            "new_time": "2020-06-11",
            "description": "This code defines a function `bar` that creates a resolution callback with a parameter of 1 and then prints the result of calling the callback with the argument \"foo\". The function `baz` sets a variable `foo` to 2 and then calls the function `bar`. Finally, the code executes the function `baz`.",
            "old_code": "def bar():\n    cb = createResolutionCallback(1)\n    print(cb(\"foo\"))\n\ndef baz():\n    foo = 2\n    bar()\n\nbaz()",
            "new_code": "def bar():\n    cb = createResolutionCallbackFromFrame(1)\n    print(cb(\"foo\"))\n\ndef baz():\n    foo = 2\n    bar()\n\nbaz()",
            "old_name": "createResolutionCallback",
            "new_name": "createResolutionCallbackFromFrame",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_49238"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.22.0",
            "new_version": "==1.3.4",
            "old_time": "2017-12-30",
            "new_time": "2021-10-17",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17776"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.3.0",
            "old_time": "2021-11-02",
            "new_time": "2022-05-05",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and enables parsing of instance IDs.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "old_name": "set_parse_ins_id",
            "new_name": "_set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6063"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.75.0",
            "new_version": "==1.10.0",
            "old_time": "2021-01-21",
            "new_time": "2022-06-01",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37384"
        },
        {
            "dependency": "streamlit",
            "old_version": "==1.1.0",
            "new_version": "==1.29.0",
            "old_time": "2021-10-21",
            "new_time": "2023-11-30",
            "description": "This code generates a random 10x5 DataFrame using NumPy and Pandas, and then displays it as an arrow table using Streamlit.",
            "old_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n   np.random.randn(10, 5),\n   columns=(\"col %d\" % i for i in range(5)))\n\nst._arrow_table(df)",
            "new_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.random.randn(10, 5), columns=(\"col %d\" % i for i in range(5)))\n\nst.table(df)",
            "old_name": "_arrow_table",
            "new_name": "table",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44081"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.61.0",
            "new_version": "==1.5.0",
            "old_time": "2020-06-03",
            "new_time": "2022-01-27",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_31866"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.49.0",
            "new_version": "==1.17.0",
            "old_time": "2019-10-23",
            "new_time": "2023-01-12",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30957"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==0.12.0",
            "new_version": "==2.2.1",
            "old_time": "2016-12-19",
            "new_time": "2020-09-22",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44821"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.8.0",
            "new_version": "==1.13.1",
            "old_time": "2018-04-27",
            "new_time": "2019-02-25",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45740"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.82.0",
            "new_version": "==1.31.1",
            "old_time": "2021-05-13",
            "new_time": "2024-02-09",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_43648"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.61.0",
            "new_version": "==1.12.1",
            "old_time": "2020-06-03",
            "new_time": "2022-08-22",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36044"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.3.2",
            "old_time": "2021-11-02",
            "new_time": "2022-08-15",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "old_name": "set_batch_size",
            "new_name": "_set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3975"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.33.0",
            "new_version": "==1.20.0",
            "old_time": "2019-04-12",
            "new_time": "2023-03-09",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29981"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.70.0",
            "new_version": "==1.5.1",
            "old_time": "2020-10-28",
            "new_time": "2022-02-09",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_32700"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.66.0",
            "new_version": "==0.85.0",
            "old_time": "2020-09-02",
            "new_time": "2021-07-22",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36523"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.60.0",
            "new_version": "==1.14.1",
            "old_time": "2020-05-17",
            "new_time": "2022-11-09",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_31834"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.4.0",
            "old_time": "2021-11-02",
            "new_time": "2022-11-16",
            "description": "The code creates an in-memory dataset for distributed training with the ability to parse instance IDs.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "old_name": "_set_parse_ins_id",
            "new_name": "set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11745"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.66.0",
            "new_version": "==1.23.1",
            "old_time": "2020-09-02",
            "new_time": "2023-06-02",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36565"
        },
        {
            "dependency": "torch",
            "old_version": "==1.3.0",
            "new_version": "==1.13.0",
            "old_time": "2019-10-10",
            "new_time": "2022-10-24",
            "description": "This code defines a function `bar` that creates a resolution callback with a parameter of 1 and then prints the result of calling the callback with the argument \"foo\". The function `baz` sets a variable `foo` to 2 and then calls the function `bar`. Finally, the code executes the function `baz`.",
            "old_code": "def bar():\n    cb = createResolutionCallback(1)\n    print(cb(\"foo\"))\n\ndef baz():\n    foo = 2\n    bar()\n\nbaz()",
            "new_code": "def bar():\n    cb = createResolutionCallbackFromFrame(1)\n    print(cb(\"foo\"))\n\ndef baz():\n    foo = 2\n    bar()\n\nbaz()",
            "old_name": "createResolutionCallback",
            "new_name": "createResolutionCallbackFromFrame",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_49276"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.47.0",
            "new_version": "==1.27.0",
            "old_time": "2019-09-30",
            "new_time": "2023-09-21",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_34721"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.41.0",
            "new_version": "==1.27.1",
            "old_time": "2019-06-24",
            "new_time": "2023-09-29",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30333"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.78.0",
            "new_version": "==1.31.0",
            "old_time": "2021-03-04",
            "new_time": "2024-02-01",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_43377"
        },
        {
            "dependency": "streamlit",
            "old_version": "==1.22.0",
            "new_version": "==1.28.1",
            "old_time": "2023-04-27",
            "new_time": "2023-11-02",
            "description": "The code generates a scatter plot chart using Streamlit and displays it using the Arrow Vega-Lite chart. The chart visualizes random data points with three variables 'a', 'b', and 'c', where 'a' and 'b' are plotted on the x and y axes as quantitative values, and 'c' is used for both the size and color of the data points.",
            "old_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n    np.random.randn(200, 3),\n    columns=['a', 'b', 'c'])\n\nst._arrow_vega_lite_chart(df, {\n    'mark': {'type': 'circle', 'tooltip': True},\n    'encoding': {\n        'x': {'field': 'a', 'type': 'quantitative'},\n        'y': {'field': 'b', 'type': 'quantitative'},\n        'size': {'field': 'c', 'type': 'quantitative'},\n        'color': {'field': 'c', 'type': 'quantitative'},\n    },\n})",
            "new_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\nchart_data = pd.DataFrame(np.random.randn(200, 3), columns=[\"a\", \"b\", \"c\"])\n\nst.vega_lite_chart(\n    chart_data,\n    {\n        \"mark\": {\"type\": \"circle\", \"tooltip\": True},\n        \"encoding\": {\n            \"x\": {\"field\": \"a\", \"type\": \"quantitative\"},\n            \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n            \"size\": {\"field\": \"c\", \"type\": \"quantitative\"},\n            \"color\": {\"field\": \"c\", \"type\": \"quantitative\"},\n        },\n    },\n)",
            "old_name": "_arrow_vega_lite_chart",
            "new_name": "vega_lite_chart",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44660"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.68.0",
            "new_version": "==1.27.2",
            "old_time": "2020-10-08",
            "new_time": "2023-10-03",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36739"
        },
        {
            "dependency": "datasets",
            "old_version": "==1.15.0",
            "new_version": "==2.16.1",
            "old_time": "2021-11-02",
            "new_time": "2023-12-30",
            "description": "This code resolves patterns locally or by URLs for YAML files in the \"src\" directory and its subdirectories.",
            "old_code": "from datasets.data_files import resolve_patterns_locally_or_by_urls\n\nbase_path = \".\"\nresolve_patterns_locally_or_by_urls(base_path, [\"src/**/*.yaml\"])",
            "new_code": "from datasets.data_files import resolve_pattern\nbase_path = \".\"\nresolve_pattern(\"docs/**/*.py\", base_path)",
            "old_name": "resolve_patterns_locally_or_by_urls",
            "new_name": "resolve_pattern",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_331"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.0",
            "new_version": "==1.2.10",
            "old_time": "2020-10-13",
            "new_time": "2021-04-23",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21347"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.1.1",
            "old_time": "2021-01-21",
            "new_time": "2021-06-23",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the time interval for sending data to the distributed training fleet to 2 seconds.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "old_name": "set_fleet_send_sleep_seconds",
            "new_name": "_set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6522"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.78.0",
            "new_version": "==1.14.0",
            "old_time": "2021-03-04",
            "new_time": "2022-10-25",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_43351"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.69.0",
            "new_version": "==1.3.0",
            "old_time": "2020-10-15",
            "new_time": "2021-12-16",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_42630"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.52.0",
            "new_version": "==1.23.1",
            "old_time": "2019-12-20",
            "new_time": "2023-06-02",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35277"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.45.0",
            "new_version": "==1.11.0",
            "old_time": "2019-08-28",
            "new_time": "2022-07-13",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30602"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.82.0",
            "new_version": "==1.21.0",
            "old_time": "2021-05-13",
            "new_time": "2023-04-06",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37850"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.57.0",
            "new_version": "==0.87.0",
            "old_time": "2020-03-27",
            "new_time": "2021-08-23",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35630"
        },
        {
            "dependency": "ray",
            "old_version": "==1.7.0",
            "new_version": "==2.2.0",
            "old_time": "2021-10-01",
            "new_time": "2022-12-13",
            "description": "The code generates a dataset with 1000 elements and then maps each element to a new dictionary with a key \"v2\" whose value is twice the original element's value. Finally, it displays the resulting dataset.",
            "old_code": "ds = ray.data.range_arrow(1000)\nds.map(lambda r: {\"v2\": r[\"value\"] * 2}).show()",
            "new_code": "import ray\nds = ray.data.range_table(1000)\nds.map(lambda r: {\"v2\": r[\"value\"] * 2}).show()",
            "old_name": "range_arrow",
            "new_name": "range_table",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29450"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.66.0",
            "new_version": "==1.15.2",
            "old_time": "2020-09-02",
            "new_time": "2022-11-30",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36555"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.61.0",
            "new_version": "==1.28.2",
            "old_time": "2020-06-03",
            "new_time": "2023-11-13",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36070"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.34.0",
            "new_version": "==1.2.0",
            "old_time": "2019-04-19",
            "new_time": "2021-11-11",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33899"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.72.0",
            "new_version": "==1.27.1",
            "old_time": "2020-12-02",
            "new_time": "2023-09-29",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37130"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.79.0",
            "new_version": "==1.5.1",
            "old_time": "2021-03-18",
            "new_time": "2022-02-09",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37600"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.3.1",
            "old_time": "2021-05-13",
            "new_time": "2022-07-01",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11499"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.5.0",
            "old_time": "2021-11-02",
            "new_time": "2023-06-19",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a custom pipe command for data processing.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_so_parser_name(\"./abc.so\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_so_parser_name",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10228"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.33.0",
            "new_version": "==1.3.1",
            "old_time": "2019-04-12",
            "new_time": "2021-12-28",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33845"
        },
        {
            "dependency": "click",
            "old_version": "==7.0",
            "new_version": "==8.1.3",
            "old_time": "2018-09-25",
            "new_time": "2022-04-28",
            "description": "This Python code defines a command line interface (CLI) using the Click library. It includes a group command with an option for input, which defaults to 23. The CLI returns the value 42. There is also a result callback function that adds the input value to the result and returns the sum.",
            "old_code": "@click.group()\n@click.option('-i', '--input', default=23)\ndef cli(input):\n    return 42\n\n@cli.resultcallback()\ndef process_result(result, input):\n    return result + input",
            "new_code": "@click.group()\n@click.option('-i', '--input', default=23)\ndef cli(input):\n    return 42\n\n@cli.result_callback()\ndef process_result(result, input):\n    return result + input",
            "old_name": "resultcallback",
            "new_name": "result_callback",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_217"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.41.0",
            "new_version": "==1.5.1",
            "old_time": "2019-06-24",
            "new_time": "2022-02-09",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30299"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.0",
            "new_version": "==1.4.0",
            "old_time": "2020-10-13",
            "new_time": "2021-07-27",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21049"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.0",
            "new_version": "==2.1.1",
            "old_time": "2020-01-29",
            "new_time": "2023-09-20",
            "description": "The code may potentially modify lambda functions named 'sum' to avoid conflicts.",
            "old_code": "_maybe_mangle_lambdas('sum')\\n\\n_maybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "new_code": "maybe_mangle_lambdas('sum')\n\nmaybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "old_name": "_maybe_mangle_lambdas",
            "new_name": "maybe_mangle_lambdas",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17264"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.66.0",
            "new_version": "==1.11.0",
            "old_time": "2020-09-02",
            "new_time": "2022-07-13",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36545"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.32.0",
            "new_version": "==1.7.0",
            "old_time": "2019-03-29",
            "new_time": "2022-03-02",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29909"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.56.0",
            "new_version": "==1.19.0",
            "old_time": "2020-02-15",
            "new_time": "2023-02-23",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35608"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.3.1",
            "old_time": "2021-11-02",
            "new_time": "2022-07-01",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets a download command for the dataset to read from AFS (Alibaba File System).",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "old_name": "_set_download_cmd",
            "new_name": "set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11173"
        },
        {
            "dependency": "imageio",
            "old_version": "==2.2.0",
            "new_version": "==2.33.1",
            "old_time": "2017-05-25",
            "new_time": "2023-12-11",
            "description": "The code parses a byte string containing information about ImageJ software and returns a dictionary with keys 'ImageJ', 'images', and 'hyperstack' mapped to their respective values.",
            "old_code": "description = b'ImageJ=1.11a\\nimages=510\\nhyperstack=true\\n'\nimagej_description_dict(description)  # doctest: +SKIP\n{'ImageJ': '1.11a', 'images': 510, 'hyperstack': True}",
            "new_code": "description = 'ImageJ=1.11a\\nimages=510\\nhyperstack=true\\n'\nimagej_description_metadata(description)\n{'ImageJ': '1.11a', 'images': 510, 'hyperstack': True}",
            "old_name": "imagej_description_dict",
            "new_name": "imagej_description_metadata",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1354"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.68.0",
            "new_version": "==0.86.0",
            "old_time": "2020-10-08",
            "new_time": "2021-08-05",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_42515"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.4.1",
            "old_time": "2021-01-21",
            "new_time": "2022-12-05",
            "description": "The code creates a dataset using PaddlePaddle's fluid framework and sets a pipe command to run a Python script called \"my_script.py\" for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "old_name": "set_pipe_command",
            "new_name": "_set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3682"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.84.0",
            "new_version": "==1.8.1",
            "old_time": "2021-07-01",
            "new_time": "2022-03-29",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_43718"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.71.0",
            "new_version": "==1.11.0",
            "old_time": "2020-11-11",
            "new_time": "2022-07-13",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37049"
        },
        {
            "dependency": "click",
            "old_version": "==3.0",
            "new_version": "==8.0.0",
            "old_time": "2014-08-12",
            "new_time": "2021-05-11",
            "description": "This Python code defines a command line interface (CLI) using the Click library. It includes a group command with an option for input, which defaults to 23. The CLI returns the value 42. There is also a result callback function that adds the input value to the result and returns the sum.",
            "old_code": "@click.group()\n@click.option('-i', '--input', default=23)\ndef cli(input):\n    return 42\n\n@cli.resultcallback()\ndef process_result(result, input):\n    return result + input",
            "new_code": "@click.group()\n@click.option('-i', '--input', default=23)\ndef cli(input):\n    return 42\n\n@cli.result_callback()\ndef process_result(result, input):\n    return result + input",
            "old_name": "resultcallback",
            "new_name": "result_callback",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.76.0",
            "new_version": "==1.1.0",
            "old_time": "2021-02-04",
            "new_time": "2021-10-21",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37426"
        },
        {
            "dependency": "imageio",
            "old_version": "==2.1.0",
            "new_version": "==2.13.0",
            "old_time": "2016-12-22",
            "new_time": "2021-11-29",
            "description": "The code parses a byte string containing information about ImageJ software and returns a dictionary with keys 'ImageJ', 'images', and 'hyperstack' mapped to their respective values.",
            "old_code": "description = b'ImageJ=1.11a\\nimages=510\\nhyperstack=true\\n'\nimagej_description_dict(description)  # doctest: +SKIP\n{'ImageJ': '1.11a', 'images': 510, 'hyperstack': True}",
            "new_code": "description = 'ImageJ=1.11a\\nimages=510\\nhyperstack=true\\n'\nimagej_description_metadata(description)\n{'ImageJ': '1.11a', 'images': 510, 'hyperstack': True}",
            "old_name": "imagej_description_dict",
            "new_name": "imagej_description_metadata",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1108"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.2.2",
            "old_time": "2021-05-13",
            "new_time": "2022-01-18",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11497"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.5.0",
            "new_version": "==2.9.1",
            "old_time": "2018-01-25",
            "new_time": "2022-05-22",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45458"
        },
        {
            "dependency": "streamlit",
            "old_version": "==1.3.0",
            "new_version": "==1.31.1",
            "old_time": "2021-12-16",
            "new_time": "2024-02-09",
            "description": "This code generates a random 10x5 DataFrame using NumPy and Pandas, and then displays it as an arrow table using Streamlit.",
            "old_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n   np.random.randn(10, 5),\n   columns=(\"col %d\" % i for i in range(5)))\n\nst._arrow_table(df)",
            "new_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.random.randn(10, 5), columns=(\"col %d\" % i for i in range(5)))\n\nst.table(df)",
            "old_name": "_arrow_table",
            "new_name": "table",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44098"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.66.0",
            "new_version": "==1.5.0",
            "old_time": "2020-09-02",
            "new_time": "2022-01-27",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36535"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.12.0",
            "new_version": "==2.11.0",
            "old_time": "2018-11-02",
            "new_time": "2022-11-16",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46133"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.79.0",
            "new_version": "==0.89.0",
            "old_time": "2021-03-18",
            "new_time": "2021-09-22",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_43382"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.22.0",
            "new_version": "==1.2.0",
            "old_time": "2017-12-30",
            "new_time": "2020-12-26",
            "description": "The code creates an index object based on the input provided, which can be a list of single values, tuples, or lists.",
            "old_code": "_ensure_index(['a', 'b'])\nIndex(['a', 'b'], dtype='object')\n\n_ensure_index([('a', 'a'),  ('b', 'c')])\nIndex([('a', 'a'), ('b', 'c')], dtype='object')\n\n_ensure_index([['a', 'a'], ['b', 'c']])\nMultiIndex(levels=[['a'], ['b', 'c']],\n           labels=[[0, 0], [0, 1]])",
            "new_code": "ensure_index(['a', 'b'])\nIndex(['a', 'b'], dtype='object')\n\nensure_index([('a', 'a'),  ('b', 'c')])\nIndex([('a', 'a'), ('b', 'c')], dtype='object')\n\nensure_index([['a', 'a'], ['b', 'c']])\nMultiIndex(levels=[['a'], ['b', 'c']],\n           labels=[[0, 0], [0, 1]])",
            "old_name": "_ensure_index",
            "new_name": "ensure_index",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_15455"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.21.0",
            "new_version": "==2.1.1",
            "old_time": "2017-10-27",
            "new_time": "2023-09-20",
            "description": "The code is inferring the data type of an integer value with 64-bit precision.",
            "old_code": "maybe_infer_dtype_type(Foo(np.dtype(\"i8\")))",
            "new_code": "_maybe_infer_dtype_type(Foo(np.dtype(\"i8\")))",
            "old_name": "maybe_infer_dtype_type",
            "new_name": "_maybe_infer_dtype_type",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_19495"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.3.0",
            "new_version": "==2.8.2",
            "old_time": "2017-08-17",
            "new_time": "2022-05-22",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45253"
        },
        {
            "dependency": "streamlit",
            "old_version": "==1.27.0",
            "new_version": "==1.28.0",
            "old_time": "2023-09-21",
            "new_time": "2023-10-25",
            "description": "The code generates a scatter plot chart using Streamlit and displays it using the Arrow Vega-Lite chart. The chart visualizes random data points with three variables 'a', 'b', and 'c', where 'a' and 'b' are plotted on the x and y axes as quantitative values, and 'c' is used for both the size and color of the data points.",
            "old_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n    np.random.randn(200, 3),\n    columns=['a', 'b', 'c'])\n\nst._arrow_vega_lite_chart(df, {\n    'mark': {'type': 'circle', 'tooltip': True},\n    'encoding': {\n        'x': {'field': 'a', 'type': 'quantitative'},\n        'y': {'field': 'b', 'type': 'quantitative'},\n        'size': {'field': 'c', 'type': 'quantitative'},\n        'color': {'field': 'c', 'type': 'quantitative'},\n    },\n})",
            "new_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\nchart_data = pd.DataFrame(np.random.randn(200, 3), columns=[\"a\", \"b\", \"c\"])\n\nst.vega_lite_chart(\n    chart_data,\n    {\n        \"mark\": {\"type\": \"circle\", \"tooltip\": True},\n        \"encoding\": {\n            \"x\": {\"field\": \"a\", \"type\": \"quantitative\"},\n            \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n            \"size\": {\"field\": \"c\", \"type\": \"quantitative\"},\n            \"color\": {\"field\": \"c\", \"type\": \"quantitative\"},\n        },\n    },\n)",
            "old_name": "_arrow_vega_lite_chart",
            "new_name": "vega_lite_chart",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44701"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code initializes an in-memory dataset for distributed training in PaddlePaddle framework and sets the merging strategy to merge data by line ID.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "old_name": "_set_merge_by_lineid",
            "new_name": "set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12533"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets it to merge data by line ID.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "old_name": "set_merge_by_lineid",
            "new_name": "_set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6854"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.2",
            "old_time": "2021-05-13",
            "new_time": "2021-07-30",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_14533"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.2",
            "old_time": "2021-01-21",
            "new_time": "2021-04-08",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the variables 'data' and 'label' for use in the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_use_var([data, label])",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "old_name": "set_use_var",
            "new_name": "_set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4240"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a custom pipe command for data processing.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_so_parser_name(\"./abc.so\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_so_parser_name",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10277"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the fleet send batch size to 800.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "old_name": "set_fleet_send_batch_size",
            "new_name": "_set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6385"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_14624"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets it to merge data by line ID.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "old_name": "set_merge_by_lineid",
            "new_name": "_set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6879"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.0",
            "new_version": "==0.8.6",
            "old_time": "2019-12-17",
            "new_time": "2020-06-22",
            "description": "This code splits the traffic for the \"service-name\" between two backend versions, \"backend:v1\" and \"backend:v2\", with a 50/50 distribution.",
            "old_code": "serve.split(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "new_code": "serve.set_traffic(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "old_name": "split",
            "new_name": "set_traffic",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29118"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.0",
            "new_version": "==0.8.6",
            "old_time": "2019-12-17",
            "new_time": "2020-06-22",
            "description": "The code runs a function `run_me` for 100 iterations, where it sleeps for 1 second in each iteration and logs the values \"hello\" as \"world\" and \"ray\" as \"tune\" using the `track.log` function. The function is executed using Ray Tune for analysis.",
            "old_code": "import time\nfrom ray import tune\nfrom ray.tune import track\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        track.log(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "new_code": "import time\nfrom ray import tune\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        tune.report(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "old_name": "log",
            "new_name": "report",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29300"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4195"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.1",
            "old_time": "2021-11-02",
            "new_time": "2021-11-30",
            "description": "The code creates a dataset using PaddlePaddle's fluid framework and sets a pipe command to run a Python script called \"my_script.py\" for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "old_name": "set_pipe_command",
            "new_name": "_set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3781"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.2",
            "old_time": "2021-05-13",
            "new_time": "2021-07-30",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12063"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code creates an in-memory dataset for distributed training with the ability to parse instance IDs.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "old_name": "_set_parse_ins_id",
            "new_name": "set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11774"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets a download command for the dataset to read from AFS (Alibaba File System).",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "old_name": "_set_download_cmd",
            "new_name": "set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11114"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "The code creates a dataset using PaddlePaddle's fluid framework and sets a pipe command to run a Python script called \"my_script.py\" for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "old_name": "set_pipe_command",
            "new_name": "_set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3838"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the fleet send batch size to 800.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "old_name": "set_fleet_send_batch_size",
            "new_name": "_set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6474"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.1",
            "old_time": "2021-11-02",
            "new_time": "2021-11-30",
            "description": "This code initializes a dataset object for distributed training and sets the HDFS configuration for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "_set_hdfs_config",
            "new_name": "set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10980"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "The code initializes an in-memory dataset for distributed training in PaddlePaddle framework and sets the merging strategy to merge data by line ID.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "old_name": "_set_merge_by_lineid",
            "new_name": "set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12557"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.1",
            "old_time": "2021-01-21",
            "new_time": "2021-03-02",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the time interval for sending data to the distributed training fleet to 2 seconds.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "old_name": "set_fleet_send_sleep_seconds",
            "new_name": "_set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6519"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.0",
            "new_version": "==0.2.28",
            "old_time": "2020-09-24",
            "new_time": "2022-02-02",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2523"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4234"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11607"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code creates an in-memory dataset using PaddlePaddle framework.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "old_name": "set_parse_content",
            "new_name": "_set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6285"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the time interval for sending data to the distributed training fleet to 2 seconds.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "old_name": "set_fleet_send_sleep_seconds",
            "new_name": "_set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6704"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset using PaddlePaddle framework and sets a download command to read data from AFS (Alibaba File System).",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "old_name": "set_download_cmd",
            "new_name": "_set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5435"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_14647"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset using PaddlePaddle framework and sets a download command to read data from AFS (Alibaba File System).",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "old_name": "set_download_cmd",
            "new_name": "_set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5492"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.1",
            "old_time": "2021-01-21",
            "new_time": "2021-03-02",
            "description": "The code creates a dataset using PaddlePaddle's fluid framework and sets a pipe command to run a Python script called \"my_script.py\" for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "old_name": "set_pipe_command",
            "new_name": "_set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3669"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.1",
            "old_time": "2021-11-02",
            "new_time": "2021-11-30",
            "description": "The code creates a dataset using PaddlePaddle framework and sets a download command to read data from AFS (Alibaba File System).",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "old_name": "set_download_cmd",
            "new_name": "_set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5491"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the fleet send batch size to 800.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "old_name": "set_fleet_send_batch_size",
            "new_name": "_set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6475"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.0",
            "new_version": "==1.0.7",
            "old_time": "2020-10-13",
            "new_time": "2020-11-17",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21326"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.1",
            "old_time": "2021-11-02",
            "new_time": "2021-11-30",
            "description": "This code creates an in-memory dataset using PaddlePaddle framework and sets the number of queues to 12.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "old_name": "set_queue_num",
            "new_name": "_set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5871"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the variables 'data' and 'label' for use in the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_use_var([data, label])",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "old_name": "set_use_var",
            "new_name": "_set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4352"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code initializes an in-memory dataset for distributed training in PaddlePaddle framework and sets the merging strategy to merge data by line ID.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "old_name": "_set_merge_by_lineid",
            "new_name": "set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12534"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the time interval for sending data to the distributed training fleet to 2 seconds.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "old_name": "set_fleet_send_sleep_seconds",
            "new_name": "_set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6573"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11608"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets it to merge data by line ID.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "old_name": "set_merge_by_lineid",
            "new_name": "_set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6878"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the fleet send batch size to 800.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "old_name": "set_fleet_send_batch_size",
            "new_name": "_set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6383"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.0",
            "new_version": "==0.2.18",
            "old_time": "2020-09-24",
            "new_time": "2021-07-21",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2514"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "old_name": "set_batch_size",
            "new_name": "_set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4005"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.1",
            "old_time": "2021-01-21",
            "new_time": "2021-03-02",
            "description": "This code initializes a dataset object for distributed training and sets the HDFS configuration for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "_set_hdfs_config",
            "new_name": "set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10868"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.2",
            "old_time": "2021-01-21",
            "new_time": "2021-04-08",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11249"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code sets up an in-memory dataset for distributed training with a sleep time of 2 seconds for sending data between nodes.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "old_name": "_set_fleet_send_sleep_seconds",
            "new_name": "set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12344"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "The code creates an in-memory dataset using PaddlePaddle framework.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "old_name": "set_parse_content",
            "new_name": "_set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6193"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and sets the number of threads to 12 for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "old_name": "_set_thread",
            "new_name": "set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10544"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "This code initializes a dataset object for distributed training and sets the HDFS configuration for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "_set_hdfs_config",
            "new_name": "set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11037"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.0",
            "new_version": "==0.8.7",
            "old_time": "2019-12-17",
            "new_time": "2020-08-12",
            "description": "This code splits the traffic for the \"service-name\" between two backend versions, \"backend:v1\" and \"backend:v2\", with a 50/50 distribution.",
            "old_code": "serve.split(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "new_code": "serve.set_traffic(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "old_name": "split",
            "new_name": "set_traffic",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29119"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "This code creates an in-memory dataset using PaddlePaddle framework and sets the number of queues to 12.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "old_name": "set_queue_num",
            "new_name": "_set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5928"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and enables parsing of instance IDs.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "old_name": "set_parse_ins_id",
            "new_name": "_set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6094"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "old_name": "set_batch_size",
            "new_name": "_set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4029"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code creates an in-memory dataset for distributed training with the ability to parse instance IDs.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "old_name": "_set_parse_ins_id",
            "new_name": "set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11773"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.0",
            "new_version": "==1.0.8",
            "old_time": "2020-10-13",
            "new_time": "2020-11-24",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21327"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.2",
            "old_time": "2021-01-21",
            "new_time": "2021-04-08",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets a download command for the dataset to read from AFS (Alibaba File System).",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "old_name": "_set_download_cmd",
            "new_name": "set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11059"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10468"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "This code creates an in-memory dataset using PaddlePaddle framework and sets the number of queues to 12.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "old_name": "set_queue_num",
            "new_name": "_set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5813"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code creates a dataset using PaddlePaddle framework and sets a download command to read data from AFS (Alibaba File System).",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "old_name": "set_download_cmd",
            "new_name": "_set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5524"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.2",
            "old_time": "2021-01-21",
            "new_time": "2021-04-08",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_14479"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "old_name": "set_batch_size",
            "new_name": "_set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4043"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11418"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.1.0",
            "new_version": "==1.1.3",
            "old_time": "2020-12-10",
            "new_time": "2021-01-05",
            "description": "The code calculates the Receiver Operating Characteristic (ROC) curve using the input tensors x and y, and returns the false positive rate (fpr), true positive rate (tpr), and thresholds.",
            "old_code": "x = torch.tensor([0, 1, 2, 3])\ny = torch.tensor([0, 1, 1, 1])\nfpr, tpr, thresholds = __roc(x, y)\nfpr\ntensor([0., 0., 0., 0., 1.])\ntpr\ntensor([0.0000, 0.3333, 0.6667, 1.0000, 1.0000])\nthresholds\ntensor([4, 3, 2, 1, 0])",
            "new_code": "_fpr, _tpr, _thresholds = _roc(x, y)\n_fpr\n_tpr\n_thresholds",
            "old_name": "__roc",
            "new_name": "_roc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21516"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and sets the number of threads to 12 for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "old_name": "_set_thread",
            "new_name": "set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10657"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "This code initializes a dataset object for distributed training and sets the HDFS configuration for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "_set_hdfs_config",
            "new_name": "set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11053"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.1",
            "old_time": "2021-01-21",
            "new_time": "2021-03-02",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the HDFS configuration for the dataset with the specified file system name and user group information.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "set_hdfs_config",
            "new_name": "_set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5189"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "The code creates an in-memory dataset using PaddlePaddle framework.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "old_name": "set_parse_content",
            "new_name": "_set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6309"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.1",
            "old_time": "2021-11-02",
            "new_time": "2021-11-30",
            "description": "The code creates an in-memory dataset using PaddlePaddle framework.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "old_name": "set_parse_content",
            "new_name": "_set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6251"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11417"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_14648"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the variables 'data' and 'label' for use in the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_use_var([data, label])",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "old_name": "set_use_var",
            "new_name": "_set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4385"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the variables 'data' and 'label' for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "new_code": "import paddle.base as base\npaddle.enable_static()\ndataset = base.DatasetFactory().create_dataset()\ndata = paddle.static.data(name=\"data\", shape=[None, 10, 10], dtype=\"int64\")\nlabel = paddle.static.data(name=\"label\", shape=[None, 1], dtype=\"int64\", lod_level=1)\ndataset.set_use_var([data, label])",
            "old_name": "_set_use_var",
            "new_name": "set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10823"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.1",
            "old_time": "2021-01-21",
            "new_time": "2021-03-02",
            "description": "The code creates an in-memory dataset using the PaddlePaddle framework with the ability to parse content.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "old_name": "_set_parse_content",
            "new_name": "set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11818"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11551"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "The code creates an in-memory dataset using the PaddlePaddle framework with the ability to parse content.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "old_name": "_set_parse_content",
            "new_name": "set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11987"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "The code creates an in-memory dataset using PaddlePaddle framework.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "old_name": "set_parse_content",
            "new_name": "_set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6252"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the time interval for sending data to the distributed training fleet to 2 seconds.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "old_name": "set_fleet_send_sleep_seconds",
            "new_name": "_set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6689"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets it to merge data by line ID.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "old_name": "set_merge_by_lineid",
            "new_name": "_set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6894"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.1",
            "old_time": "2021-01-21",
            "new_time": "2021-03-02",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the variables 'data' and 'label' for use in the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_use_var([data, label])",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "old_name": "set_use_var",
            "new_name": "_set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4239"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and sets the number of threads to 12 for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "old_name": "_set_thread",
            "new_name": "set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10634"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10444"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets a download command for the dataset to read from AFS (Alibaba File System).",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "old_name": "_set_download_cmd",
            "new_name": "set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11112"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "old_name": "set_batch_size",
            "new_name": "_set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3915"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "The code creates an in-memory dataset for distributed training with the ability to parse instance IDs.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "old_name": "_set_parse_ins_id",
            "new_name": "set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11741"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.1",
            "old_time": "2021-01-21",
            "new_time": "2021-03-02",
            "description": "The code creates a dataset using PaddlePaddle framework and sets a download command to read data from AFS (Alibaba File System).",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "old_name": "set_download_cmd",
            "new_name": "_set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5379"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_14591"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.0",
            "new_version": "==1.0.7",
            "old_time": "2020-10-13",
            "new_time": "2020-11-17",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21018"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.0",
            "new_version": "==1.0.4",
            "old_time": "2020-10-13",
            "new_time": "2020-10-27",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21323"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a pipe command to run a Python script called \"my_script.py\".",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_9995"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11394"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.1",
            "old_time": "2021-11-02",
            "new_time": "2021-11-30",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the variables 'data' and 'label' for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "new_code": "import paddle.base as base\npaddle.enable_static()\ndataset = base.DatasetFactory().create_dataset()\ndata = paddle.static.data(name=\"data\", shape=[None, 10, 10], dtype=\"int64\")\nlabel = paddle.static.data(name=\"label\", shape=[None, 1], dtype=\"int64\", lod_level=1)\ndataset.set_use_var([data, label])",
            "old_name": "_set_use_var",
            "new_name": "set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10790"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a custom pipe command for data processing.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_so_parser_name(\"./abc.so\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_so_parser_name",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10253"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a pipe command to run a Python script called \"my_script.py\".",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10108"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4105"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the variables 'data' and 'label' for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "new_code": "import paddle.base as base\npaddle.enable_static()\ndataset = base.DatasetFactory().create_dataset()\ndata = paddle.static.data(name=\"data\", shape=[None, 10, 10], dtype=\"int64\")\nlabel = paddle.static.data(name=\"label\", shape=[None, 1], dtype=\"int64\", lod_level=1)\ndataset.set_use_var([data, label])",
            "old_name": "_set_use_var",
            "new_name": "set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10732"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.1",
            "old_time": "2021-01-21",
            "new_time": "2021-03-02",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11438"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the HDFS configuration for the dataset with the specified file system name and user group information.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "set_hdfs_config",
            "new_name": "_set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5334"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "old_name": "set_batch_size",
            "new_name": "_set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4044"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.0",
            "new_version": "==0.2.12",
            "old_time": "2020-09-24",
            "new_time": "2021-04-01",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2508"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11304"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code creates a dataset using the PaddlePaddle framework and prints out the description of the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "old_name": "desc",
            "new_name": "_desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5715"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.1.0",
            "new_version": "==1.1.5",
            "old_time": "2020-12-10",
            "new_time": "2021-01-21",
            "description": "The code calculates the Receiver Operating Characteristic (ROC) curve using the input tensors x and y, and returns the false positive rate (fpr), true positive rate (tpr), and thresholds.",
            "old_code": "x = torch.tensor([0, 1, 2, 3])\ny = torch.tensor([0, 1, 1, 1])\nfpr, tpr, thresholds = __roc(x, y)\nfpr\ntensor([0., 0., 0., 0., 1.])\ntpr\ntensor([0.0000, 0.3333, 0.6667, 1.0000, 1.0000])\nthresholds\ntensor([4, 3, 2, 1, 0])",
            "new_code": "_fpr, _tpr, _thresholds = _roc(x, y)\n_fpr\n_tpr\n_thresholds",
            "old_name": "__roc",
            "new_name": "_roc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21518"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.2",
            "old_time": "2021-05-13",
            "new_time": "2021-07-30",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the fleet send batch size to 800.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "old_name": "set_fleet_send_batch_size",
            "new_name": "_set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6384"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a custom pipe command for data processing.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_so_parser_name(\"./abc.so\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_so_parser_name",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10293"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "The code creates an in-memory dataset for distributed training with the ability to parse instance IDs.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "old_name": "_set_parse_ins_id",
            "new_name": "set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11682"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "The code sets up an in-memory dataset for distributed training with a sleep time of 2 seconds for sending data between nodes.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "old_name": "_set_fleet_send_sleep_seconds",
            "new_name": "set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12368"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "The code creates an in-memory dataset using PaddlePaddle framework.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "old_name": "set_parse_content",
            "new_name": "_set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6308"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.2",
            "old_time": "2021-05-13",
            "new_time": "2021-07-30",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and sets the number of threads to 12 for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "old_name": "_set_thread",
            "new_name": "set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10543"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the variables 'data' and 'label' for use in the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_use_var([data, label])",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "old_name": "set_use_var",
            "new_name": "_set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4423"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.1",
            "old_time": "2021-01-21",
            "new_time": "2021-03-02",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and enables parsing of instance IDs.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "old_name": "set_parse_ins_id",
            "new_name": "_set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5949"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets a download command for the dataset to read from AFS (Alibaba File System).",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "old_name": "_set_download_cmd",
            "new_name": "set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11203"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "The code creates an in-memory dataset using the PaddlePaddle framework with the ability to parse content.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "old_name": "_set_parse_content",
            "new_name": "set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11931"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4162"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "The code creates a dataset using PaddlePaddle framework and sets a download command to read data from AFS (Alibaba File System).",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "old_name": "set_download_cmd",
            "new_name": "_set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5549"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code sets up an in-memory dataset for distributed training with a sleep time of 2 seconds for sending data between nodes.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "old_name": "_set_fleet_send_sleep_seconds",
            "new_name": "set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12343"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and enables parsing of instance IDs.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "old_name": "set_parse_ins_id",
            "new_name": "_set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6133"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a pipe command to run a Python script called \"my_script.py\".",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10123"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.1",
            "old_time": "2021-01-21",
            "new_time": "2021-03-02",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10298"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "This code initializes a dataset object for distributed training and sets the HDFS configuration for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "_set_hdfs_config",
            "new_name": "set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11052"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the HDFS configuration for the dataset with the specified file system name and user group information.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "set_hdfs_config",
            "new_name": "_set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5335"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11302"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset using the PaddlePaddle framework and prints out the description of the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "old_name": "desc",
            "new_name": "_desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5625"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "This code initializes a dataset object for distributed training and sets the HDFS configuration for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "_set_hdfs_config",
            "new_name": "set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10922"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10411"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.1",
            "old_time": "2021-11-02",
            "new_time": "2021-11-30",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11360"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12192"
        },
        {
            "dependency": "pyrsistent",
            "old_version": "==0.6.0",
            "new_version": "==0.6.1",
            "old_time": "2014-10-26",
            "new_time": "2014-10-31",
            "description": "The code defines an immutable data structure called Point with attributes x, y, and id_. It creates instances of Point with specified attribute values and allows for updating the attribute values using the set method.",
            "old_code": "Point = immutable('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint(x=1, y=2)\n\nPoint(x=3, y=2)\n\nPoint = immutable('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\nPoint(x=3, y=2, id_=17)\n\np.set(id_=18)",
            "new_code": "Point = pclass('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint = pclass('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\np.set(id_=18)",
            "old_name": "immutable",
            "new_name": "pclass",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20274"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "This code initializes a dataset object for distributed training and sets the HDFS configuration for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "_set_hdfs_config",
            "new_name": "set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10981"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10443"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the fleet send batch size to 800.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "old_name": "set_fleet_send_batch_size",
            "new_name": "_set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6498"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.1",
            "old_time": "2021-11-02",
            "new_time": "2021-11-30",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10410"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.2",
            "old_time": "2021-01-21",
            "new_time": "2021-04-08",
            "description": "The code creates an in-memory dataset for distributed training with the ability to parse instance IDs.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "old_name": "_set_parse_ins_id",
            "new_name": "set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11629"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and sets the number of threads to 12 for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "old_name": "_set_thread",
            "new_name": "set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10672"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.2",
            "old_time": "2021-01-21",
            "new_time": "2021-04-08",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and enables parsing of instance IDs.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "old_name": "set_parse_ins_id",
            "new_name": "_set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5950"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.0",
            "new_version": "==0.2.17",
            "old_time": "2020-09-24",
            "new_time": "2021-07-09",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2513"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.2",
            "old_time": "2021-01-21",
            "new_time": "2021-04-08",
            "description": "The code creates a dataset using PaddlePaddle's fluid framework and sets a pipe command to run a Python script called \"my_script.py\" for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "old_name": "set_pipe_command",
            "new_name": "_set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3670"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the HDFS configuration for the dataset with the specified file system name and user group information.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "set_hdfs_config",
            "new_name": "_set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5243"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "The code creates an in-memory dataset using PaddlePaddle framework.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "old_name": "set_parse_content",
            "new_name": "_set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6324"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "old_name": "set_batch_size",
            "new_name": "_set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3972"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and enables parsing of instance IDs.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "old_name": "set_parse_ins_id",
            "new_name": "_set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6134"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset using PaddlePaddle's fluid framework and sets a pipe command to run a Python script called \"my_script.py\" for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "old_name": "set_pipe_command",
            "new_name": "_set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3782"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the fleet send batch size to 800.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "old_name": "set_fleet_send_batch_size",
            "new_name": "_set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6514"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.0",
            "new_version": "==0.2.13",
            "old_time": "2020-09-24",
            "new_time": "2021-05-04",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2509"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.0",
            "new_version": "==1.0.6",
            "old_time": "2020-10-13",
            "new_time": "2020-11-11",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21325"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10352"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets a download command for the dataset to read from AFS (Alibaba File System).",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "old_name": "_set_download_cmd",
            "new_name": "set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11171"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11492"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "This code creates an in-memory dataset using PaddlePaddle framework and sets the number of queues to 12.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "old_name": "set_queue_num",
            "new_name": "_set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5943"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.0",
            "new_version": "==0.2.22",
            "old_time": "2020-09-24",
            "new_time": "2021-10-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2518"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.2",
            "old_time": "2021-01-21",
            "new_time": "2021-04-08",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the time interval for sending data to the distributed training fleet to 2 seconds.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "old_name": "set_fleet_send_sleep_seconds",
            "new_name": "_set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6520"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.2",
            "old_time": "2021-01-21",
            "new_time": "2021-04-08",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4050"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the variables 'data' and 'label' for use in the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_use_var([data, label])",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "old_name": "set_use_var",
            "new_name": "_set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4295"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4233"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11622"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the fleet send batch size to 800.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "old_name": "set_fleet_send_batch_size",
            "new_name": "_set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6499"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11433"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.0",
            "new_version": "==0.2.24",
            "old_time": "2020-09-24",
            "new_time": "2021-10-19",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2519"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "The code initializes an in-memory dataset for distributed training in PaddlePaddle framework and sets the merging strategy to merge data by line ID.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "old_name": "_set_merge_by_lineid",
            "new_name": "set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12573"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.1",
            "old_time": "2021-01-21",
            "new_time": "2021-03-02",
            "description": "The code sets up an in-memory dataset for distributed training with a sleep time of 2 seconds for sending data between nodes.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "old_name": "_set_fleet_send_sleep_seconds",
            "new_name": "set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12198"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a pipe command to run a Python script called \"my_script.py\".",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_9993"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "This code initializes a dataset object for distributed training and sets the HDFS configuration for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "_set_hdfs_config",
            "new_name": "set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11013"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11432"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "The code creates a dataset using the PaddlePaddle framework and prints out the description of the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "old_name": "desc",
            "new_name": "_desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5754"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.2",
            "old_time": "2021-05-13",
            "new_time": "2021-07-30",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11493"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the time interval for sending data to the distributed training fleet to 2 seconds.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "old_name": "set_fleet_send_sleep_seconds",
            "new_name": "_set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6665"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the variables 'data' and 'label' for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "new_code": "import paddle.base as base\npaddle.enable_static()\ndataset = base.DatasetFactory().create_dataset()\ndata = paddle.static.data(name=\"data\", shape=[None, 10, 10], dtype=\"int64\")\nlabel = paddle.static.data(name=\"label\", shape=[None, 1], dtype=\"int64\", lod_level=1)\ndataset.set_use_var([data, label])",
            "old_name": "_set_use_var",
            "new_name": "set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10824"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and enables parsing of instance IDs.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "old_name": "set_parse_ins_id",
            "new_name": "_set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6003"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.1",
            "old_time": "2021-01-21",
            "new_time": "2021-03-02",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and sets the number of threads to 12 for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "old_name": "_set_thread",
            "new_name": "set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10488"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.2",
            "old_time": "2021-01-21",
            "new_time": "2021-04-08",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the HDFS configuration for the dataset with the specified file system name and user group information.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "set_hdfs_config",
            "new_name": "_set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5190"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.0",
            "new_version": "==0.2.20",
            "old_time": "2020-09-24",
            "new_time": "2021-09-03",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2516"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "This code initializes a dataset object for distributed training and sets the HDFS configuration for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "_set_hdfs_config",
            "new_name": "set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10924"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.1",
            "old_time": "2021-11-02",
            "new_time": "2021-11-30",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a pipe command to run a Python script called \"my_script.py\".",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10051"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "This code creates an in-memory dataset using PaddlePaddle framework and sets the number of queues to 12.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "old_name": "set_queue_num",
            "new_name": "_set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5944"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.1",
            "old_time": "2021-11-02",
            "new_time": "2021-11-30",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets a download command for the dataset to read from AFS (Alibaba File System).",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "old_name": "_set_download_cmd",
            "new_name": "set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11170"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.2",
            "old_time": "2021-05-13",
            "new_time": "2021-07-30",
            "description": "The code sets up an in-memory dataset for distributed training with a sleep time of 2 seconds for sending data between nodes.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "old_name": "_set_fleet_send_sleep_seconds",
            "new_name": "set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12253"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10467"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.2",
            "old_time": "2023-06-19",
            "new_time": "2023-10-19",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the variables 'data' and 'label' for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "new_code": "import paddle.base as base\npaddle.enable_static()\ndataset = base.DatasetFactory().create_dataset()\ndata = paddle.static.data(name=\"data\", shape=[None, 10, 10], dtype=\"int64\")\nlabel = paddle.static.data(name=\"label\", shape=[None, 1], dtype=\"int64\", lod_level=1)\ndataset.set_use_var([data, label])",
            "old_name": "_set_use_var",
            "new_name": "set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10863"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "This code creates an in-memory dataset using PaddlePaddle framework and sets the number of queues to 12.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "old_name": "set_queue_num",
            "new_name": "_set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5904"
        },
        {
            "dependency": "librosa",
            "old_version": "==0.6.0",
            "new_version": "==0.6.3",
            "old_time": "2018-02-17",
            "new_time": "2019-02-13",
            "description": "Calculate the root mean square energy of the audio signal y.",
            "old_code": "y, sr = librosa.load(librosa.util.example_audio_file())\nlibrosa.feature.rmse(y=y)\n\nS, phase = librosa.magphase(librosa.stft(y))\nrms = librosa.feature.rmse(S=S)\n\nS = librosa.magphase(librosa.stft(y, window=np.ones, center=False))[0]\nlibrosa.feature.rmse(S=S)",
            "new_code": "y, sr = librosa.load(librosa.util.example_audio_file())\nlibrosa.feature.rms(y=y)\n\nS, phase = librosa.magphase(librosa.stft(y))\nrms = librosa.feature.rms(S=S)\n\nimport matplotlib.pyplot as plt\nplt.figure()\nplt.subplot(2, 1, 1)\nplt.semilogy(rms.T, label='RMS Energy')\nplt.xticks([])\nplt.xlim([0, rms.shape[-1]])\nplt.legend(loc='best')\nplt.subplot(2, 1, 2)\nlibrosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),\n...                          y_axis='log', x_axis='time')\nplt.title('log Power spectrogram')\nplt.tight_layout()\n\nS = librosa.magphase(librosa.stft(y, window=np.ones, center=False))[0]\nlibrosa.feature.rms(S=S)",
            "old_name": "rmse",
            "new_name": "rms",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3490"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "The code creates a dataset using PaddlePaddle's fluid framework and sets a pipe command to run a Python script called \"my_script.py\" for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "old_name": "set_pipe_command",
            "new_name": "_set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3839"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the HDFS configuration for the dataset with the specified file system name and user group information.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "set_hdfs_config",
            "new_name": "_set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5373"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and sets the number of threads to 12 for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "old_name": "_set_thread",
            "new_name": "set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10658"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10482"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code creates an in-memory dataset using PaddlePaddle framework.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "old_name": "set_parse_content",
            "new_name": "_set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6284"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.2",
            "old_time": "2022-05-05",
            "new_time": "2022-08-15",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11584"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "The code initializes an in-memory dataset for distributed training in PaddlePaddle framework and sets the merging strategy to merge data by line ID.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "old_name": "_set_merge_by_lineid",
            "new_name": "set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12558"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11494"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.0",
            "new_version": "==1.0.4",
            "old_time": "2020-10-13",
            "new_time": "2020-10-27",
            "description": "Calculate the mean absolute error (MAE) between two tensors x and y.",
            "old_code": "mae = nn.L1Loss(reduction='mean')\nx = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmae_value = mae(x, y)\nprint(mae_value)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmean_absolute_error(x, y)\ntensor(0.2500)",
            "old_name": "mae",
            "new_name": "mean_absolute_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20795"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.1",
            "old_time": "2021-01-21",
            "new_time": "2021-03-02",
            "description": "The code creates a dataset using the PaddlePaddle framework and prints out the description of the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "old_name": "desc",
            "new_name": "_desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5569"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4219"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.1",
            "old_time": "2022-11-16",
            "new_time": "2022-12-05",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets a download command for the dataset to read from AFS (Alibaba File System).",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "old_name": "_set_download_cmd",
            "new_name": "set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11227"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.0",
            "new_version": "==0.2.19",
            "old_time": "2020-09-24",
            "new_time": "2021-08-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2515"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.0",
            "new_version": "==2.4.2",
            "old_time": "2022-11-16",
            "new_time": "2023-02-15",
            "description": "This code creates an in-memory dataset using PaddlePaddle framework and sets the number of queues to 12.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "old_name": "set_queue_num",
            "new_name": "_set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5929"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a pipe command to run a Python script called \"my_script.py\".",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10084"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the HDFS configuration for the dataset with the specified file system name and user group information.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "set_hdfs_config",
            "new_name": "_set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5245"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.0",
            "new_version": "==2.2.2",
            "old_time": "2021-11-02",
            "new_time": "2022-01-18",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12121"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.0",
            "new_version": "==2.3.1",
            "old_time": "2022-05-05",
            "new_time": "2022-07-01",
            "description": "The code creates a dataset using the PaddlePaddle framework and prints out the description of the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "old_name": "desc",
            "new_name": "_desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5714"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.0",
            "new_version": "==2.5.1",
            "old_time": "2023-06-19",
            "new_time": "2023-07-25",
            "description": "The code creates a dataset using PaddlePaddle's fluid framework and sets a pipe command to run a Python script called \"my_script.py\" for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "old_name": "set_pipe_command",
            "new_name": "_set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3853"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "The code sets up an in-memory dataset for distributed training with a sleep time of 2 seconds for sending data between nodes.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "old_name": "_set_fleet_send_sleep_seconds",
            "new_name": "set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12254"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.1",
            "old_time": "2021-05-13",
            "new_time": "2021-06-23",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and sets the number of threads to 12 for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "old_name": "_set_thread",
            "new_name": "set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10542"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.0",
            "new_version": "==2.0.2",
            "old_time": "2021-01-21",
            "new_time": "2021-04-08",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the variables 'data' and 'label' for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "new_code": "import paddle.base as base\npaddle.enable_static()\ndataset = base.DatasetFactory().create_dataset()\ndata = paddle.static.data(name=\"data\", shape=[None, 10, 10], dtype=\"int64\")\nlabel = paddle.static.data(name=\"label\", shape=[None, 1], dtype=\"int64\", lod_level=1)\ndataset.set_use_var([data, label])",
            "old_name": "_set_use_var",
            "new_name": "set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10679"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.0",
            "new_version": "==2.1.3",
            "old_time": "2021-05-13",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset using PaddlePaddle's fluid framework and sets a pipe command to run a Python script called \"my_script.py\" for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "old_name": "set_pipe_command",
            "new_name": "_set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3725"
        },
        {
            "dependency": "pyrsistent",
            "old_version": "==0.7.1",
            "new_version": "==0.14.3",
            "old_time": "2015-01-17",
            "new_time": "2018-06-11",
            "description": "The code defines a class named Point with attributes x, y, and id_. It creates an instance p of Point with x=1, y=2. It then updates the x attribute of p to 3. Another instance p is created with x=1, y=2, and id_=17. The id_ attribute of p is then updated to 18.",
            "old_code": "Point = pclass('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint = pclass('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\np.set(id_=18)",
            "new_code": "Point = immutable('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint = immutable('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\np.set(id_=18)",
            "old_name": "pclass",
            "new_name": "immutable",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20517"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.15.3",
            "new_version": "==2.4.0",
            "old_time": "2020-05-14",
            "new_time": "2020-12-12",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46416"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.7.6",
            "new_version": "==2.0.6",
            "old_time": "2022-09-13",
            "new_time": "2023-07-21",
            "description": "The code registers different distributed data parallel communication hooks for a deep learning model. The hooks include fp16_compress_hook for compressing gradients, powerSGD_hook for a specific communication optimization technique, and post_localSGD_hook for another communication optimization technique. Additionally, it demonstrates combining fp16_compress_wrapper with other communication hooks for further optimization.",
            "old_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "new_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "old_name": "register_ddp_comm_hook",
            "new_name": "_register_ddp_comm_hook",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_24427"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.2.6",
            "new_version": "==2.1.2",
            "old_time": "2021-03-30",
            "new_time": "2023-11-15",
            "description": "The code loads and reads the README file located in the project root directory and displays its content in HTML format with center alignment.",
            "old_code": "_load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "new_code": "load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "old_name": "_load_readme_description",
            "new_name": "load_readme_description",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21683"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.5.1",
            "new_version": "==2.8.4",
            "old_time": "2018-03-20",
            "new_time": "2022-11-15",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45523"
        },
        {
            "dependency": "streamlit",
            "old_version": "==1.5.1",
            "new_version": "==1.28.0",
            "old_time": "2022-02-09",
            "new_time": "2023-10-25",
            "description": "This code generates a random 10x5 DataFrame using NumPy and Pandas, and then displays it as an arrow table using Streamlit.",
            "old_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n   np.random.randn(10, 5),\n   columns=(\"col %d\" % i for i in range(5)))\n\nst._arrow_table(df)",
            "new_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.random.randn(10, 5), columns=(\"col %d\" % i for i in range(5)))\n\nst.table(df)",
            "old_name": "_arrow_table",
            "new_name": "table",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44120"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.23.4",
            "new_version": "==2.0.2",
            "old_time": "2018-08-03",
            "new_time": "2023-05-28",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17944"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.3.2",
            "new_version": "==2.1.3",
            "old_time": "2021-05-19",
            "new_time": "2023-12-20",
            "description": "The code loads and reads the README file located in the project root directory and displays its content in HTML format with center alignment.",
            "old_code": "_load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "new_code": "load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "old_name": "_load_readme_description",
            "new_name": "load_readme_description",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21838"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.2",
            "new_version": "==2.6.0",
            "old_time": "2021-07-30",
            "new_time": "2023-12-21",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_14576"
        },
        {
            "dependency": "pyrsistent",
            "old_version": "==0.6.3",
            "new_version": "==0.11.0",
            "old_time": "2014-11-27",
            "new_time": "2015-07-11",
            "description": "The code defines a class named Point with attributes x, y, and id_. It creates an instance p of Point with x=1, y=2. It then updates the x attribute of p to 3. Another instance p is created with x=1, y=2, and id_=17. The id_ attribute of p is then updated to 18.",
            "old_code": "Point = pclass('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint = pclass('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\np.set(id_=18)",
            "new_code": "Point = immutable('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint = immutable('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\np.set(id_=18)",
            "old_name": "pclass",
            "new_name": "immutable",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20391"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.2",
            "new_version": "==1.4.8",
            "old_time": "2020-10-15",
            "new_time": "2021-09-22",
            "description": "Calculate the mean absolute error (MAE) between two tensors x and y.",
            "old_code": "mae = nn.L1Loss(reduction='mean')\nx = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmae_value = mae(x, y)\nprint(mae_value)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmean_absolute_error(x, y)\ntensor(0.2500)",
            "old_name": "mae",
            "new_name": "mean_absolute_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20925"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.2",
            "new_version": "==2.5.2",
            "old_time": "2021-04-08",
            "new_time": "2023-10-19",
            "description": "The code initializes an in-memory dataset for distributed training in PaddlePaddle framework and sets the merging strategy to merge data by line ID.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "old_name": "_set_merge_by_lineid",
            "new_name": "set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12440"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.3",
            "new_version": "==2.3.1",
            "old_time": "2021-09-10",
            "new_time": "2022-07-01",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the fleet send batch size to 800.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "old_name": "set_fleet_send_batch_size",
            "new_name": "_set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6432"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.3",
            "new_version": "==1.5.0",
            "old_time": "2020-03-18",
            "new_time": "2022-09-19",
            "description": "The code is inferring the data type of an integer value with 64-bit precision.",
            "old_code": "maybe_infer_dtype_type(Foo(np.dtype(\"i8\")))",
            "new_code": "_maybe_infer_dtype_type(Foo(np.dtype(\"i8\")))",
            "old_name": "maybe_infer_dtype_type",
            "new_name": "_maybe_infer_dtype_type",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_19738"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.2.1",
            "new_version": "==2.8.4",
            "old_time": "2017-06-30",
            "new_time": "2022-11-15",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45188"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.2.5",
            "new_version": "==1.4.1",
            "old_time": "2021-06-22",
            "new_time": "2022-02-12",
            "description": "The code performs resampling on a pandas Series or DataFrame with a specified frequency and backfills missing values within the resampled intervals.",
            "old_code": "s = pd.Series([1, 2, 3],\n              index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01-01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').backfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').backfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n                  index=pd.date_range('20180101', periods=3,\n                                      freq='h'))\ndf\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').backfill()\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 00:30:00  NaN  3\n2018-01-01 01:00:00  NaN  3\n2018-01-01 01:30:00  6.0  5\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('15min').backfill(limit=2)\n                   a    b\n2018-01-01 00:00:00  2.0  1.0\n2018-01-01 00:15:00  NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-01 02:00:00   6.0   5.0",
            "new_code": "s = pd.Series([1, 2, 3],\n...               index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01:01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').bfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').bfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n...                   index=pd.date_range('20180101', periods=3,\n...                                       freq='h'))\ndf\n                       a    b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').bfill()\n                       a    b\n2018-01-01 00:00:00  2.0   1\n2018-01-01 00:30:00   NaN   3\n2018-01-01 01:00:00   NaN   3\n2018-01-01 01:30:00   6.0   5\n2018-01-01 02:00:00   6.0   5\n\ndf.resample('15min').bfill(limit=2)\n                       a    b\n2018-01-01 00:00:00   2.0   1.0\n2018-01-01 00:15:00   NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-02 02:00:00   6.0   5.0",
            "old_name": "backfill",
            "new_name": "bfill",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_19321"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.1.5",
            "new_version": "==1.5.3",
            "old_time": "2020-12-07",
            "new_time": "2023-01-19",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18530"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.4",
            "new_version": "==1.3.1",
            "old_time": "2020-05-28",
            "new_time": "2021-07-25",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18300"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.25.2",
            "new_version": "==1.1.0",
            "old_time": "2019-10-18",
            "new_time": "2020-07-28",
            "description": "The code may potentially modify lambda functions named 'sum' to avoid conflicts.",
            "old_code": "_maybe_mangle_lambdas('sum')\\n\\n_maybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "new_code": "maybe_mangle_lambdas('sum')\n\nmaybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "old_name": "_maybe_mangle_lambdas",
            "new_name": "maybe_mangle_lambdas",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17158"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.1.5",
            "new_version": "==1.3.0",
            "old_time": "2020-12-07",
            "new_time": "2021-07-02",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18516"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.50.2",
            "new_version": "==1.11.0",
            "old_time": "2019-11-11",
            "new_time": "2022-07-13",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35145"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.2",
            "new_version": "==2.4.0",
            "old_time": "2021-07-30",
            "new_time": "2022-11-16",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the fleet send batch size to 800.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "old_name": "set_fleet_send_batch_size",
            "new_name": "_set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6421"
        },
        {
            "dependency": "pyrsistent",
            "old_version": "==0.6.1",
            "new_version": "==0.11.7",
            "old_time": "2014-10-31",
            "new_time": "2015-10-03",
            "description": "The code defines a class named Point with attributes x, y, and id_. It creates an instance p of Point with x=1, y=2. It then updates the x attribute of p to 3. Another instance p is created with x=1, y=2, and id_=17. The id_ attribute of p is then updated to 18.",
            "old_code": "Point = pclass('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint = pclass('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\np.set(id_=18)",
            "new_code": "Point = immutable('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint = immutable('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\np.set(id_=18)",
            "old_name": "pclass",
            "new_name": "immutable",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20294"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.73.1",
            "new_version": "==1.23.1",
            "old_time": "2020-12-21",
            "new_time": "2023-06-02",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37237"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.43.2",
            "new_version": "==1.18.0",
            "old_time": "2019-07-10",
            "new_time": "2023-02-09",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30517"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.69",
            "new_version": "==0.2.16",
            "old_time": "2020-06-03",
            "new_time": "2021-06-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1936"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.47.4",
            "new_version": "==1.27.2",
            "old_time": "2019-10-05",
            "new_time": "2023-10-03",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30873"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.81.1",
            "new_version": "==1.19.0",
            "old_time": "2021-05-04",
            "new_time": "2023-02-23",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37792"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.7.1",
            "new_version": "==2.2.3",
            "old_time": "2018-05-04",
            "new_time": "2021-06-10",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45694"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.15.4",
            "new_version": "==2.4.4",
            "old_time": "2020-09-22",
            "new_time": "2021-10-30",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46460"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.1",
            "new_version": "==1.1.1",
            "old_time": "2020-10-14",
            "new_time": "2020-12-15",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21065"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.25.2",
            "new_version": "==1.3.2",
            "old_time": "2019-10-18",
            "new_time": "2021-08-15",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18115"
        },
        {
            "dependency": "datasets",
            "old_version": "==1.15.1",
            "new_version": "==2.16.0",
            "old_time": "2021-11-02",
            "new_time": "2023-12-22",
            "description": "This code resolves patterns locally or by URLs for YAML files in the \"src\" directory and its subdirectories.",
            "old_code": "from datasets.data_files import resolve_patterns_locally_or_by_urls\n\nbase_path = \".\"\nresolve_patterns_locally_or_by_urls(base_path, [\"src/**/*.yaml\"])",
            "new_code": "from datasets.data_files import resolve_pattern\nbase_path = \".\"\nresolve_pattern(\"docs/**/*.py\", base_path)",
            "old_name": "resolve_patterns_locally_or_by_urls",
            "new_name": "resolve_pattern",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_342"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.65.2",
            "new_version": "==1.10.0",
            "old_time": "2020-08-14",
            "new_time": "2022-06-01",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36488"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.62",
            "new_version": "==0.3.7",
            "old_time": "2020-03-22",
            "new_time": "2022-04-15",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1507"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.8.6",
            "new_version": "==2.2.0",
            "old_time": "2022-12-21",
            "new_time": "2024-02-07",
            "description": "The code registers different distributed data parallel communication hooks for a deep learning model. The hooks include fp16_compress_hook for compressing gradients, powerSGD_hook for a specific communication optimization technique, and post_localSGD_hook for another communication optimization technique. Additionally, it demonstrates combining fp16_compress_wrapper with other communication hooks for further optimization.",
            "old_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "new_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "old_name": "register_ddp_comm_hook",
            "new_name": "_register_ddp_comm_hook",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_24564"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.5.8",
            "new_version": "==2.0.1",
            "old_time": "2022-01-05",
            "new_time": "2023-03-30",
            "description": "The code sets environment variables for the PL Trainer with the number of GPUs as 42 and a specific value for another variable. It then parses the environment variables for the Trainer and returns a Namespace object with the specified GPU value.",
            "old_code": "import os\nos.environ[\"PL_TRAINER_GPUS\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\nparse_env_variables(Trainer)\nNamespace(gpus=42)",
            "new_code": "import os\nos.environ[\"PL_TRAINER_DEVICES\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\n_parse_env_variables(Trainer)\nNamespace(devices=42)",
            "old_name": "parse_env_variables",
            "new_name": "_parse_env_variables",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_23224"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.72",
            "new_version": "==0.2.16",
            "old_time": "2020-06-28",
            "new_time": "2021-06-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2128"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.5",
            "new_version": "==0.4.14",
            "old_time": "2020-10-26",
            "new_time": "2023-07-27",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2882"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.5.1",
            "old_time": "2021-06-23",
            "new_time": "2023-07-25",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the HDFS configuration for the dataset with the specified file system name and user group information.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "set_hdfs_config",
            "new_name": "_set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5271"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.1.0",
            "old_time": "2021-03-02",
            "new_time": "2021-05-13",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets it to merge data by line ID.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "old_name": "set_merge_by_lineid",
            "new_name": "_set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6729"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==0.5.3",
            "new_version": "==2.2.0",
            "old_time": "2019-11-06",
            "new_time": "2024-02-07",
            "description": "The code registers different distributed data parallel communication hooks for a deep learning model. The hooks include fp16_compress_hook for compressing gradients, powerSGD_hook for a specific communication optimization technique, and post_localSGD_hook for another communication optimization technique. Additionally, it demonstrates combining fp16_compress_wrapper with other communication hooks for further optimization.",
            "old_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "new_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "old_name": "register_ddp_comm_hook",
            "new_name": "_register_ddp_comm_hook",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_23732"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.64",
            "new_version": "==0.4.18",
            "old_time": "2020-04-21",
            "new_time": "2023-10-07",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1669"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.84.1",
            "new_version": "==1.30.0",
            "old_time": "2021-07-12",
            "new_time": "2024-01-11",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_43808"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.8.5",
            "new_version": "==2.0.2",
            "old_time": "2022-12-15",
            "new_time": "2023-04-24",
            "description": "The code registers different distributed data parallel communication hooks for a deep learning model. The hooks include fp16_compress_hook for compressing gradients, powerSGD_hook for a specific communication optimization technique, and post_localSGD_hook for another communication optimization technique. Additionally, it demonstrates combining fp16_compress_wrapper with other communication hooks for further optimization.",
            "old_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "new_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "old_name": "register_ddp_comm_hook",
            "new_name": "_register_ddp_comm_hook",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_24535"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.3",
            "new_version": "==2.3.0",
            "old_time": "2021-09-10",
            "new_time": "2022-05-05",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets it to merge data by line ID.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "old_name": "set_merge_by_lineid",
            "new_name": "_set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6811"
        },
        {
            "dependency": "pyrsistent",
            "old_version": "==0.6.1",
            "new_version": "==0.12.2",
            "old_time": "2014-10-31",
            "new_time": "2017-05-30",
            "description": "The code defines a class named Point with attributes x, y, and id_. It creates an instance p of Point with x=1, y=2. It then updates the x attribute of p to 3. Another instance p is created with x=1, y=2, and id_=17. The id_ attribute of p is then updated to 18.",
            "old_code": "Point = pclass('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint = pclass('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\np.set(id_=18)",
            "new_code": "Point = immutable('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint = immutable('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\np.set(id_=18)",
            "old_name": "pclass",
            "new_name": "immutable",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20303"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.6.5",
            "new_version": "==2.0.3",
            "old_time": "2022-07-12",
            "new_time": "2023-06-07",
            "description": "The code loads and reads the README file located in the project root directory and displays its content in HTML format with center alignment.",
            "old_code": "_load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "new_code": "load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "old_name": "_load_readme_description",
            "new_name": "load_readme_description",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_22554"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.1",
            "new_version": "==1.4.1",
            "old_time": "2020-10-14",
            "new_time": "2021-08-03",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21402"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.71",
            "new_version": "==0.4.22",
            "old_time": "2020-06-26",
            "new_time": "2023-12-14",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2121"
        },
        {
            "dependency": "MarkupSafe",
            "old_version": "==0.23",
            "new_version": "==2.0.1",
            "old_time": "2014-05-08",
            "new_time": "2021-05-18",
            "description": "The code is escaping special characters in a given string to their corresponding HTML entities.",
            "old_code": "value = escape('<User 1>')\nvalue\nMarkup('&lt;User 1&gt;')\nescape(str(value))\nMarkup('&amp;lt;User 1&amp;gt;')\nescape(soft_unicode(value))\nMarkup('&lt;User 1&gt;')",
            "new_code": "value = escape(\"<User 1>\")\nvalue\nMarkup('&lt;User 1&gt;')\nescape(str(value))\nMarkup('&amp;lt;User 1&amp;gt;')\nescape(soft_str(value))\nMarkup('&lt;User 1&gt;')",
            "old_name": "soft_unicode",
            "new_name": "soft_str",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3638"
        },
        {
            "dependency": "imageio",
            "old_version": "==2.1.2",
            "new_version": "==2.26.0",
            "old_time": "2017-02-02",
            "new_time": "2023-02-27",
            "description": "The code parses a byte string containing information about ImageJ software and returns a dictionary with keys 'ImageJ', 'images', and 'hyperstack' mapped to their respective values.",
            "old_code": "description = b'ImageJ=1.11a\\nimages=510\\nhyperstack=true\\n'\nimagej_description_dict(description)  # doctest: +SKIP\n{'ImageJ': '1.11a', 'images': 510, 'hyperstack': True}",
            "new_code": "description = 'ImageJ=1.11a\\nimages=510\\nhyperstack=true\\n'\nimagej_description_metadata(description)\n{'ImageJ': '1.11a', 'images': 510, 'hyperstack': True}",
            "old_name": "imagej_description_dict",
            "new_name": "imagej_description_metadata",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1272"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.74.1",
            "new_version": "==1.3.1",
            "old_time": "2021-01-07",
            "new_time": "2021-12-28",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_43117"
        },
        {
            "dependency": "imageio",
            "old_version": "==1.5",
            "new_version": "==2.10.5",
            "old_time": "2016-01-30",
            "new_time": "2021-11-17",
            "description": "The code generates RGB values from the given data using different bit lengths for each color channel.",
            "old_code": "data = struct.pack('BBBB', 0x21, 0x08, 0xff, 0xff)\nprint(unpackrgb(data, '<B', (5, 6, 5), False))\nprint(unpackrgb(data, '<B', (5, 6, 5)))\nprint(unpackrgb(data, '<B', (5, 5, 5)))",
            "new_code": "data = struct.pack('BBBB', 0x21, 0x08, 0xff, 0xff)\nprint(unpack_rgb(data, '<B', (5, 6, 5), False))\nprint(unpack_rgb(data, '<B', (5, 6, 5)))\nprint(unpack_rgb(data, '<B', (5, 5, 5)))",
            "old_name": "unpackrgb",
            "new_name": "unpack_rgb",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_840"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.5",
            "new_version": "==1.8.0",
            "old_time": "2020-05-06",
            "new_time": "2021-10-29",
            "description": "The code runs a function `run_me` for 100 iterations, where it sleeps for 1 second in each iteration and logs the values \"hello\" as \"world\" and \"ray\" as \"tune\" using the `track.log` function. The function is executed using Ray Tune for analysis.",
            "old_code": "import time\nfrom ray import tune\nfrom ray.tune import track\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        track.log(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "new_code": "import time\nfrom ray import tune\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        tune.report(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "old_name": "log",
            "new_name": "report",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29400"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.4.8",
            "new_version": "==2.1.4",
            "old_time": "2021-09-22",
            "new_time": "2024-01-31",
            "description": "The code loads and reads the README file located in the project root directory and displays its content in HTML format with center alignment.",
            "old_code": "_load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "new_code": "load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "old_name": "_load_readme_description",
            "new_name": "load_readme_description",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_22169"
        },
        {
            "dependency": "streamlit",
            "old_version": "==1.23.1",
            "new_version": "==1.29.0",
            "old_time": "2023-06-02",
            "new_time": "2023-11-30",
            "description": "The code generates a scatter plot chart using Streamlit and displays it using the Arrow Vega-Lite chart. The chart visualizes random data points with three variables 'a', 'b', and 'c', where 'a' and 'b' are plotted on the x and y axes as quantitative values, and 'c' is used for both the size and color of the data points.",
            "old_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n    np.random.randn(200, 3),\n    columns=['a', 'b', 'c'])\n\nst._arrow_vega_lite_chart(df, {\n    'mark': {'type': 'circle', 'tooltip': True},\n    'encoding': {\n        'x': {'field': 'a', 'type': 'quantitative'},\n        'y': {'field': 'b', 'type': 'quantitative'},\n        'size': {'field': 'c', 'type': 'quantitative'},\n        'color': {'field': 'c', 'type': 'quantitative'},\n    },\n})",
            "new_code": "import streamlit as st\nimport pandas as pd\nimport numpy as np\n\nchart_data = pd.DataFrame(np.random.randn(200, 3), columns=[\"a\", \"b\", \"c\"])\n\nst.vega_lite_chart(\n    chart_data,\n    {\n        \"mark\": {\"type\": \"circle\", \"tooltip\": True},\n        \"encoding\": {\n            \"x\": {\"field\": \"a\", \"type\": \"quantitative\"},\n            \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n            \"size\": {\"field\": \"c\", \"type\": \"quantitative\"},\n            \"color\": {\"field\": \"c\", \"type\": \"quantitative\"},\n        },\n    },\n)",
            "old_name": "_arrow_vega_lite_chart",
            "new_name": "vega_lite_chart",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44676"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.69.2",
            "new_version": "==1.24.0",
            "old_time": "2020-10-16",
            "new_time": "2023-06-27",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_32681"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.9",
            "new_version": "==0.3.7",
            "old_time": "2021-01-27",
            "new_time": "2022-04-15",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3107"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.4.1",
            "old_time": "2021-06-23",
            "new_time": "2022-12-05",
            "description": "The code sets up an in-memory dataset for distributed training with a sleep time of 2 seconds for sending data between nodes.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "old_name": "_set_fleet_send_sleep_seconds",
            "new_name": "set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12277"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.5.10",
            "new_version": "==2.0.5",
            "old_time": "2022-02-09",
            "new_time": "2023-07-10",
            "description": "The code sets environment variables for the PL Trainer with the number of GPUs as 42 and a specific value for another variable. It then parses the environment variables for the Trainer and returns a Namespace object with the specified GPU value.",
            "old_code": "import os\nos.environ[\"PL_TRAINER_GPUS\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\nparse_env_variables(Trainer)\nNamespace(gpus=42)",
            "new_code": "import os\nos.environ[\"PL_TRAINER_DEVICES\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\n_parse_env_variables(Trainer)\nNamespace(devices=42)",
            "old_name": "parse_env_variables",
            "new_name": "_parse_env_variables",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_23260"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.4.1",
            "new_version": "==1.15.4",
            "old_time": "2017-12-08",
            "new_time": "2020-09-22",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45344"
        },
        {
            "dependency": "MarkupSafe",
            "old_version": "==0.15",
            "new_version": "==2.1.4",
            "old_time": "2011-07-20",
            "new_time": "2024-01-19",
            "description": "The code is escaping special characters in a given string to their corresponding HTML entities.",
            "old_code": "value = escape('<User 1>')\nvalue\nMarkup('&lt;User 1&gt;')\nescape(str(value))\nMarkup('&amp;lt;User 1&amp;gt;')\nescape(soft_unicode(value))\nMarkup('&lt;User 1&gt;')",
            "new_code": "value = escape(\"<User 1>\")\nvalue\nMarkup('&lt;User 1&gt;')\nescape(str(value))\nMarkup('&amp;lt;User 1&amp;gt;')\nescape(soft_str(value))\nMarkup('&lt;User 1&gt;')",
            "old_name": "soft_unicode",
            "new_name": "soft_str",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3579"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.60",
            "new_version": "==0.4.2",
            "old_time": "2020-03-17",
            "new_time": "2023-01-25",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1398"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.20.1",
            "new_version": "==2.2.0",
            "old_time": "2017-05-05",
            "new_time": "2024-01-20",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17641"
        },
        {
            "dependency": "ray",
            "old_version": "==0.6.3",
            "new_version": "==1.5.0",
            "old_time": "2019-02-07",
            "new_time": "2021-07-23",
            "description": "This code filters nodes based on the node type \"worker\" in a provider.",
            "old_code": "provider.nodes({TAG_RAY_NODE_TYPE: \"worker\"})",
            "new_code": "provider.non_terminated_nodes({TAG_RAY_NODE_TYPE: \"worker\"})\n[\"node-1\", \"node-2\"]",
            "old_name": "nodes",
            "new_name": "non_terminated_nodes",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_25681"
        },
        {
            "dependency": "pyrsistent",
            "old_version": "==0.9.1",
            "new_version": "==0.12.3",
            "old_time": "2015-02-25",
            "new_time": "2017-06-04",
            "description": "The code defines a class named Point with attributes x, y, and id_. It creates an instance p of Point with x=1, y=2. It then updates the x attribute of p to 3. Another instance p is created with x=1, y=2, and id_=17. The id_ attribute of p is then updated to 18.",
            "old_code": "Point = pclass('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint = pclass('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\np.set(id_=18)",
            "new_code": "Point = immutable('x, y', name='Point')\n\np = Point(1, 2)\n\np2 = p.set(x=3)\n\nPoint = immutable('x, y, id_', name='Point')\n\np = Point(1, 2, id_=17)\n\np.set(x=3)\n\np.set(id_=18)",
            "old_name": "pclass",
            "new_name": "immutable",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20668"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.8.2",
            "new_version": "==2.0.4",
            "old_time": "2022-11-18",
            "new_time": "2023-06-22",
            "description": "The code sets environment variables for the PL Trainer with the number of GPUs as 42 and a specific value for another variable. It then parses the environment variables for the Trainer and returns a Namespace object with the specified GPU value.",
            "old_code": "import os\nos.environ[\"PL_TRAINER_GPUS\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\nparse_env_variables(Trainer)\nNamespace(gpus=42)",
            "new_code": "import os\nos.environ[\"PL_TRAINER_DEVICES\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\n_parse_env_variables(Trainer)\nNamespace(devices=42)",
            "old_name": "parse_env_variables",
            "new_name": "_parse_env_variables",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_23531"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==2.0.1",
            "new_version": "==2.7.2",
            "old_time": "2020-01-22",
            "new_time": "2022-05-12",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46592"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.43.2",
            "new_version": "==1.3.1",
            "old_time": "2019-07-10",
            "new_time": "2021-12-28",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30492"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.5.2",
            "old_time": "2021-06-23",
            "new_time": "2023-10-19",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets it to merge data by line ID.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "old_name": "set_merge_by_lineid",
            "new_name": "_set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6792"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.1.1",
            "new_version": "==2.0.2",
            "old_time": "2020-08-20",
            "new_time": "2023-05-28",
            "description": "The code is inferring the data type of an integer value with 64-bit precision.",
            "old_code": "maybe_infer_dtype_type(Foo(np.dtype(\"i8\")))",
            "new_code": "_maybe_infer_dtype_type(Foo(np.dtype(\"i8\")))",
            "old_name": "maybe_infer_dtype_type",
            "new_name": "_maybe_infer_dtype_type",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_19800"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==2.1.3",
            "new_version": "==2.4.4",
            "old_time": "2021-01-04",
            "new_time": "2021-10-30",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46857"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.3",
            "new_version": "==1.5.3",
            "old_time": "2020-03-18",
            "new_time": "2023-01-19",
            "description": "The code may potentially modify lambda functions named 'sum' to avoid conflicts.",
            "old_code": "_maybe_mangle_lambdas('sum')\\n\\n_maybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "new_code": "maybe_mangle_lambdas('sum')\n\nmaybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "old_name": "_maybe_mangle_lambdas",
            "new_name": "maybe_mangle_lambdas",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17369"
        },
        {
            "dependency": "ray",
            "old_version": "==0.5.3",
            "new_version": "==1.13.0",
            "old_time": "2018-09-25",
            "new_time": "2022-06-01",
            "description": "This code filters nodes based on the node type \"worker\" in a provider.",
            "old_code": "provider.nodes({TAG_RAY_NODE_TYPE: \"worker\"})",
            "new_code": "provider.non_terminated_nodes({TAG_RAY_NODE_TYPE: \"worker\"})\n[\"node-1\", \"node-2\"]",
            "old_name": "nodes",
            "new_name": "non_terminated_nodes",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_25221"
        },
        {
            "dependency": "ray",
            "old_version": "==0.7.5",
            "new_version": "==2.0.1",
            "old_time": "2019-09-17",
            "new_time": "2022-10-07",
            "description": "The code runs a function `run_me` for 100 iterations, where it sleeps for 1 second in each iteration and logs the values \"hello\" as \"world\" and \"ray\" as \"tune\" using the `track.log` function. The function is executed using Ray Tune for analysis.",
            "old_code": "import time\nfrom ray import tune\nfrom ray.tune import track\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        track.log(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "new_code": "import time\nfrom ray import tune\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        tune.report(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "old_name": "log",
            "new_name": "report",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29259"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.1",
            "new_version": "==2.5.1",
            "old_time": "2022-07-01",
            "new_time": "2023-07-25",
            "description": "The code creates an in-memory dataset using the PaddlePaddle framework with the ability to parse content.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "old_name": "_set_parse_content",
            "new_name": "set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11977"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.81.1",
            "new_version": "==1.27.2",
            "old_time": "2021-05-04",
            "new_time": "2023-10-03",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_37803"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.4.8",
            "new_version": "==2.1.4",
            "old_time": "2021-09-22",
            "new_time": "2024-01-31",
            "description": "The code registers different distributed data parallel communication hooks for a deep learning model. The hooks include fp16_compress_hook for compressing gradients, powerSGD_hook for a specific communication optimization technique, and post_localSGD_hook for another communication optimization technique. Additionally, it demonstrates combining fp16_compress_wrapper with other communication hooks for further optimization.",
            "old_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "new_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "old_name": "register_ddp_comm_hook",
            "new_name": "_register_ddp_comm_hook",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_24035"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.2.10",
            "new_version": "==2.0.0",
            "old_time": "2021-04-23",
            "new_time": "2023-03-15",
            "description": "The code sets environment variables for the PL Trainer with the number of GPUs as 42 and a specific value for another variable. It then parses the environment variables for the Trainer and returns a Namespace object with the specified GPU value.",
            "old_code": "import os\nos.environ[\"PL_TRAINER_GPUS\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\nparse_env_variables(Trainer)\nNamespace(gpus=42)",
            "new_code": "import os\nos.environ[\"PL_TRAINER_DEVICES\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\n_parse_env_variables(Trainer)\nNamespace(devices=42)",
            "old_name": "parse_env_variables",
            "new_name": "_parse_env_variables",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_22775"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.9.4",
            "new_version": "==2.1.1",
            "old_time": "2023-03-01",
            "new_time": "2023-11-06",
            "description": "The code registers different distributed data parallel communication hooks for a deep learning model. The hooks include fp16_compress_hook for compressing gradients, powerSGD_hook for a specific communication optimization technique, and post_localSGD_hook for another communication optimization technique. Additionally, it demonstrates combining fp16_compress_wrapper with other communication hooks for further optimization.",
            "old_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "new_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "old_name": "register_ddp_comm_hook",
            "new_name": "_register_ddp_comm_hook",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_24640"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.69.2",
            "new_version": "==1.27.0",
            "old_time": "2020-10-16",
            "new_time": "2023-09-21",
            "description": "Display an explanation in a beta expander widget that includes a chart showing randomly generated numbers based on actual dice rolls.",
            "old_code": "with st.beta_expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "new_code": "with st.expander(\"See explanation\"):\n    st.write(\"\"\"\n        The chart above shows some numbers I picked for you.\n        I rolled actual dice for these, so they're *guaranteed* to\n        be random.\n    \"\"\")\n    st.image(\"https://static.streamlit.io/examples/dice.jpg\")",
            "old_name": "beta_expander",
            "new_name": "expander",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_42775"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.5.3",
            "new_version": "==2.0.3",
            "old_time": "2021-11-24",
            "new_time": "2023-06-07",
            "description": "The code registers different distributed data parallel communication hooks for a deep learning model. The hooks include fp16_compress_hook for compressing gradients, powerSGD_hook for a specific communication optimization technique, and post_localSGD_hook for another communication optimization technique. Additionally, it demonstrates combining fp16_compress_wrapper with other communication hooks for further optimization.",
            "old_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "new_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "old_name": "register_ddp_comm_hook",
            "new_name": "_register_ddp_comm_hook",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_24104"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.6.1",
            "new_version": "==2.1.2",
            "old_time": "2022-04-13",
            "new_time": "2023-11-15",
            "description": "The code loads and reads the README file located in the project root directory and displays its content in HTML format with center alignment.",
            "old_code": "_load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "new_code": "load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "old_name": "_load_readme_description",
            "new_name": "load_readme_description",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_22475"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.69.2",
            "new_version": "==1.27.0",
            "old_time": "2020-10-16",
            "new_time": "2023-09-21",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36961"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.2",
            "new_version": "==0.4.21",
            "old_time": "2020-10-14",
            "new_time": "2023-12-04",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2696"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.4.1",
            "new_version": "==2.9.2",
            "old_time": "2017-12-08",
            "new_time": "2022-09-01",
            "description": "This code snippet defines that the function \"Size\" is not differentiable in TensorFlow.",
            "old_code": "tf.NotDifferentiable(\"Size\")",
            "new_code": "tf.no_gradient(\"Size\")",
            "old_name": "NotDifferentiable",
            "new_name": "no_gradient",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_45392"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.84.2",
            "new_version": "==1.22.0",
            "old_time": "2021-07-19",
            "new_time": "2023-04-27",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33658"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.66",
            "new_version": "==0.4.11",
            "old_time": "2020-05-05",
            "new_time": "2023-06-01",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1791"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.2",
            "new_version": "==1.1.4",
            "old_time": "2020-03-12",
            "new_time": "2020-10-30",
            "description": "This code removes duplicate tuples from a list based on the first element of each tuple.",
            "old_code": "_make_unique([('a', '<lambda>'), ('a', '<lambda>'), ('b', '<lambda>')])",
            "new_code": "kwarg_list = [('a', '<lambda>'), ('a', '<lambda>'), ('b', '<lambda>')]\n_make_unique_kwarg_list(kwarg_list)\n[('a', '<lambda>_0'), ('a', '<lambda>_1'), ('b', '<lambda>')]",
            "old_name": "_make_unique",
            "new_name": "_make_unique_kwarg_list",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_16940"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.2",
            "new_version": "==2.1.3",
            "old_time": "2020-03-12",
            "new_time": "2023-11-10",
            "description": "This code removes duplicate tuples from a list based on the first element of each tuple.",
            "old_code": "_make_unique([('a', '<lambda>'), ('a', '<lambda>'), ('b', '<lambda>')])",
            "new_code": "kwarg_list = [('a', '<lambda>'), ('a', '<lambda>'), ('b', '<lambda>')]\n_make_unique_kwarg_list(kwarg_list)\n[('a', '<lambda>_0'), ('a', '<lambda>_1'), ('b', '<lambda>')]",
            "old_name": "_make_unique",
            "new_name": "_make_unique_kwarg_list",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_16970"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.47.1",
            "new_version": "==1.14.1",
            "old_time": "2019-10-01",
            "new_time": "2022-11-09",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_34760"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.23.1",
            "new_version": "==1.1.1",
            "old_time": "2018-06-12",
            "new_time": "2020-08-20",
            "description": "The code creates an index object based on the input provided, which can be a list of single values, tuples, or lists.",
            "old_code": "_ensure_index(['a', 'b'])\nIndex(['a', 'b'], dtype='object')\n\n_ensure_index([('a', 'a'),  ('b', 'c')])\nIndex([('a', 'a'), ('b', 'c')], dtype='object')\n\n_ensure_index([['a', 'a'], ['b', 'c']])\nMultiIndex(levels=[['a'], ['b', 'c']],\n           labels=[[0, 0], [0, 1]])",
            "new_code": "ensure_index(['a', 'b'])\nIndex(['a', 'b'], dtype='object')\n\nensure_index([('a', 'a'),  ('b', 'c')])\nIndex([('a', 'a'), ('b', 'c')], dtype='object')\n\nensure_index([['a', 'a'], ['b', 'c']])\nMultiIndex(levels=[['a'], ['b', 'c']],\n           labels=[[0, 0], [0, 1]])",
            "old_name": "_ensure_index",
            "new_name": "ensure_index",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_15550"
        },
        {
            "dependency": "keras",
            "old_version": "==2.1.6",
            "new_version": "==3.0.4",
            "old_time": "2018-04-23",
            "new_time": "2024-01-20",
            "description": "This code calculates the hash value of a file located at '/path/to/file.zip' using the SHA-256 algorithm.",
            "old_code": "_hash_file('/path/to/file.zip')\n'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'",
            "new_code": "hash_file('/path/to/file.zip')",
            "old_name": "_hash_file",
            "new_name": "hash_file",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3399"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.67.1",
            "new_version": "==1.25.0",
            "old_time": "2020-09-23",
            "new_time": "2023-07-20",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_32438"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.9.4",
            "new_version": "==2.0.5",
            "old_time": "2023-03-01",
            "new_time": "2023-07-10",
            "description": "The code registers different distributed data parallel communication hooks for a deep learning model. The hooks include fp16_compress_hook for compressing gradients, powerSGD_hook for a specific communication optimization technique, and post_localSGD_hook for another communication optimization technique. Additionally, it demonstrates combining fp16_compress_wrapper with other communication hooks for further optimization.",
            "old_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "new_code": "from torch.distributed.algorithms.ddp_comm_hooks import ( # doctest: +SKIP\n    ...     default_hooks as default,\n    ...     powerSGD_hook as powerSGD,\n    ...     post_localSGD_hook as post_localSGD,\n    ... )\n    \n    # fp16_compress_hook for compress gradients\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_hook=default.fp16_compress_hook,\n    ... )\n    \n    # powerSGD_hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ... )\n    \n    # post_localSGD_hook\n    subgroup, _ = torch.distributed.new_subgroups() # doctest: +SKIP\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     state=post_localSGD.PostLocalSGDState(\n    ...         process_group=None,\n    ...         subgroup=subgroup,\n    ...         start_localSGD_iter=1_000,\n    ...     ),\n    ...     ddp_comm_hook=post_localSGD.post_localSGD_hook,\n    ... )\n    \n    # fp16_compress_wrapper combined with other communication hook\n    ddp_model = ...\n    _register_ddp_comm_hook( # doctest: +SKIP\n    ...     model=ddp_model,\n    ...     ddp_comm_state=powerSGD.PowerSGDState(\n    ...         process_group=None,\n    ...         matrix_approximation_rank=1,\n    ...         start_powerSGD_iter=5000,\n    ...     ),\n    ...     ddp_comm_hook=powerSGD.powerSGD_hook,\n    ...     ddp_comm_wrapper=default.fp16_compress_wrapper,\n    ... )",
            "old_name": "register_ddp_comm_hook",
            "new_name": "_register_ddp_comm_hook",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_24634"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.50.1",
            "new_version": "==1.25.0",
            "old_time": "2019-11-11",
            "new_time": "2023-07-20",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_31066"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.2",
            "new_version": "==2.4.1",
            "old_time": "2022-01-18",
            "new_time": "2022-12-05",
            "description": "The code creates a dataset using PaddlePaddle framework and sets a download command to read data from AFS (Alibaba File System).",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "old_name": "set_download_cmd",
            "new_name": "_set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5518"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.69.2",
            "new_version": "==0.78.0",
            "old_time": "2020-10-16",
            "new_time": "2021-03-04",
            "description": "The code allows the user to pick a color using a color picker widget and displays the selected color.",
            "old_code": "st.beta_color_picker('Pick A Color', '#00f900')\nst.write('The current color is', color)",
            "new_code": "color = st.color_picker('Pick A Color', '#00f900')\nst.write('The current color is', color)",
            "old_name": "beta_color_picker",
            "new_name": "color_picker",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29674"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.7.1",
            "new_version": "==2.0.9",
            "old_time": "2022-08-10",
            "new_time": "2023-09-14",
            "description": "The code sets environment variables for the PL Trainer with the number of GPUs as 42 and a specific value for another variable. It then parses the environment variables for the Trainer and returns a Namespace object with the specified GPU value.",
            "old_code": "import os\nos.environ[\"PL_TRAINER_GPUS\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\nparse_env_variables(Trainer)\nNamespace(gpus=42)",
            "new_code": "import os\nos.environ[\"PL_TRAINER_DEVICES\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\n_parse_env_variables(Trainer)\nNamespace(devices=42)",
            "old_name": "parse_env_variables",
            "new_name": "_parse_env_variables",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_23392"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.62.1",
            "new_version": "==1.9.1",
            "old_time": "2020-06-29",
            "new_time": "2022-05-26",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_31971"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.1.1",
            "new_version": "==1.2.3",
            "old_time": "2020-08-20",
            "new_time": "2021-03-02",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18389"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.25.2",
            "new_version": "==2.0.2",
            "old_time": "2019-10-18",
            "new_time": "2023-05-28",
            "description": "The code performs resampling on a pandas Series or DataFrame with a specified frequency and backfills missing values within the resampled intervals.",
            "old_code": "s = pd.Series([1, 2, 3],\n              index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01-01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').backfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').backfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n                  index=pd.date_range('20180101', periods=3,\n                                      freq='h'))\ndf\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').backfill()\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 00:30:00  NaN  3\n2018-01-01 01:00:00  NaN  3\n2018-01-01 01:30:00  6.0  5\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('15min').backfill(limit=2)\n                   a    b\n2018-01-01 00:00:00  2.0  1.0\n2018-01-01 00:15:00  NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-01 02:00:00   6.0   5.0",
            "new_code": "s = pd.Series([1, 2, 3],\n...               index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01:01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').bfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').bfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n...                   index=pd.date_range('20180101', periods=3,\n...                                       freq='h'))\ndf\n                       a    b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').bfill()\n                       a    b\n2018-01-01 00:00:00  2.0   1\n2018-01-01 00:30:00   NaN   3\n2018-01-01 01:00:00   NaN   3\n2018-01-01 01:30:00   6.0   5\n2018-01-01 02:00:00   6.0   5\n\ndf.resample('15min').bfill(limit=2)\n                       a    b\n2018-01-01 00:00:00   2.0   1.0\n2018-01-01 00:15:00   NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-02 02:00:00   6.0   5.0",
            "old_name": "backfill",
            "new_name": "bfill",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18970"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.1",
            "new_version": "==2.5.0",
            "old_time": "2022-07-01",
            "new_time": "2023-06-19",
            "description": "The code creates a dataset using PaddlePaddle framework and sets a download command to read data from AFS (Alibaba File System).",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "old_name": "set_download_cmd",
            "new_name": "_set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5537"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.61",
            "new_version": "==0.2.20",
            "old_time": "2020-03-17",
            "new_time": "2021-09-03",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1428"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.4.4",
            "new_version": "==2.0.0",
            "old_time": "2022-08-31",
            "new_time": "2023-04-03",
            "description": "The code is inferring the data type of an integer value with 64-bit precision.",
            "old_code": "maybe_infer_dtype_type(Foo(np.dtype(\"i8\")))",
            "new_code": "_maybe_infer_dtype_type(Foo(np.dtype(\"i8\")))",
            "old_name": "maybe_infer_dtype_type",
            "new_name": "_maybe_infer_dtype_type",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20092"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.4.0",
            "old_time": "2021-03-02",
            "new_time": "2022-11-16",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11468"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.5",
            "new_version": "==1.5.3",
            "old_time": "2020-06-17",
            "new_time": "2023-01-19",
            "description": "The code performs resampling on a pandas Series or DataFrame with a specified frequency and backfills missing values within the resampled intervals.",
            "old_code": "s = pd.Series([1, 2, 3],\n              index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01-01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').backfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').backfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n                  index=pd.date_range('20180101', periods=3,\n                                      freq='h'))\ndf\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').backfill()\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 00:30:00  NaN  3\n2018-01-01 01:00:00  NaN  3\n2018-01-01 01:30:00  6.0  5\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('15min').backfill(limit=2)\n                   a    b\n2018-01-01 00:00:00  2.0  1.0\n2018-01-01 00:15:00  NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-01 02:00:00   6.0   5.0",
            "new_code": "s = pd.Series([1, 2, 3],\n...               index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01:01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').bfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').bfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n...                   index=pd.date_range('20180101', periods=3,\n...                                       freq='h'))\ndf\n                       a    b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').bfill()\n                       a    b\n2018-01-01 00:00:00  2.0   1\n2018-01-01 00:30:00   NaN   3\n2018-01-01 01:00:00   NaN   3\n2018-01-01 01:30:00   6.0   5\n2018-01-01 02:00:00   6.0   5\n\ndf.resample('15min').bfill(limit=2)\n                       a    b\n2018-01-01 00:00:00   2.0   1.0\n2018-01-01 00:15:00   NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-02 02:00:00   6.0   5.0",
            "old_name": "backfill",
            "new_name": "bfill",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_19100"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.67.1",
            "new_version": "==1.16.0",
            "old_time": "2020-09-23",
            "new_time": "2022-12-14",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_32426"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.6.0",
            "old_time": "2021-03-02",
            "new_time": "2023-12-21",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4085"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.57.1",
            "new_version": "==1.18.0",
            "old_time": "2020-03-28",
            "new_time": "2023-02-09",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35718"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.69.1",
            "new_version": "==1.14.0",
            "old_time": "2020-10-15",
            "new_time": "2022-10-25",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_32617"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==2.2.3",
            "new_version": "==2.10.1",
            "old_time": "2021-06-10",
            "new_time": "2022-11-15",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_47076"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.4",
            "new_version": "==1.3.5",
            "old_time": "2020-05-28",
            "new_time": "2021-12-12",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18304"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.3",
            "new_version": "==1.5.3",
            "old_time": "2020-03-18",
            "new_time": "2023-01-19",
            "description": "The code performs resampling on a pandas Series or DataFrame with a specified frequency and backfills missing values within the resampled intervals.",
            "old_code": "s = pd.Series([1, 2, 3],\n              index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01-01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').backfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').backfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n                  index=pd.date_range('20180101', periods=3,\n                                      freq='h'))\ndf\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').backfill()\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 00:30:00  NaN  3\n2018-01-01 01:00:00  NaN  3\n2018-01-01 01:30:00  6.0  5\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('15min').backfill(limit=2)\n                   a    b\n2018-01-01 00:00:00  2.0  1.0\n2018-01-01 00:15:00  NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-01 02:00:00   6.0   5.0",
            "new_code": "s = pd.Series([1, 2, 3],\n...               index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01:01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').bfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').bfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n...                   index=pd.date_range('20180101', periods=3,\n...                                       freq='h'))\ndf\n                       a    b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').bfill()\n                       a    b\n2018-01-01 00:00:00  2.0   1\n2018-01-01 00:30:00   NaN   3\n2018-01-01 01:00:00   NaN   3\n2018-01-01 01:30:00   6.0   5\n2018-01-01 02:00:00   6.0   5\n\ndf.resample('15min').bfill(limit=2)\n                       a    b\n2018-01-01 00:00:00   2.0   1.0\n2018-01-01 00:15:00   NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-02 02:00:00   6.0   5.0",
            "old_name": "backfill",
            "new_name": "bfill",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_19062"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==2.1.3",
            "new_version": "==2.5.0",
            "old_time": "2021-01-04",
            "new_time": "2021-05-12",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46858"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.68",
            "new_version": "==0.3.5",
            "old_time": "2020-05-21",
            "new_time": "2022-04-07",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1889"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.57.3",
            "new_version": "==0.85.0",
            "old_time": "2020-04-04",
            "new_time": "2021-07-22",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35795"
        },
        {
            "dependency": "ray",
            "old_version": "==0.6.1",
            "new_version": "==1.11.1",
            "old_time": "2018-12-24",
            "new_time": "2022-04-11",
            "description": "This code filters nodes based on the node type \"worker\" in a provider.",
            "old_code": "provider.nodes({TAG_RAY_NODE_TYPE: \"worker\"})",
            "new_code": "provider.non_terminated_nodes({TAG_RAY_NODE_TYPE: \"worker\"})\n[\"node-1\", \"node-2\"]",
            "old_name": "nodes",
            "new_name": "non_terminated_nodes",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_25458"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.1.3",
            "new_version": "==2.2.0",
            "old_time": "2020-10-05",
            "new_time": "2024-01-20",
            "description": "The code performs resampling on a pandas Series or DataFrame with a specified frequency and backfills missing values within the resampled intervals.",
            "old_code": "s = pd.Series([1, 2, 3],\n              index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01-01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').backfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').backfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n                  index=pd.date_range('20180101', periods=3,\n                                      freq='h'))\ndf\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').backfill()\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 00:30:00  NaN  3\n2018-01-01 01:00:00  NaN  3\n2018-01-01 01:30:00  6.0  5\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('15min').backfill(limit=2)\n                   a    b\n2018-01-01 00:00:00  2.0  1.0\n2018-01-01 00:15:00  NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-01 02:00:00   6.0   5.0",
            "new_code": "s = pd.Series([1, 2, 3],\n...               index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01:01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').bfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').bfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n...                   index=pd.date_range('20180101', periods=3,\n...                                       freq='h'))\ndf\n                       a    b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').bfill()\n                       a    b\n2018-01-01 00:00:00  2.0   1\n2018-01-01 00:30:00   NaN   3\n2018-01-01 01:00:00   NaN   3\n2018-01-01 01:30:00   6.0   5\n2018-01-01 02:00:00   6.0   5\n\ndf.resample('15min').bfill(limit=2)\n                       a    b\n2018-01-01 00:00:00   2.0   1.0\n2018-01-01 00:15:00   NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-02 02:00:00   6.0   5.0",
            "old_name": "backfill",
            "new_name": "bfill",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_19186"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.57.2",
            "new_version": "==1.11.1",
            "old_time": "2020-03-31",
            "new_time": "2022-07-27",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35762"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.7",
            "new_version": "==0.3.10",
            "old_time": "2020-12-05",
            "new_time": "2022-05-04",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2982"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.3",
            "new_version": "==1.4.6",
            "old_time": "2020-10-20",
            "new_time": "2021-09-10",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21495"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.25.2",
            "new_version": "==1.0.1",
            "old_time": "2019-10-18",
            "new_time": "2020-02-05",
            "description": "The code creates a DataFrame using pandas with values and column names specified. It then creates an index object and retrieves its values. Next, it creates a MultiIndex object with two levels of indexes and retrieves its values. Finally, it checks the number of dimensions of the values in the MultiIndex object.",
            "old_code": "df = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n                   index=['a', 'b', 'c'], columns=['A', 'B', 'C'])\ndf.index.get_values()\nidx = pd.Index(['1', '2', '3'])\nidx.get_values()\nmidx = pd.MultiIndex.from_arrays([[1, 2, 3], ['a', 'b', 'c']],\n                                 names=('number', 'letter'))\nmidx.get_values()\nmidx.get_values().ndim",
            "new_code": "df = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n                   index=['a', 'b', 'c'], columns=['A', 'B', 'C'])\ndf.index._internal_get_values()\nidx = pd.Index(['1', '2', '3'])\nidx._internal_get_values()\nmidx = pd.MultiIndex.from_arrays([[1, 2, 3], ['a', 'b', 'c']],\n                                  names=('number', 'letter'))\nmidx._internal_get_values()\nmidx._internal_get_values().ndim",
            "old_name": "get_values",
            "new_name": "_internal_get_values",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_15869"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.65.2",
            "new_version": "==1.0.0",
            "old_time": "2020-08-14",
            "new_time": "2021-10-05",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_32252"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.74",
            "new_version": "==0.4.12",
            "old_time": "2020-07-30",
            "new_time": "2023-06-08",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2304"
        },
        {
            "dependency": "imageio",
            "old_version": "==1.5",
            "new_version": "==2.28.1",
            "old_time": "2016-01-30",
            "new_time": "2023-05-01",
            "description": "The code generates RGB values from the given data using different bit lengths for each color channel.",
            "old_code": "data = struct.pack('BBBB', 0x21, 0x08, 0xff, 0xff)\nprint(unpackrgb(data, '<B', (5, 6, 5), False))\nprint(unpackrgb(data, '<B', (5, 6, 5)))\nprint(unpackrgb(data, '<B', (5, 5, 5)))",
            "new_code": "data = struct.pack('BBBB', 0x21, 0x08, 0xff, 0xff)\nprint(unpack_rgb(data, '<B', (5, 6, 5), False))\nprint(unpack_rgb(data, '<B', (5, 6, 5)))\nprint(unpack_rgb(data, '<B', (5, 5, 5)))",
            "old_name": "unpackrgb",
            "new_name": "unpack_rgb",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_880"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.47.1",
            "new_version": "==1.15.0",
            "old_time": "2019-10-01",
            "new_time": "2022-11-14",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_30757"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.63.1",
            "new_version": "==0.87.0",
            "old_time": "2020-07-17",
            "new_time": "2021-08-23",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_32053"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.2",
            "new_version": "==2.1.3",
            "old_time": "2021-04-08",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4089"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.3.2",
            "old_time": "2021-06-23",
            "new_time": "2022-08-15",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a pipe command to run a Python script called \"my_script.py\".",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10016"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.63",
            "new_version": "==0.4.21",
            "old_time": "2020-04-13",
            "new_time": "2023-12-04",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1608"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.24.1",
            "new_version": "==2.1.3",
            "old_time": "2019-02-03",
            "new_time": "2023-11-10",
            "description": "The code performs resampling on a pandas Series or DataFrame with a specified frequency and backfills missing values within the resampled intervals.",
            "old_code": "s = pd.Series([1, 2, 3],\n              index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01-01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').backfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').backfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n                  index=pd.date_range('20180101', periods=3,\n                                      freq='h'))\ndf\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').backfill()\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 00:30:00  NaN  3\n2018-01-01 01:00:00  NaN  3\n2018-01-01 01:30:00  6.0  5\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('15min').backfill(limit=2)\n                   a    b\n2018-01-01 00:00:00  2.0  1.0\n2018-01-01 00:15:00  NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-01 02:00:00   6.0   5.0",
            "new_code": "s = pd.Series([1, 2, 3],\n...               index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01:01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').bfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').bfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n...                   index=pd.date_range('20180101', periods=3,\n...                                       freq='h'))\ndf\n                       a    b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').bfill()\n                       a    b\n2018-01-01 00:00:00  2.0   1\n2018-01-01 00:30:00   NaN   3\n2018-01-01 01:00:00   NaN   3\n2018-01-01 01:30:00   6.0   5\n2018-01-01 02:00:00   6.0   5\n\ndf.resample('15min').bfill(limit=2)\n                       a    b\n2018-01-01 00:00:00   2.0   1.0\n2018-01-01 00:15:00   NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-02 02:00:00   6.0   5.0",
            "old_name": "backfill",
            "new_name": "bfill",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18899"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.3.3",
            "new_version": "==2.2.0",
            "old_time": "2021-09-12",
            "new_time": "2024-01-20",
            "description": "The code is inferring the data type of an integer value with 64-bit precision.",
            "old_code": "maybe_infer_dtype_type(Foo(np.dtype(\"i8\")))",
            "new_code": "_maybe_infer_dtype_type(Foo(np.dtype(\"i8\")))",
            "old_name": "maybe_infer_dtype_type",
            "new_name": "_maybe_infer_dtype_type",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20003"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.1.5",
            "new_version": "==1.4.2",
            "old_time": "2020-12-07",
            "new_time": "2022-04-02",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18524"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.61",
            "new_version": "==0.3.1",
            "old_time": "2020-03-17",
            "new_time": "2022-02-18",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1437"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.2.2",
            "old_time": "2021-03-02",
            "new_time": "2022-01-18",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12034"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.2",
            "new_version": "==1.2.1",
            "old_time": "2020-03-12",
            "new_time": "2021-01-20",
            "description": "This code removes duplicate tuples from a list based on the first element of each tuple.",
            "old_code": "_make_unique([('a', '<lambda>'), ('a', '<lambda>'), ('b', '<lambda>')])",
            "new_code": "kwarg_list = [('a', '<lambda>'), ('a', '<lambda>'), ('b', '<lambda>')]\n_make_unique_kwarg_list(kwarg_list)\n[('a', '<lambda>_0'), ('a', '<lambda>_1'), ('b', '<lambda>')]",
            "old_name": "_make_unique",
            "new_name": "_make_unique_kwarg_list",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_16943"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.3",
            "new_version": "==1.2.0",
            "old_time": "2020-10-20",
            "new_time": "2021-02-18",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21469"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.4.7",
            "new_version": "==2.1.3",
            "old_time": "2021-09-15",
            "new_time": "2023-12-20",
            "description": "The code loads and reads the README file located in the project root directory and displays its content in HTML format with center alignment.",
            "old_code": "_load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "new_code": "load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "old_name": "_load_readme_description",
            "new_name": "load_readme_description",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_22146"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.1",
            "new_version": "==1.2.10",
            "old_time": "2020-10-14",
            "new_time": "2021-04-23",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21083"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.1",
            "new_version": "==1.2.3",
            "old_time": "2020-02-05",
            "new_time": "2021-03-02",
            "description": "This code removes duplicate tuples from a list based on the first element of each tuple.",
            "old_code": "_make_unique([('a', '<lambda>'), ('a', '<lambda>'), ('b', '<lambda>')])",
            "new_code": "kwarg_list = [('a', '<lambda>'), ('a', '<lambda>'), ('b', '<lambda>')]\n_make_unique_kwarg_list(kwarg_list)\n[('a', '<lambda>_0'), ('a', '<lambda>_1'), ('b', '<lambda>')]",
            "old_name": "_make_unique",
            "new_name": "_make_unique_kwarg_list",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_16908"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.3.6",
            "new_version": "==2.0.9",
            "old_time": "2021-06-17",
            "new_time": "2023-09-14",
            "description": "The code sets environment variables for the PL Trainer with the number of GPUs as 42 and a specific value for another variable. It then parses the environment variables for the Trainer and returns a Namespace object with the specified GPU value.",
            "old_code": "import os\nos.environ[\"PL_TRAINER_GPUS\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\nparse_env_variables(Trainer)\nNamespace(gpus=42)",
            "new_code": "import os\nos.environ[\"PL_TRAINER_DEVICES\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\n_parse_env_variables(Trainer)\nNamespace(devices=42)",
            "old_name": "parse_env_variables",
            "new_name": "_parse_env_variables",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_22896"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.2",
            "new_version": "==1.3.0",
            "old_time": "2020-10-15",
            "new_time": "2021-05-06",
            "description": "Calculate the mean absolute error (MAE) between two tensors x and y.",
            "old_code": "mae = nn.L1Loss(reduction='mean')\nx = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmae_value = mae(x, y)\nprint(mae_value)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmean_absolute_error(x, y)\ntensor(0.2500)",
            "old_name": "mae",
            "new_name": "mean_absolute_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20908"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.2",
            "new_version": "==2.1.2",
            "old_time": "2020-03-12",
            "new_time": "2023-10-26",
            "description": "This code removes duplicate tuples from a list based on the first element of each tuple.",
            "old_code": "_make_unique([('a', '<lambda>'), ('a', '<lambda>'), ('b', '<lambda>')])",
            "new_code": "kwarg_list = [('a', '<lambda>'), ('a', '<lambda>'), ('b', '<lambda>')]\n_make_unique_kwarg_list(kwarg_list)\n[('a', '<lambda>_0'), ('a', '<lambda>_1'), ('b', '<lambda>')]",
            "old_name": "_make_unique",
            "new_name": "_make_unique_kwarg_list",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_16969"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.6.4",
            "new_version": "==2.0.2",
            "old_time": "2022-06-01",
            "new_time": "2023-04-24",
            "description": "The code loads and reads the README file located in the project root directory and displays its content in HTML format with center alignment.",
            "old_code": "_load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "new_code": "load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "old_name": "_load_readme_description",
            "new_name": "load_readme_description",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_22531"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.3",
            "new_version": "==2.1.1",
            "old_time": "2020-03-18",
            "new_time": "2023-09-20",
            "description": "This code normalizes keyword aggregation by converting the input dictionary into a list of tuples.",
            "old_code": "_normalize_keyword_aggregation({'output': ('input', 'sum')})\n({'input': ['sum']}, ('output',), [('input', 'sum')])",
            "new_code": "normalize_keyword_aggregation({\"output\": (\"input\", \"sum\")})\n(defaultdict(<class 'list'>, {'input': ['sum']}), ('output',), array([0]))",
            "old_name": "_normalize_keyword_aggregation",
            "new_name": "normalize_keyword_aggregation",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_16783"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.25.1",
            "new_version": "==1.5.1",
            "old_time": "2019-08-22",
            "new_time": "2022-10-18",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18094"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.1",
            "new_version": "==2.0.0",
            "old_time": "2020-02-05",
            "new_time": "2023-04-03",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18221"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==2.0.3",
            "new_version": "==2.9.2",
            "old_time": "2020-09-22",
            "new_time": "2022-09-01",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46682"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.84.1",
            "new_version": "==1.4.0",
            "old_time": "2021-07-12",
            "new_time": "2022-01-11",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_33580"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.1.3",
            "new_version": "==2.0.1",
            "old_time": "2020-10-05",
            "new_time": "2023-04-24",
            "description": "The code performs resampling on a pandas Series or DataFrame with a specified frequency and backfills missing values within the resampled intervals.",
            "old_code": "s = pd.Series([1, 2, 3],\n              index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01-01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').backfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').backfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n                  index=pd.date_range('20180101', periods=3,\n                                      freq='h'))\ndf\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').backfill()\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 00:30:00  NaN  3\n2018-01-01 01:00:00  NaN  3\n2018-01-01 01:30:00  6.0  5\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('15min').backfill(limit=2)\n                   a    b\n2018-01-01 00:00:00  2.0  1.0\n2018-01-01 00:15:00  NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-01 02:00:00   6.0   5.0",
            "new_code": "s = pd.Series([1, 2, 3],\n...               index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01:01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').bfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').bfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n...                   index=pd.date_range('20180101', periods=3,\n...                                       freq='h'))\ndf\n                       a    b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').bfill()\n                       a    b\n2018-01-01 00:00:00  2.0   1\n2018-01-01 00:30:00   NaN   3\n2018-01-01 01:00:00   NaN   3\n2018-01-01 01:30:00   6.0   5\n2018-01-01 02:00:00   6.0   5\n\ndf.resample('15min').bfill(limit=2)\n                       a    b\n2018-01-01 00:00:00   2.0   1.0\n2018-01-01 00:15:00   NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-02 02:00:00   6.0   5.0",
            "old_name": "backfill",
            "new_name": "bfill",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_19178"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.5.3",
            "new_version": "==2.0.1",
            "old_time": "2021-11-24",
            "new_time": "2023-03-30",
            "description": "The code sets environment variables for the PL Trainer with the number of GPUs as 42 and a specific value for another variable. It then parses the environment variables for the Trainer and returns a Namespace object with the specified GPU value.",
            "old_code": "import os\nos.environ[\"PL_TRAINER_GPUS\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\nparse_env_variables(Trainer)\nNamespace(gpus=42)",
            "new_code": "import os\nos.environ[\"PL_TRAINER_DEVICES\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\n_parse_env_variables(Trainer)\nNamespace(devices=42)",
            "old_name": "parse_env_variables",
            "new_name": "_parse_env_variables",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_23144"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==2.2.1",
            "new_version": "==2.13.1",
            "old_time": "2020-09-22",
            "new_time": "2023-09-12",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_47006"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.67",
            "new_version": "==0.2.14",
            "old_time": "2020-05-12",
            "new_time": "2021-06-10",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1806"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.1",
            "new_version": "==1.4.4",
            "old_time": "2020-02-05",
            "new_time": "2022-08-31",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18216"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.20.1",
            "new_version": "==2.1.0",
            "old_time": "2017-05-05",
            "new_time": "2023-08-30",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17636"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.8",
            "new_version": "==0.3.17",
            "old_time": "2021-01-12",
            "new_time": "2022-08-31",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3053"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==1.0.1",
            "new_version": "==1.4.1",
            "old_time": "2017-03-07",
            "new_time": "2017-12-08",
            "description": "The code initializes a string to index table from a vocabulary file, maps the strings in the 'features' constant to their corresponding indices using the table, and then initializes the table.",
            "old_code": "features = tf.constant([\"emerson\", \"lake\", \"and\", \"palmer\"])\ntable = tf.contrib.lookup.string_to_index_table_from_file(\n    vocabulary_file=\"test.txt\", num_oov_buckets=1)\nids = table.lookup(features)\n...\ntf.tables_initializer().run()",
            "new_code": "features = tf.constant([\"emerson\", \"lake\", \"and\", \"palmer\"])\ntable = tf.contrib.lookup.index_table_from_file(\n    vocabulary_file=\"test.txt\", num_oov_buckets=1)\nids = table.lookup(features)\n...\ntf.tables_initializer().run()\n\nids.eval()  ==> [0, 1, 3, 2]  # where 3 is the out-of-vocabulary bucket",
            "old_name": "string_to_index_table_from_file",
            "new_name": "index_table_from_file",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_44737"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.2.3",
            "new_version": "==1.4.2",
            "old_time": "2021-03-02",
            "new_time": "2022-04-02",
            "description": "The code performs resampling on a pandas Series or DataFrame with a specified frequency and backfills missing values within the resampled intervals.",
            "old_code": "s = pd.Series([1, 2, 3],\n              index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01-01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').backfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').backfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n                  index=pd.date_range('20180101', periods=3,\n                                      freq='h'))\ndf\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').backfill()\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 00:30:00  NaN  3\n2018-01-01 01:00:00  NaN  3\n2018-01-01 01:30:00  6.0  5\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('15min').backfill(limit=2)\n                   a    b\n2018-01-01 00:00:00  2.0  1.0\n2018-01-01 00:15:00  NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-01 02:00:00   6.0   5.0",
            "new_code": "s = pd.Series([1, 2, 3],\n...               index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01:01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').bfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').bfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n...                   index=pd.date_range('20180101', periods=3,\n...                                       freq='h'))\ndf\n                       a    b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').bfill()\n                       a    b\n2018-01-01 00:00:00  2.0   1\n2018-01-01 00:30:00   NaN   3\n2018-01-01 01:00:00   NaN   3\n2018-01-01 01:30:00   6.0   5\n2018-01-01 02:00:00   6.0   5\n\ndf.resample('15min').bfill(limit=2)\n                       a    b\n2018-01-01 00:00:00   2.0   1.0\n2018-01-01 00:15:00   NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-02 02:00:00   6.0   5.0",
            "old_name": "backfill",
            "new_name": "bfill",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_19284"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.73",
            "new_version": "==0.3.4",
            "old_time": "2020-07-22",
            "new_time": "2022-03-18",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2208"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.1.5",
            "new_version": "==2.2.0",
            "old_time": "2020-12-07",
            "new_time": "2024-01-20",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18540"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.4",
            "new_version": "==1.3.4",
            "old_time": "2020-05-28",
            "new_time": "2021-10-17",
            "description": "The code may potentially modify lambda functions named 'sum' to avoid conflicts.",
            "old_code": "_maybe_mangle_lambdas('sum')\\n\\n_maybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "new_code": "maybe_mangle_lambdas('sum')\n\nmaybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "old_name": "_maybe_mangle_lambdas",
            "new_name": "maybe_mangle_lambdas",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17396"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.1.0",
            "old_time": "2021-03-02",
            "new_time": "2021-05-13",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the time interval for sending data to the distributed training fleet to 2 seconds.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "old_name": "set_fleet_send_sleep_seconds",
            "new_name": "_set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6539"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.2",
            "new_version": "==1.6.0",
            "old_time": "2020-02-24",
            "new_time": "2021-08-21",
            "description": "This code splits the traffic for the \"service-name\" between two backend versions, \"backend:v1\" and \"backend:v2\", with a 50/50 distribution.",
            "old_code": "serve.split(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "new_code": "serve.set_traffic(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "old_name": "split",
            "new_name": "set_traffic",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29146"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.3.1",
            "new_version": "==2.1.4",
            "old_time": "2021-07-25",
            "new_time": "2023-12-08",
            "description": "The code performs resampling on a pandas Series or DataFrame with a specified frequency and backfills missing values within the resampled intervals.",
            "old_code": "s = pd.Series([1, 2, 3],\n              index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01-01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').backfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').backfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n                  index=pd.date_range('20180101', periods=3,\n                                      freq='h'))\ndf\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').backfill()\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 00:30:00  NaN  3\n2018-01-01 01:00:00  NaN  3\n2018-01-01 01:30:00  6.0  5\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('15min').backfill(limit=2)\n                   a    b\n2018-01-01 00:00:00  2.0  1.0\n2018-01-01 00:15:00  NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-01 02:00:00   6.0   5.0",
            "new_code": "s = pd.Series([1, 2, 3],\n...               index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01:01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').bfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').bfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n...                   index=pd.date_range('20180101', periods=3,\n...                                       freq='h'))\ndf\n                       a    b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').bfill()\n                       a    b\n2018-01-01 00:00:00  2.0   1\n2018-01-01 00:30:00   NaN   3\n2018-01-01 01:00:00   NaN   3\n2018-01-01 01:30:00   6.0   5\n2018-01-01 02:00:00   6.0   5\n\ndf.resample('15min').bfill(limit=2)\n                       a    b\n2018-01-01 00:00:00   2.0   1.0\n2018-01-01 00:15:00   NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-02 02:00:00   6.0   5.0",
            "old_name": "backfill",
            "new_name": "bfill",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_19375"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.2",
            "new_version": "==2.3.2",
            "old_time": "2021-04-08",
            "new_time": "2022-08-15",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the variables 'data' and 'label' for use in the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_use_var([data, label])",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "old_name": "set_use_var",
            "new_name": "_set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4285"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.8.4",
            "new_version": "==2.1.2",
            "old_time": "2022-12-08",
            "new_time": "2023-11-15",
            "description": "The code sets environment variables for the PL Trainer with the number of GPUs as 42 and a specific value for another variable. It then parses the environment variables for the Trainer and returns a Namespace object with the specified GPU value.",
            "old_code": "import os\nos.environ[\"PL_TRAINER_GPUS\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\nparse_env_variables(Trainer)\nNamespace(gpus=42)",
            "new_code": "import os\nos.environ[\"PL_TRAINER_DEVICES\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\n_parse_env_variables(Trainer)\nNamespace(devices=42)",
            "old_name": "parse_env_variables",
            "new_name": "_parse_env_variables",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_23571"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.50.1",
            "new_version": "==1.16.0",
            "old_time": "2019-11-11",
            "new_time": "2022-12-14",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_35100"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==2.0.1",
            "new_version": "==2.6.5",
            "old_time": "2020-01-22",
            "new_time": "2022-05-22",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46589"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.2.10",
            "new_version": "==2.0.5",
            "old_time": "2021-04-23",
            "new_time": "2023-07-10",
            "description": "The code loads and reads the README file located in the project root directory and displays its content in HTML format with center alignment.",
            "old_code": "_load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "new_code": "load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "old_name": "_load_readme_description",
            "new_name": "load_readme_description",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21764"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.9",
            "new_version": "==0.3.24",
            "old_time": "2021-01-27",
            "new_time": "2022-11-04",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3123"
        },
        {
            "dependency": "imageio",
            "old_version": "==2.0.1",
            "new_version": "==2.16.2",
            "old_time": "2016-12-10",
            "new_time": "2022-04-11",
            "description": "The code parses a byte string containing information about ImageJ software and returns a dictionary with keys 'ImageJ', 'images', and 'hyperstack' mapped to their respective values.",
            "old_code": "description = b'ImageJ=1.11a\\nimages=510\\nhyperstack=true\\n'\nimagej_description_dict(description)  # doctest: +SKIP\n{'ImageJ': '1.11a', 'images': 510, 'hyperstack': True}",
            "new_code": "description = 'ImageJ=1.11a\\nimages=510\\nhyperstack=true\\n'\nimagej_description_metadata(description)\n{'ImageJ': '1.11a', 'images': 510, 'hyperstack': True}",
            "old_name": "imagej_description_dict",
            "new_name": "imagej_description_metadata",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1052"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.25.2",
            "new_version": "==1.5.1",
            "old_time": "2019-10-18",
            "new_time": "2022-10-18",
            "description": "The code may potentially modify lambda functions named 'sum' to avoid conflicts.",
            "old_code": "_maybe_mangle_lambdas('sum')\\n\\n_maybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "new_code": "maybe_mangle_lambdas('sum')\n\nmaybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "old_name": "_maybe_mangle_lambdas",
            "new_name": "maybe_mangle_lambdas",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17182"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.5.2",
            "old_time": "2021-03-02",
            "new_time": "2023-10-19",
            "description": "The code creates an in-memory dataset using the PaddlePaddle framework with the ability to parse content.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "old_name": "_set_parse_content",
            "new_name": "set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11853"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.2",
            "new_version": "==2.4.1",
            "old_time": "2022-08-15",
            "new_time": "2022-12-05",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11601"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.4.4",
            "new_version": "==1.9.5",
            "old_time": "2021-08-24",
            "new_time": "2023-04-12",
            "description": "The code loads and reads the README file located in the project root directory and displays its content in HTML format with center alignment.",
            "old_code": "_load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "new_code": "load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "old_name": "_load_readme_description",
            "new_name": "load_readme_description",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_22066"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.24.2",
            "new_version": "==1.5.1",
            "old_time": "2019-03-12",
            "new_time": "2022-10-18",
            "description": "The code is inferring the data type of an integer value with 64-bit precision.",
            "old_code": "maybe_infer_dtype_type(Foo(np.dtype(\"i8\")))",
            "new_code": "_maybe_infer_dtype_type(Foo(np.dtype(\"i8\")))",
            "old_name": "maybe_infer_dtype_type",
            "new_name": "_maybe_infer_dtype_type",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_19627"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.23.1",
            "new_version": "==1.4.2",
            "old_time": "2018-06-12",
            "new_time": "2022-04-02",
            "description": "The code performs resampling on a pandas Series or DataFrame with a specified frequency and backfills missing values within the resampled intervals.",
            "old_code": "s = pd.Series([1, 2, 3],\n              index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01-01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').backfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').backfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n                  index=pd.date_range('20180101', periods=3,\n                                      freq='h'))\ndf\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').backfill()\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 00:30:00  NaN  3\n2018-01-01 01:00:00  NaN  3\n2018-01-01 01:30:00  6.0  5\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('15min').backfill(limit=2)\n                   a    b\n2018-01-01 00:00:00  2.0  1.0\n2018-01-01 00:15:00  NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-01 02:00:00   6.0   5.0",
            "new_code": "s = pd.Series([1, 2, 3],\n...               index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01:01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').bfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').bfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n...                   index=pd.date_range('20180101', periods=3,\n...                                       freq='h'))\ndf\n                       a    b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').bfill()\n                       a    b\n2018-01-01 00:00:00  2.0   1\n2018-01-01 00:30:00   NaN   3\n2018-01-01 01:00:00   NaN   3\n2018-01-01 01:30:00   6.0   5\n2018-01-01 02:00:00   6.0   5\n\ndf.resample('15min').bfill(limit=2)\n                       a    b\n2018-01-01 00:00:00   2.0   1.0\n2018-01-01 00:15:00   NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-02 02:00:00   6.0   5.0",
            "old_name": "backfill",
            "new_name": "bfill",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18790"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.5.7",
            "new_version": "==2.0.8",
            "old_time": "2021-12-21",
            "new_time": "2023-08-30",
            "description": "The code sets environment variables for the PL Trainer with the number of GPUs as 42 and a specific value for another variable. It then parses the environment variables for the Trainer and returns a Namespace object with the specified GPU value.",
            "old_code": "import os\nos.environ[\"PL_TRAINER_GPUS\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\nparse_env_variables(Trainer)\nNamespace(gpus=42)",
            "new_code": "import os\nos.environ[\"PL_TRAINER_DEVICES\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\n_parse_env_variables(Trainer)\nNamespace(devices=42)",
            "old_name": "parse_env_variables",
            "new_name": "_parse_env_variables",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_23215"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.5.5",
            "new_version": "==2.0.5",
            "old_time": "2021-12-07",
            "new_time": "2023-07-10",
            "description": "The code sets environment variables for the PL Trainer with the number of GPUs as 42 and a specific value for another variable. It then parses the environment variables for the Trainer and returns a Namespace object with the specified GPU value.",
            "old_code": "import os\nos.environ[\"PL_TRAINER_GPUS\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\nparse_env_variables(Trainer)\nNamespace(gpus=42)",
            "new_code": "import os\nos.environ[\"PL_TRAINER_DEVICES\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\n_parse_env_variables(Trainer)\nNamespace(devices=42)",
            "old_name": "parse_env_variables",
            "new_name": "_parse_env_variables",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_23180"
        },
        {
            "dependency": "pandas",
            "old_version": "==0.23.3",
            "new_version": "==2.1.4",
            "old_time": "2018-07-07",
            "new_time": "2023-12-08",
            "description": "The code creates an index object based on the input provided, which can be a list of single values, tuples, or lists.",
            "old_code": "_ensure_index(['a', 'b'])\nIndex(['a', 'b'], dtype='object')\n\n_ensure_index([('a', 'a'),  ('b', 'c')])\nIndex([('a', 'a'), ('b', 'c')], dtype='object')\n\n_ensure_index([['a', 'a'], ['b', 'c']])\nMultiIndex(levels=[['a'], ['b', 'c']],\n           labels=[[0, 0], [0, 1]])",
            "new_code": "ensure_index(['a', 'b'])\nIndex(['a', 'b'], dtype='object')\n\nensure_index([('a', 'a'),  ('b', 'c')])\nIndex([('a', 'a'), ('b', 'c')], dtype='object')\n\nensure_index([['a', 'a'], ['b', 'c']])\nMultiIndex(levels=[['a'], ['b', 'c']],\n           labels=[[0, 0], [0, 1]])",
            "old_name": "_ensure_index",
            "new_name": "ensure_index",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_15684"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.65.2",
            "new_version": "==1.15.2",
            "old_time": "2020-08-14",
            "new_time": "2022-11-30",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36499"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.2",
            "new_version": "==1.2.4",
            "old_time": "2020-03-12",
            "new_time": "2021-04-12",
            "description": "This code defines multiple aggregation functions with relabeling for the 'a' column, including 'max' and 'min'.",
            "old_code": "_is_multi_agg_with_relabel(a_max=('a', 'max'),\n                            a_min=('a', 'min'))",
            "new_code": "is_multi_agg_with_relabel(a=\"max\")\nis_multi_agg_with_relabel(a_max=(\"a\", \"max\"), a_min=(\"a\", \"min\"))\nis_multi_agg_with_relabel()",
            "old_name": "_is_multi_agg_with_relabel",
            "new_name": "is_multi_agg_with_relabel",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_16430"
        },
        {
            "dependency": "tensorflow",
            "old_version": "==2.0.2",
            "new_version": "==2.4.1",
            "old_time": "2020-05-12",
            "new_time": "2021-01-21",
            "description": "The code creates a dataset with a batch size determined by the input context, repeats the dataset indefinitely, batches the data, and then shards the dataset based on the input context's number of input pipelines and input pipeline ID. The code then distributes the dataset across replicas using the provided strategy and runs a function on each batch using the strategy.",
            "old_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.experimental_distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "new_code": "def dataset_fn(input_context):\n  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n  d = tf.data.Dataset.from_tensors([[1.]]).repeat().batch(batch_size)\n  return d.shard(\n      input_context.num_input_pipelines, input_context.input_pipeline_id)\n\ninputs = strategy.distribute_datasets_from_function(dataset_fn)\n\nfor batch in inputs:\n  replica_results = strategy.run(replica_fn, args=(batch,))",
            "old_name": "experimental_distribute_datasets_from_function",
            "new_name": "distribute_datasets_from_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_46616"
        },
        {
            "dependency": "ray",
            "old_version": "==0.5.2",
            "new_version": "==2.8.0",
            "old_time": "2018-08-29",
            "new_time": "2023-11-02",
            "description": "This code filters nodes based on the node type \"worker\" in a provider.",
            "old_code": "provider.nodes({TAG_RAY_NODE_TYPE: \"worker\"})",
            "new_code": "provider.non_terminated_nodes({TAG_RAY_NODE_TYPE: \"worker\"})\n[\"node-1\", \"node-2\"]",
            "old_name": "nodes",
            "new_name": "non_terminated_nodes",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_25136"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.1.4",
            "new_version": "==1.3.2",
            "old_time": "2020-10-30",
            "new_time": "2021-08-15",
            "description": "This code checks if the input is an iterable object that is not a string.",
            "old_code": "_iterable_not_string([1, 2, 3])\n_iterable_not_string(\"foo\")\n_iterable_not_string(1)",
            "new_code": "iterable_not_string([1, 2, 3])\nTrue\niterable_not_string(\"foo\")\nFalse\niterable_not_string(1)\nFalse",
            "old_name": "_iterable_not_string",
            "new_name": "iterable_not_string",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_18487"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.6.3",
            "new_version": "==2.1.2",
            "old_time": "2022-05-03",
            "new_time": "2023-11-15",
            "description": "The code loads and reads the README file located in the project root directory and displays its content in HTML format with center alignment.",
            "old_code": "_load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "new_code": "load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "old_name": "_load_readme_description",
            "new_name": "load_readme_description",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_22519"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.5.8",
            "new_version": "==2.0.9",
            "old_time": "2022-01-05",
            "new_time": "2023-09-14",
            "description": "The code sets environment variables for the PL Trainer with the number of GPUs as 42 and a specific value for another variable. It then parses the environment variables for the Trainer and returns a Namespace object with the specified GPU value.",
            "old_code": "import os\nos.environ[\"PL_TRAINER_GPUS\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\nparse_env_variables(Trainer)\nNamespace(gpus=42)",
            "new_code": "import os\nos.environ[\"PL_TRAINER_DEVICES\"] = '42'\nos.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\n_parse_env_variables(Trainer)\nNamespace(devices=42)",
            "old_name": "parse_env_variables",
            "new_name": "_parse_env_variables",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_23232"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.5",
            "new_version": "==2.1.0",
            "old_time": "2020-06-17",
            "new_time": "2023-08-30",
            "description": "The code may potentially modify lambda functions named 'sum' to avoid conflicts.",
            "old_code": "_maybe_mangle_lambdas('sum')\\n\\n_maybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "new_code": "maybe_mangle_lambdas('sum')\n\nmaybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "old_name": "_maybe_mangle_lambdas",
            "new_name": "maybe_mangle_lambdas",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17448"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.69.1",
            "new_version": "==0.85.0",
            "old_time": "2020-10-15",
            "new_time": "2021-07-22",
            "description": "The code creates two DataFrames, df1 and df2, with random values and 20 columns each. It then displays df1 in a table using Streamlit's st.table function and adds the rows of df2 to the table. Next, it creates a line chart using df1 and adds the rows of df2 to the chart. Finally, it creates a Vega-Lite chart with a line mark, x and y encoding, and a named dataset 'some_fancy_name' using df1. It then adds the rows of df2 to the Vega-Lite chart using the named dataset.",
            "old_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n      'some_fancy_name': df1,  # <-- named dataset\n     },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st._legacy_table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table._legacy_add_rows(df2)\n\nmy_chart = st._legacy_line_chart(df1)\nmy_chart._legacy_add_rows(df2)\n\nmy_chart = st._legacy_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._legacy_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_legacy_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_32589"
        },
        {
            "dependency": "imageio",
            "old_version": "==2.1.1",
            "new_version": "==2.21.3",
            "old_time": "2016-12-24",
            "new_time": "2022-09-12",
            "description": "The code parses a byte string containing information about ImageJ software and returns a dictionary with keys 'ImageJ', 'images', and 'hyperstack' mapped to their respective values.",
            "old_code": "description = b'ImageJ=1.11a\\nimages=510\\nhyperstack=true\\n'\nimagej_description_dict(description)  # doctest: +SKIP\n{'ImageJ': '1.11a', 'images': 510, 'hyperstack': True}",
            "new_code": "description = 'ImageJ=1.11a\\nimages=510\\nhyperstack=true\\n'\nimagej_description_metadata(description)\n{'ImageJ': '1.11a', 'images': 510, 'hyperstack': True}",
            "old_name": "imagej_description_dict",
            "new_name": "imagej_description_metadata",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_1196"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.2",
            "new_version": "==2.1.0",
            "old_time": "2021-04-08",
            "new_time": "2021-05-13",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11285"
        },
        {
            "dependency": "jax",
            "old_version": "==0.1.77",
            "new_version": "==0.3.6",
            "old_time": "2020-09-15",
            "new_time": "2022-04-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2466"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.2",
            "new_version": "==2.1.2",
            "old_time": "2021-04-08",
            "new_time": "2021-07-30",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "old_name": "set_batch_size",
            "new_name": "_set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3898"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.65.2",
            "new_version": "==1.3.1",
            "old_time": "2020-08-14",
            "new_time": "2021-12-28",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_36477"
        },
        {
            "dependency": "streamlit",
            "old_version": "==0.40.1",
            "new_version": "==1.29.0",
            "old_time": "2019-06-13",
            "new_time": "2023-11-30",
            "description": "The code creates two DataFrames with random values, displays the first DataFrame in a table, and adds rows from the second DataFrame to the table. It also creates a line chart with the first DataFrame and adds rows from the second DataFrame to the chart. Additionally, it creates a Vega-Lite line chart with specific encoding and datasets, and adds rows from the second DataFrame to the chart using a named dataset.",
            "old_code": "df1 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table = st.table(df1)\n\ndf2 = pd.DataFrame(\n    np.random.randn(50, 20),\n    columns=('col %d' % i for i in range(20)))\n\nmy_table.add_rows(df2)\n\nmy_chart = st.line_chart(df1)\nmy_chart.add_rows(df2)\n\nmy_chart = st.vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "new_code": "df1 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table = st._arrow_table(df1)\n\ndf2 = pd.DataFrame(\n   np.random.randn(50, 20),\n   columns=('col %d' % i for i in range(20)))\n\nmy_table._arrow_add_rows(df2)\n\nmy_chart = st._arrow_line_chart(df1)\nmy_chart._arrow_add_rows(df2)\n\nmy_chart = st._arrow_vega_lite_chart({\n    'mark': 'line',\n    'encoding': {'x': 'a', 'y': 'b'},\n    'datasets': {\n        'some_fancy_name': df1,  # <-- named dataset\n    },\n    'data': {'name': 'some_fancy_name'},\n}),\nmy_chart._arrow_add_rows(some_fancy_name=df2)  # <-- name used as keyword",
            "old_name": "add_rows",
            "new_name": "_arrow_add_rows",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_34223"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.5.3",
            "new_version": "==1.9.4",
            "old_time": "2021-11-24",
            "new_time": "2023-03-01",
            "description": "The code loads and reads the README file located in the project root directory and displays its content in HTML format with center alignment.",
            "old_code": "_load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "new_code": "load_readme_description(_PROJECT_ROOT, \"\", \"\")  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n'<div align=\"center\">...",
            "old_name": "_load_readme_description",
            "new_name": "load_readme_description",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_22263"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.0.1",
            "new_version": "==2.1.4",
            "old_time": "2020-02-05",
            "new_time": "2023-12-08",
            "description": "The code may potentially modify lambda functions named 'sum' to avoid conflicts.",
            "old_code": "_maybe_mangle_lambdas('sum')\\n\\n_maybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "new_code": "maybe_mangle_lambdas('sum')\n\nmaybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP",
            "old_name": "_maybe_mangle_lambdas",
            "new_name": "maybe_mangle_lambdas",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_17304"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.9",
            "new_version": "==0.4.13",
            "old_time": "2021-01-27",
            "new_time": "2023-06-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3137"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.3",
            "old_time": "2021-06-23",
            "new_time": "2021-09-10",
            "description": "This code creates an in-memory dataset using PaddlePaddle framework and sets the number of queues to 12.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "old_name": "set_queue_num",
            "new_name": "_set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5830"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.1",
            "new_version": "==2.3.2",
            "old_time": "2022-07-01",
            "new_time": "2022-08-15",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11402"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.10",
            "new_version": "==0.2.16",
            "old_time": "2021-03-05",
            "new_time": "2021-06-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3152"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.11",
            "new_version": "==0.2.25",
            "old_time": "2021-03-24",
            "new_time": "2021-11-10",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3224"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.11",
            "new_version": "==0.2.28",
            "old_time": "2021-03-24",
            "new_time": "2022-02-02",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3227"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.7",
            "new_version": "==0.2.12",
            "old_time": "2020-12-05",
            "new_time": "2021-04-01",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2956"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.5",
            "new_version": "==0.2.12",
            "old_time": "2020-10-26",
            "new_time": "2021-04-01",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2828"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.5",
            "new_version": "==0.2.24",
            "old_time": "2020-10-26",
            "new_time": "2021-10-19",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2839"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.0.2",
            "old_time": "2021-03-02",
            "new_time": "2021-04-08",
            "description": "The code sets up an in-memory dataset for distributed training with a sleep time of 2 seconds for sending data between nodes.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "old_name": "_set_fleet_send_sleep_seconds",
            "new_name": "set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12217"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.1",
            "new_version": "==1.0.7",
            "old_time": "2020-10-14",
            "new_time": "2020-11-17",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21062"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.2",
            "old_time": "2021-06-23",
            "new_time": "2021-07-30",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a pipe command to run a Python script called \"my_script.py\".",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10009"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.5",
            "new_version": "==0.8.7",
            "old_time": "2020-05-06",
            "new_time": "2020-08-12",
            "description": "The code runs a function `run_me` for 100 iterations, where it sleeps for 1 second in each iteration and logs the values \"hello\" as \"world\" and \"ray\" as \"tune\" using the `track.log` function. The function is executed using Ray Tune for analysis.",
            "old_code": "import time\nfrom ray import tune\nfrom ray.tune import track\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        track.log(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "new_code": "import time\nfrom ray import tune\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        tune.report(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "old_name": "log",
            "new_name": "report",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29396"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.2",
            "old_time": "2021-06-23",
            "new_time": "2021-07-30",
            "description": "The code sets up an in-memory dataset for distributed training with a sleep time of 2 seconds for sending data between nodes.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "old_name": "_set_fleet_send_sleep_seconds",
            "new_name": "set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12268"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code initializes an in-memory dataset for distributed training in PaddlePaddle framework and sets the merging strategy to merge data by line ID.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "old_name": "_set_merge_by_lineid",
            "new_name": "set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12512"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.1",
            "new_version": "==2.4.2",
            "old_time": "2022-12-05",
            "new_time": "2023-02-15",
            "description": "The code creates a dataset using the PaddlePaddle framework and prints out the description of the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "old_name": "desc",
            "new_name": "_desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5744"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.1",
            "new_version": "==2.3.2",
            "old_time": "2022-07-01",
            "new_time": "2022-08-15",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4203"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_14602"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.5",
            "new_version": "==0.2.22",
            "old_time": "2020-10-26",
            "new_time": "2021-10-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2838"
        },
        {
            "dependency": "ray",
            "old_version": "==0.6.3",
            "new_version": "==0.6.6",
            "old_time": "2019-02-07",
            "new_time": "2019-04-18",
            "description": "This code filters nodes based on the node type \"worker\" in a provider.",
            "old_code": "provider.nodes({TAG_RAY_NODE_TYPE: \"worker\"})",
            "new_code": "provider.non_terminated_nodes({TAG_RAY_NODE_TYPE: \"worker\"})\n[\"node-1\", \"node-2\"]",
            "old_name": "nodes",
            "new_name": "non_terminated_nodes",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_25645"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.8",
            "new_version": "==0.2.25",
            "old_time": "2021-01-12",
            "new_time": "2021-11-10",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3032"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.1",
            "new_version": "==1.0.7",
            "old_time": "2020-10-14",
            "new_time": "2020-11-17",
            "description": "Calculate the mean absolute error (MAE) between two tensors x and y.",
            "old_code": "mae = nn.L1Loss(reduction='mean')\nx = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmae_value = mae(x, y)\nprint(mae_value)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmean_absolute_error(x, y)\ntensor(0.2500)",
            "old_name": "mae",
            "new_name": "mean_absolute_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20842"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.3",
            "new_version": "==0.2.15",
            "old_time": "2020-10-14",
            "new_time": "2021-06-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2703"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.3",
            "new_version": "==0.8.7",
            "old_time": "2020-03-24",
            "new_time": "2020-08-12",
            "description": "The code runs a function `run_me` for 100 iterations, where it sleeps for 1 second in each iteration and logs the values \"hello\" as \"world\" and \"ray\" as \"tune\" using the `track.log` function. The function is executed using Ray Tune for analysis.",
            "old_code": "import time\nfrom ray import tune\nfrom ray.tune import track\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        track.log(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "new_code": "import time\nfrom ray import tune\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        tune.report(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "old_name": "log",
            "new_name": "report",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29358"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.4",
            "new_version": "==0.2.12",
            "old_time": "2020-10-20",
            "new_time": "2021-04-01",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2764"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.3",
            "old_time": "2021-06-23",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset using PaddlePaddle framework and sets a download command to read data from AFS (Alibaba File System).",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "old_name": "set_download_cmd",
            "new_name": "_set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5450"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4173"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.11",
            "new_version": "==0.2.16",
            "old_time": "2021-03-24",
            "new_time": "2021-06-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3216"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.1",
            "new_version": "==1.0.7",
            "old_time": "2020-10-14",
            "new_time": "2020-11-17",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21370"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.3",
            "new_version": "==0.2.20",
            "old_time": "2020-10-14",
            "new_time": "2021-09-03",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2708"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.2",
            "new_version": "==2.1.3",
            "old_time": "2021-07-30",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the HDFS configuration for the dataset with the specified file system name and user group information.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "set_hdfs_config",
            "new_name": "_set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5274"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.1",
            "new_version": "==2.4.2",
            "old_time": "2022-12-05",
            "new_time": "2023-02-15",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and sets the number of threads to 12 for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "old_name": "_set_thread",
            "new_name": "set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10663"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset using the PaddlePaddle framework and prints out the description of the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "old_name": "desc",
            "new_name": "_desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5693"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.10",
            "new_version": "==0.2.17",
            "old_time": "2021-03-05",
            "new_time": "2021-07-09",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3153"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.1",
            "new_version": "==1.0.6",
            "old_time": "2020-10-14",
            "new_time": "2020-11-11",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21061"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.2",
            "new_version": "==0.2.19",
            "old_time": "2020-10-14",
            "new_time": "2021-08-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2643"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the variables 'data' and 'label' for use in the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_use_var([data, label])",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "old_name": "set_use_var",
            "new_name": "_set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4363"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.1",
            "new_version": "==2.4.2",
            "old_time": "2022-12-05",
            "new_time": "2023-02-15",
            "description": "This code creates an in-memory dataset using PaddlePaddle framework and sets the number of queues to 12.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "old_name": "set_queue_num",
            "new_name": "_set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5934"
        },
        {
            "dependency": "ray",
            "old_version": "==0.6.1",
            "new_version": "==0.6.5",
            "old_time": "2018-12-24",
            "new_time": "2019-03-22",
            "description": "This code filters nodes based on the node type \"worker\" in a provider.",
            "old_code": "provider.nodes({TAG_RAY_NODE_TYPE: \"worker\"})",
            "new_code": "provider.non_terminated_nodes({TAG_RAY_NODE_TYPE: \"worker\"})\n[\"node-1\", \"node-2\"]",
            "old_name": "nodes",
            "new_name": "non_terminated_nodes",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_25398"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.4",
            "new_version": "==0.8.5",
            "old_time": "2020-04-01",
            "new_time": "2020-05-06",
            "description": "This code splits the traffic for the \"service-name\" between two backend versions, \"backend:v1\" and \"backend:v2\", with a 50/50 distribution.",
            "old_code": "serve.split(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "new_code": "serve.set_traffic(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "old_name": "split",
            "new_name": "set_traffic",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29157"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.4",
            "new_version": "==0.2.22",
            "old_time": "2020-10-20",
            "new_time": "2021-10-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2774"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.1",
            "new_version": "==2.4.2",
            "old_time": "2022-12-05",
            "new_time": "2023-02-15",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the variables 'data' and 'label' for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "new_code": "import paddle.base as base\npaddle.enable_static()\ndataset = base.DatasetFactory().create_dataset()\ndata = paddle.static.data(name=\"data\", shape=[None, 10, 10], dtype=\"int64\")\nlabel = paddle.static.data(name=\"label\", shape=[None, 1], dtype=\"int64\", lod_level=1)\ndataset.set_use_var([data, label])",
            "old_name": "_set_use_var",
            "new_name": "set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10853"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.1",
            "new_version": "==2.3.2",
            "old_time": "2022-07-01",
            "new_time": "2022-08-15",
            "description": "The code creates an in-memory dataset using PaddlePaddle framework.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "old_name": "set_parse_content",
            "new_name": "_set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6293"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.11",
            "new_version": "==0.2.15",
            "old_time": "2021-03-24",
            "new_time": "2021-06-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3215"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates an in-memory dataset using PaddlePaddle framework.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "old_name": "set_parse_content",
            "new_name": "_set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6263"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.0.2",
            "old_time": "2021-03-02",
            "new_time": "2021-04-08",
            "description": "This code initializes a dataset object for distributed training and sets the HDFS configuration for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "_set_hdfs_config",
            "new_name": "set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10887"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.2",
            "new_version": "==2.1.3",
            "old_time": "2021-07-30",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4134"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.3",
            "new_version": "==0.8.7",
            "old_time": "2020-03-24",
            "new_time": "2020-08-12",
            "description": "This code splits the traffic for the \"service-name\" between two backend versions, \"backend:v1\" and \"backend:v2\", with a 50/50 distribution.",
            "old_code": "serve.split(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "new_code": "serve.set_traffic(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "old_name": "split",
            "new_name": "set_traffic",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29149"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.0.2",
            "old_time": "2021-03-02",
            "new_time": "2021-04-08",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12027"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.10",
            "new_version": "==0.2.22",
            "old_time": "2021-03-05",
            "new_time": "2021-10-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3158"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.2",
            "new_version": "==2.1.3",
            "old_time": "2021-07-30",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets a download command for the dataset to read from AFS (Alibaba File System).",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "old_name": "_set_download_cmd",
            "new_name": "set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11143"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.5",
            "new_version": "==0.2.25",
            "old_time": "2020-10-26",
            "new_time": "2021-11-10",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2840"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.8",
            "new_version": "==0.2.17",
            "old_time": "2021-01-12",
            "new_time": "2021-07-09",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3025"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.3",
            "old_time": "2021-06-23",
            "new_time": "2021-09-10",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and enables parsing of instance IDs.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "old_name": "set_parse_ins_id",
            "new_name": "_set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6020"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.2",
            "new_version": "==2.1.3",
            "old_time": "2021-07-30",
            "new_time": "2021-09-10",
            "description": "The code sets up an in-memory dataset for distributed training with a sleep time of 2 seconds for sending data between nodes.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "old_name": "_set_fleet_send_sleep_seconds",
            "new_name": "set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12283"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.3",
            "new_version": "==0.8.5",
            "old_time": "2020-03-24",
            "new_time": "2020-05-06",
            "description": "This code splits the traffic for the \"service-name\" between two backend versions, \"backend:v1\" and \"backend:v2\", with a 50/50 distribution.",
            "old_code": "serve.split(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "new_code": "serve.set_traffic(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "old_name": "split",
            "new_name": "set_traffic",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29147"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.4",
            "new_version": "==0.2.28",
            "old_time": "2020-10-20",
            "new_time": "2022-02-02",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2779"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.9",
            "new_version": "==0.2.28",
            "old_time": "2021-01-27",
            "new_time": "2022-02-02",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3099"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.1",
            "new_version": "==0.2.22",
            "old_time": "2020-10-07",
            "new_time": "2021-10-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2582"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.1",
            "new_version": "==2.5.2",
            "old_time": "2023-07-25",
            "new_time": "2023-10-19",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10485"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.7",
            "new_version": "==0.2.25",
            "old_time": "2020-12-05",
            "new_time": "2021-11-10",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2968"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.2",
            "new_version": "==0.2.15",
            "old_time": "2020-10-14",
            "new_time": "2021-06-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2639"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11372"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.0.2",
            "old_time": "2021-03-02",
            "new_time": "2021-04-08",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11267"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.1",
            "new_version": "==0.2.19",
            "old_time": "2020-10-07",
            "new_time": "2021-08-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2579"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.1",
            "new_version": "==2.5.2",
            "old_time": "2023-07-25",
            "new_time": "2023-10-19",
            "description": "The code creates an in-memory dataset using the PaddlePaddle framework with the ability to parse content.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "old_name": "_set_parse_content",
            "new_name": "set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12005"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.2",
            "new_version": "==2.1.3",
            "old_time": "2021-07-30",
            "new_time": "2021-09-10",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10383"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.11",
            "new_version": "==0.2.14",
            "old_time": "2021-03-24",
            "new_time": "2021-06-10",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3214"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.1",
            "new_version": "==2.4.2",
            "old_time": "2022-12-05",
            "new_time": "2023-02-15",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11613"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.2",
            "new_version": "==2.1.3",
            "old_time": "2021-07-30",
            "new_time": "2021-09-10",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and enables parsing of instance IDs.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "old_name": "set_parse_ins_id",
            "new_name": "_set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6034"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.0.2",
            "old_time": "2021-03-02",
            "new_time": "2021-04-08",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the HDFS configuration for the dataset with the specified file system name and user group information.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "set_hdfs_config",
            "new_name": "_set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5208"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.6",
            "new_version": "==0.2.21",
            "old_time": "2020-11-18",
            "new_time": "2021-09-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2901"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.9",
            "new_version": "==0.2.17",
            "old_time": "2021-01-27",
            "new_time": "2021-07-09",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3089"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.1",
            "new_version": "==0.2.14",
            "old_time": "2020-10-07",
            "new_time": "2021-06-10",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2574"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.5",
            "new_version": "==0.2.16",
            "old_time": "2020-10-26",
            "new_time": "2021-06-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2832"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.1",
            "new_version": "==1.0.8",
            "old_time": "2020-10-14",
            "new_time": "2020-11-24",
            "description": "Calculate the mean absolute error (MAE) between two tensors x and y.",
            "old_code": "mae = nn.L1Loss(reduction='mean')\nx = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmae_value = mae(x, y)\nprint(mae_value)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmean_absolute_error(x, y)\ntensor(0.2500)",
            "old_name": "mae",
            "new_name": "mean_absolute_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20843"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.10",
            "new_version": "==0.2.25",
            "old_time": "2021-03-05",
            "new_time": "2021-11-10",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3160"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.4",
            "new_version": "==0.8.6",
            "old_time": "2020-04-01",
            "new_time": "2020-06-22",
            "description": "This code splits the traffic for the \"service-name\" between two backend versions, \"backend:v1\" and \"backend:v2\", with a 50/50 distribution.",
            "old_code": "serve.split(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "new_code": "serve.set_traffic(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "old_name": "split",
            "new_name": "set_traffic",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29158"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.1",
            "new_version": "==2.3.2",
            "old_time": "2022-07-01",
            "new_time": "2022-08-15",
            "description": "This code creates an in-memory dataset using PaddlePaddle framework and sets the number of queues to 12.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "old_name": "set_queue_num",
            "new_name": "_set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5913"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.7",
            "new_version": "==0.2.13",
            "old_time": "2020-12-05",
            "new_time": "2021-05-04",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2957"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.3",
            "new_version": "==1.0.5",
            "old_time": "2020-10-20",
            "new_time": "2020-11-04",
            "description": "Calculate the mean absolute error (MAE) between two tensors x and y.",
            "old_code": "mae = nn.L1Loss(reduction='mean')\nx = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmae_value = mae(x, y)\nprint(mae_value)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmean_absolute_error(x, y)\ntensor(0.2500)",
            "old_name": "mae",
            "new_name": "mean_absolute_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20928"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.1",
            "new_version": "==1.0.5",
            "old_time": "2020-10-14",
            "new_time": "2020-11-04",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21060"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.11",
            "new_version": "==0.2.24",
            "old_time": "2021-03-24",
            "new_time": "2021-10-19",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3223"
        },
        {
            "dependency": "librosa",
            "old_version": "==0.6.2",
            "new_version": "==0.6.3",
            "old_time": "2018-08-09",
            "new_time": "2019-02-13",
            "description": "Calculate the root mean square energy of the audio signal y.",
            "old_code": "y, sr = librosa.load(librosa.util.example_audio_file())\nlibrosa.feature.rmse(y=y)\n\nS, phase = librosa.magphase(librosa.stft(y))\nrms = librosa.feature.rmse(S=S)\n\nS = librosa.magphase(librosa.stft(y, window=np.ones, center=False))[0]\nlibrosa.feature.rmse(S=S)",
            "new_code": "y, sr = librosa.load(librosa.util.example_audio_file())\nlibrosa.feature.rms(y=y)\n\nS, phase = librosa.magphase(librosa.stft(y))\nrms = librosa.feature.rms(S=S)\n\nimport matplotlib.pyplot as plt\nplt.figure()\nplt.subplot(2, 1, 1)\nplt.semilogy(rms.T, label='RMS Energy')\nplt.xticks([])\nplt.xlim([0, rms.shape[-1]])\nplt.legend(loc='best')\nplt.subplot(2, 1, 2)\nlibrosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),\n...                          y_axis='log', x_axis='time')\nplt.title('log Power spectrogram')\nplt.tight_layout()\n\nS = librosa.magphase(librosa.stft(y, window=np.ones, center=False))[0]\nlibrosa.feature.rms(S=S)",
            "old_name": "rmse",
            "new_name": "rms",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3508"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.11",
            "new_version": "==0.2.27",
            "old_time": "2021-03-24",
            "new_time": "2022-01-18",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3226"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.1",
            "new_version": "==2.5.2",
            "old_time": "2023-07-25",
            "new_time": "2023-10-19",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the HDFS configuration for the dataset with the specified file system name and user group information.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "set_hdfs_config",
            "new_name": "_set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5376"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.2",
            "new_version": "==2.1.3",
            "old_time": "2021-07-30",
            "new_time": "2021-09-10",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12093"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.1",
            "new_version": "==2.4.2",
            "old_time": "2022-12-05",
            "new_time": "2023-02-15",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and then prints the description of the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "old_name": "_desc",
            "new_name": "desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11423"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.1",
            "new_version": "==2.4.2",
            "old_time": "2022-12-05",
            "new_time": "2023-02-15",
            "description": "The code creates an in-memory dataset using PaddlePaddle framework.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "old_name": "set_parse_content",
            "new_name": "_set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6314"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.8",
            "new_version": "==0.2.27",
            "old_time": "2021-01-12",
            "new_time": "2022-01-18",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3034"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.2",
            "new_version": "==1.0.7",
            "old_time": "2020-10-15",
            "new_time": "2020-11-17",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21106"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.3",
            "new_version": "==0.2.28",
            "old_time": "2020-10-14",
            "new_time": "2022-02-02",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2715"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.1",
            "new_version": "==0.8.6",
            "old_time": "2020-01-26",
            "new_time": "2020-06-22",
            "description": "The code runs a function `run_me` for 100 iterations, where it sleeps for 1 second in each iteration and logs the values \"hello\" as \"world\" and \"ray\" as \"tune\" using the `track.log` function. The function is executed using Ray Tune for analysis.",
            "old_code": "import time\nfrom ray import tune\nfrom ray.tune import track\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        track.log(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "new_code": "import time\nfrom ray import tune\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        tune.report(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "old_name": "log",
            "new_name": "report",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29319"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.0.2",
            "old_time": "2021-03-02",
            "new_time": "2021-04-08",
            "description": "The code creates an in-memory dataset for distributed training with the ability to parse instance IDs.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "old_name": "_set_parse_ins_id",
            "new_name": "set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11647"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.2",
            "new_version": "==1.0.6",
            "old_time": "2020-10-15",
            "new_time": "2020-11-11",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21413"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.1",
            "new_version": "==2.4.2",
            "old_time": "2022-12-05",
            "new_time": "2023-02-15",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the HDFS configuration for the dataset with the specified file system name and user group information.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "set_hdfs_config",
            "new_name": "_set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5364"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12132"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the HDFS configuration for the dataset with the specified file system name and user group information.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "set_hdfs_config",
            "new_name": "_set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5313"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.2",
            "new_version": "==2.1.3",
            "old_time": "2021-07-30",
            "new_time": "2021-09-10",
            "description": "The code initializes an in-memory dataset for distributed training in PaddlePaddle framework and sets the merging strategy to merge data by line ID.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "old_name": "_set_merge_by_lineid",
            "new_name": "set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12473"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.3",
            "new_version": "==0.2.13",
            "old_time": "2020-10-14",
            "new_time": "2021-05-04",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2701"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.3",
            "old_time": "2021-06-23",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the number of threads to 12 for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "old_name": "set_thread",
            "new_name": "_set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4120"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.3",
            "old_time": "2021-06-23",
            "new_time": "2021-09-10",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and sets the number of threads to 12 for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "old_name": "_set_thread",
            "new_name": "set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10559"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.7",
            "new_version": "==0.2.28",
            "old_time": "2020-12-05",
            "new_time": "2022-02-02",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2971"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the variables 'data' and 'label' for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "new_code": "import paddle.base as base\npaddle.enable_static()\ndataset = base.DatasetFactory().create_dataset()\ndata = paddle.static.data(name=\"data\", shape=[None, 10, 10], dtype=\"int64\")\nlabel = paddle.static.data(name=\"label\", shape=[None, 1], dtype=\"int64\", lod_level=1)\ndataset.set_use_var([data, label])",
            "old_name": "_set_use_var",
            "new_name": "set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10802"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.0.2",
            "old_time": "2021-03-02",
            "new_time": "2021-04-08",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the time interval for sending data to the distributed training fleet to 2 seconds.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "old_name": "set_fleet_send_sleep_seconds",
            "new_name": "_set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6538"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.1",
            "new_version": "==2.4.2",
            "old_time": "2022-12-05",
            "new_time": "2023-02-15",
            "description": "The code sets up an in-memory dataset for distributed training with a sleep time of 2 seconds for sending data between nodes.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "old_name": "_set_fleet_send_sleep_seconds",
            "new_name": "set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12373"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.2",
            "new_version": "==1.0.6",
            "old_time": "2020-10-15",
            "new_time": "2020-11-11",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21105"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.0.2",
            "old_time": "2021-03-02",
            "new_time": "2021-04-08",
            "description": "The code creates a dataset using the PaddlePaddle framework and prints out the description of the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\nprint(dataset.desc())",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\nprint(dataset._desc())",
            "old_name": "desc",
            "new_name": "_desc",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5588"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.2",
            "new_version": "==2.1.3",
            "old_time": "2021-07-30",
            "new_time": "2021-09-10",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the fleet send batch size to 800.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "old_name": "set_fleet_send_batch_size",
            "new_name": "_set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6414"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.1",
            "new_version": "==2.5.2",
            "old_time": "2023-07-25",
            "new_time": "2023-10-19",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets it to merge data by line ID.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "old_name": "set_merge_by_lineid",
            "new_name": "_set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6896"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.4",
            "new_version": "==0.2.20",
            "old_time": "2020-10-20",
            "new_time": "2021-09-03",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2772"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset object using PaddlePaddle's distributed fleet module and sets a custom pipe command for data processing.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_so_parser_name(\"./abc.so\")",
            "old_name": "_set_pipe_command",
            "new_name": "set_so_parser_name",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10232"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.9",
            "new_version": "==0.2.27",
            "old_time": "2021-01-27",
            "new_time": "2022-01-18",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3098"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.2",
            "old_time": "2021-06-23",
            "new_time": "2021-07-30",
            "description": "This code initializes a dataset object for distributed training and sets the HDFS configuration for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_hdfs_config(\"my_fs_name\", \"my_fs_ugi\")",
            "old_name": "_set_hdfs_config",
            "new_name": "set_hdfs_config",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10938"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.1",
            "new_version": "==2.4.2",
            "old_time": "2022-12-05",
            "new_time": "2023-02-15",
            "description": "The code creates a dataset using PaddlePaddle's fluid framework and sets a pipe command to run a Python script called \"my_script.py\" for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "old_name": "set_pipe_command",
            "new_name": "_set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3844"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.1",
            "new_version": "==2.3.2",
            "old_time": "2022-07-01",
            "new_time": "2022-08-15",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and enables parsing of instance IDs.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "old_name": "set_parse_ins_id",
            "new_name": "_set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6103"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.2",
            "new_version": "==1.0.8",
            "old_time": "2020-10-15",
            "new_time": "2020-11-24",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21107"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.5",
            "new_version": "==0.2.21",
            "old_time": "2020-10-26",
            "new_time": "2021-09-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2837"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.3",
            "new_version": "==0.2.25",
            "old_time": "2020-10-14",
            "new_time": "2021-11-10",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2712"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.1",
            "new_version": "==2.4.2",
            "old_time": "2022-12-05",
            "new_time": "2023-02-15",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and enables parsing of instance IDs.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "old_name": "set_parse_ins_id",
            "new_name": "_set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6124"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.3",
            "new_version": "==0.2.12",
            "old_time": "2020-10-14",
            "new_time": "2021-04-01",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2700"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.9",
            "new_version": "==0.2.12",
            "old_time": "2021-01-27",
            "new_time": "2021-04-01",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3084"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.1",
            "new_version": "==2.5.2",
            "old_time": "2023-07-25",
            "new_time": "2023-10-19",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the fleet send batch size to 800.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "old_name": "set_fleet_send_batch_size",
            "new_name": "_set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6516"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.9",
            "new_version": "==0.2.19",
            "old_time": "2021-01-27",
            "new_time": "2021-08-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3091"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.3",
            "new_version": "==1.0.5",
            "old_time": "2020-10-20",
            "new_time": "2020-11-04",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21456"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.3",
            "old_time": "2021-06-23",
            "new_time": "2021-09-10",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10369"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.2",
            "old_time": "2021-06-23",
            "new_time": "2021-07-30",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11508"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.2",
            "new_version": "==2.1.3",
            "old_time": "2021-07-30",
            "new_time": "2021-09-10",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the variables 'data' and 'label' for use in the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_use_var([data, label])",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "old_name": "set_use_var",
            "new_name": "_set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4324"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.0.2",
            "old_time": "2021-03-02",
            "new_time": "2021-04-08",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the variables 'data' and 'label' for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "new_code": "import paddle.base as base\npaddle.enable_static()\ndataset = base.DatasetFactory().create_dataset()\ndata = paddle.static.data(name=\"data\", shape=[None, 10, 10], dtype=\"int64\")\nlabel = paddle.static.data(name=\"label\", shape=[None, 1], dtype=\"int64\", lod_level=1)\ndataset.set_use_var([data, label])",
            "old_name": "_set_use_var",
            "new_name": "set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10697"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.3",
            "new_version": "==1.0.6",
            "old_time": "2020-10-20",
            "new_time": "2020-11-11",
            "description": "Calculate the mean absolute error (MAE) between two tensors x and y.",
            "old_code": "mae = nn.L1Loss(reduction='mean')\nx = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmae_value = mae(x, y)\nprint(mae_value)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmean_absolute_error(x, y)\ntensor(0.2500)",
            "old_name": "mae",
            "new_name": "mean_absolute_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20929"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.0.2",
            "old_time": "2021-03-02",
            "new_time": "2021-04-08",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and sets the number of threads to 12 for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "old_name": "_set_thread",
            "new_name": "set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10507"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.5",
            "new_version": "==0.2.13",
            "old_time": "2020-10-26",
            "new_time": "2021-05-04",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2829"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.2",
            "new_version": "==1.0.4",
            "old_time": "2020-10-15",
            "new_time": "2020-10-27",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21411"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.5",
            "new_version": "==0.2.27",
            "old_time": "2020-10-26",
            "new_time": "2022-01-18",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2842"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.1",
            "new_version": "==1.0.4",
            "old_time": "2020-10-14",
            "new_time": "2020-10-27",
            "description": "Calculate the mean absolute error (MAE) between two tensors x and y.",
            "old_code": "mae = nn.L1Loss(reduction='mean')\nx = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmae_value = mae(x, y)\nprint(mae_value)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmean_absolute_error(x, y)\ntensor(0.2500)",
            "old_name": "mae",
            "new_name": "mean_absolute_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20839"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the fleet send batch size to 800.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "old_name": "set_fleet_send_batch_size",
            "new_name": "_set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6453"
        },
        {
            "dependency": "pandas",
            "old_version": "==1.5.1",
            "new_version": "==1.5.3",
            "old_time": "2022-10-18",
            "new_time": "2023-01-19",
            "description": "The code performs resampling on a pandas Series or DataFrame with a specified frequency and backfills missing values within the resampled intervals.",
            "old_code": "s = pd.Series([1, 2, 3],\n              index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01-01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').backfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').backfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n                  index=pd.date_range('20180101', periods=3,\n                                      freq='h'))\ndf\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').backfill()\n                   a  b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 00:30:00  NaN  3\n2018-01-01 01:00:00  NaN  3\n2018-01-01 01:30:00  6.0  5\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('15min').backfill(limit=2)\n                   a    b\n2018-01-01 00:00:00  2.0  1.0\n2018-01-01 00:15:00  NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-01 02:00:00   6.0   5.0",
            "new_code": "s = pd.Series([1, 2, 3],\n...               index=pd.date_range('20180101', periods=3, freq='h'))\ns\n2018-01-01 00:00:00    1\n2018-01-01 01:00:00    2\n2018-01:01 02:00:00    3\nFreq: H, dtype: int64\n\ns.resample('30min').bfill()\n2018-01-01 00:00:00    1\n2018-01-01 00:30:00    2\n2018-01-01 01:00:00    2\n2018-01-01 01:30:00    3\n2018-01-01 02:00:00    3\nFreq: 30T, dtype: int64\n\ns.resample('15min').bfill(limit=2)\n2018-01-01 00:00:00    1.0\n2018-01-01 00:15:00    NaN\n2018-01-01 00:30:00    2.0\n2018-01-01 00:45:00    2.0\n2018-01-01 01:00:00    2.0\n2018-01-01 01:15:00    NaN\n2018-01-01 01:30:00    3.0\n2018-01-01 01:45:00    3.0\n2018-01-01 02:00:00    3.0\nFreq: 15T, dtype: float64\n\ndf = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},\n...                   index=pd.date_range('20180101', periods=3,\n...                                       freq='h'))\ndf\n                       a    b\n2018-01-01 00:00:00  2.0  1\n2018-01-01 01:00:00  NaN  3\n2018-01-01 02:00:00  6.0  5\n\ndf.resample('30min').bfill()\n                       a    b\n2018-01-01 00:00:00  2.0   1\n2018-01-01 00:30:00   NaN   3\n2018-01-01 01:00:00   NaN   3\n2018-01-01 01:30:00   6.0   5\n2018-01-01 02:00:00   6.0   5\n\ndf.resample('15min').bfill(limit=2)\n                       a    b\n2018-01-01 00:00:00   2.0   1.0\n2018-01-01 00:15:00   NaN   NaN\n2018-01-01 00:30:00   NaN   3.0\n2018-01-01 00:45:00   NaN   3.0\n2018-01-01 01:00:00   NaN   3.0\n2018-01-01 01:15:00   NaN   NaN\n2018-01-01 01:30:00   6.0   5.0\n2018-01-01 01:45:00   6.0   5.0\n2018-01-02 02:00:00   6.0   5.0",
            "old_name": "backfill",
            "new_name": "bfill",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_19454"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.1",
            "new_version": "==2.3.2",
            "old_time": "2022-07-01",
            "new_time": "2022-08-15",
            "description": "The code creates an in-memory dataset using the PaddlePaddle framework with the ability to parse content.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "old_name": "_set_parse_content",
            "new_name": "set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11972"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.1",
            "new_version": "==2.5.2",
            "old_time": "2023-07-25",
            "new_time": "2023-10-19",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_14665"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates an in-memory dataset using the PaddlePaddle framework with the ability to parse content.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "old_name": "_set_parse_content",
            "new_name": "set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11942"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.2",
            "old_time": "2021-06-23",
            "new_time": "2021-07-30",
            "description": "The code creates a dataset using PaddlePaddle framework and sets a download command to read data from AFS (Alibaba File System).",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "old_name": "set_download_cmd",
            "new_name": "_set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5449"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.3",
            "new_version": "==0.2.21",
            "old_time": "2020-10-14",
            "new_time": "2021-09-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2709"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.3",
            "new_version": "==1.0.4",
            "old_time": "2020-10-20",
            "new_time": "2020-10-27",
            "description": "The code calculates the Root Mean Squared Logarithmic Error (RMSLE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nrmsle(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_log_error(x, y)",
            "old_name": "rmsle",
            "new_name": "mean_squared_log_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21455"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.3",
            "old_time": "2021-06-23",
            "new_time": "2021-09-10",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11509"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.4",
            "new_version": "==0.2.14",
            "old_time": "2020-10-20",
            "new_time": "2021-06-10",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2766"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.3",
            "old_time": "2021-06-23",
            "new_time": "2021-09-10",
            "description": "The code initializes an in-memory dataset for distributed training in PaddlePaddle framework and sets the merging strategy to merge data by line ID.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "old_name": "_set_merge_by_lineid",
            "new_name": "set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12459"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.2",
            "new_version": "==0.2.20",
            "old_time": "2020-10-14",
            "new_time": "2021-09-03",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2644"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.1",
            "new_version": "==0.2.25",
            "old_time": "2020-10-07",
            "new_time": "2021-11-10",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2584"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.1",
            "new_version": "==0.8.7",
            "old_time": "2020-01-26",
            "new_time": "2020-08-12",
            "description": "This code splits the traffic for the \"service-name\" between two backend versions, \"backend:v1\" and \"backend:v2\", with a 50/50 distribution.",
            "old_code": "serve.split(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "new_code": "serve.set_traffic(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "old_name": "split",
            "new_name": "set_traffic",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29129"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.1",
            "new_version": "==0.2.21",
            "old_time": "2020-10-07",
            "new_time": "2021-09-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2581"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.1",
            "new_version": "==2.5.2",
            "old_time": "2023-07-25",
            "new_time": "2023-10-19",
            "description": "The code creates a dataset using the PaddlePaddle framework and sets the variables 'data' and 'label' for use in the dataset.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_use_var([data, label])",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_use_var([data, label])",
            "old_name": "set_use_var",
            "new_name": "_set_use_var",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4426"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.2",
            "old_time": "2021-06-23",
            "new_time": "2021-07-30",
            "description": "This code creates a dataset object using the paddle.distributed.fleet.DatasetBase class and sets the number of threads to 12 for the dataset.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_thread(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_thread(12)",
            "old_name": "_set_thread",
            "new_name": "set_thread",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10558"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.1",
            "new_version": "==1.0.5",
            "old_time": "2020-10-14",
            "new_time": "2020-11-04",
            "description": "Calculate the mean absolute error (MAE) between two tensors x and y.",
            "old_code": "mae = nn.L1Loss(reduction='mean')\nx = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmae_value = mae(x, y)\nprint(mae_value)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmean_absolute_error(x, y)\ntensor(0.2500)",
            "old_name": "mae",
            "new_name": "mean_absolute_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20840"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets a download command for the dataset to read from AFS (Alibaba File System).",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "old_name": "_set_download_cmd",
            "new_name": "set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11182"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.2",
            "old_time": "2021-06-23",
            "new_time": "2021-07-30",
            "description": "This code creates an in-memory dataset using PaddlePaddle framework and sets the number of queues to 12.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "old_name": "set_queue_num",
            "new_name": "_set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5829"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.1",
            "new_version": "==2.3.2",
            "old_time": "2022-07-01",
            "new_time": "2022-08-15",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_14632"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.8",
            "new_version": "==0.2.14",
            "old_time": "2021-01-12",
            "new_time": "2021-06-10",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3022"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.11",
            "new_version": "==0.2.18",
            "old_time": "2021-03-24",
            "new_time": "2021-07-21",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3218"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.1",
            "new_version": "==1.0.8",
            "old_time": "2020-10-14",
            "new_time": "2020-11-24",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21063"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.8",
            "new_version": "==0.2.22",
            "old_time": "2021-01-12",
            "new_time": "2021-10-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3030"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.2",
            "old_time": "2021-06-23",
            "new_time": "2021-07-30",
            "description": "The code creates an in-memory dataset using PaddlePaddle framework.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "old_name": "set_parse_content",
            "new_name": "_set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6209"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.2",
            "old_time": "2021-06-23",
            "new_time": "2021-07-30",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "old_name": "set_batch_size",
            "new_name": "_set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3929"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.0.1",
            "new_version": "==2.0.2",
            "old_time": "2021-03-02",
            "new_time": "2021-04-08",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets it to merge data by line ID.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "old_name": "set_merge_by_lineid",
            "new_name": "_set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6728"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.1",
            "new_version": "==0.2.20",
            "old_time": "2020-10-07",
            "new_time": "2021-09-03",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2580"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.1",
            "new_version": "==2.3.2",
            "old_time": "2022-07-01",
            "new_time": "2022-08-15",
            "description": "The code creates an in-memory dataset for distributed training with the ability to parse instance IDs.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_ins_id(True)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_ins_id(True)",
            "old_name": "_set_parse_ins_id",
            "new_name": "set_parse_ins_id",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11782"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.1",
            "new_version": "==2.4.2",
            "old_time": "2022-12-05",
            "new_time": "2023-02-15",
            "description": "The code initializes an in-memory dataset for distributed training in PaddlePaddle framework and sets the merging strategy to merge data by line ID.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_merge_by_lineid()",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_merge_by_lineid()",
            "old_name": "_set_merge_by_lineid",
            "new_name": "set_merge_by_lineid",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12563"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.1",
            "new_version": "==1.0.6",
            "old_time": "2020-10-14",
            "new_time": "2020-11-11",
            "description": "Calculate the mean absolute error (MAE) between two tensors x and y.",
            "old_code": "mae = nn.L1Loss(reduction='mean')\nx = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmae_value = mae(x, y)\nprint(mae_value)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmean_absolute_error(x, y)\ntensor(0.2500)",
            "old_name": "mae",
            "new_name": "mean_absolute_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20841"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.3",
            "new_version": "==1.0.8",
            "old_time": "2020-10-20",
            "new_time": "2020-11-24",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21151"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.2",
            "new_version": "==1.0.5",
            "old_time": "2020-10-15",
            "new_time": "2020-11-04",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21104"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.6",
            "new_version": "==0.2.22",
            "old_time": "2020-11-18",
            "new_time": "2021-10-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2902"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.3",
            "new_version": "==1.0.4",
            "old_time": "2020-10-20",
            "new_time": "2020-10-27",
            "description": "Calculate the mean squared error (MSE) between two tensors x and y.",
            "old_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmse(x, y)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\n\ny = torch.tensor([0., 1, 2, 2])\n\nmean_squared_error(x, y)",
            "old_name": "mse",
            "new_name": "mean_squared_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_21147"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset using PaddlePaddle's fluid framework and sets a pipe command to run a Python script called \"my_script.py\" for data processing.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_pipe_command(\"python my_script.py\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.dataset.DatasetBase()\ndataset._set_pipe_command(\"python my_script.py\")",
            "old_name": "set_pipe_command",
            "new_name": "_set_pipe_command",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3793"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.5",
            "new_version": "==0.2.20",
            "old_time": "2020-10-26",
            "new_time": "2021-09-03",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2836"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "old_name": "set_batch_size",
            "new_name": "_set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3983"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates a dataset using PaddlePaddle framework and sets a download command to read data from AFS (Alibaba File System).",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_download_cmd(\"./read_from_afs\")",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_download_cmd(\"./read_from_afs\")",
            "old_name": "set_download_cmd",
            "new_name": "_set_download_cmd",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_5503"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.2",
            "new_version": "==0.2.14",
            "old_time": "2020-10-14",
            "new_time": "2021-06-10",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2638"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.3",
            "old_time": "2021-06-23",
            "new_time": "2021-09-10",
            "description": "The code creates an in-memory dataset using PaddlePaddle framework.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_parse_content(True)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_parse_content(True)",
            "old_name": "set_parse_content",
            "new_name": "_set_parse_content",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6210"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.3",
            "old_time": "2021-06-23",
            "new_time": "2021-09-10",
            "description": "The code creates an in-memory dataset using PaddlePaddle's fluid framework and sets the time interval for sending data to the distributed training fleet to 2 seconds.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_sleep_seconds(2)",
            "new_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_sleep_seconds(2)",
            "old_name": "set_fleet_send_sleep_seconds",
            "new_name": "_set_fleet_send_sleep_seconds",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_6590"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.2",
            "new_version": "==0.8.7",
            "old_time": "2020-02-24",
            "new_time": "2020-08-12",
            "description": "This code splits the traffic for the \"service-name\" between two backend versions, \"backend:v1\" and \"backend:v2\", with a 50/50 distribution.",
            "old_code": "serve.split(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "new_code": "serve.set_traffic(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "old_name": "split",
            "new_name": "set_traffic",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29139"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.8",
            "new_version": "==0.2.16",
            "old_time": "2021-01-12",
            "new_time": "2021-06-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3024"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.1",
            "new_version": "==0.8.6",
            "old_time": "2020-01-26",
            "new_time": "2020-06-22",
            "description": "This code splits the traffic for the \"service-name\" between two backend versions, \"backend:v1\" and \"backend:v2\", with a 50/50 distribution.",
            "old_code": "serve.split(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "new_code": "serve.set_traffic(\"service-name\", {\n    \"backend:v1\": 0.5,\n    \"backend:v2\": 0.5\n})",
            "old_name": "split",
            "new_name": "set_traffic",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29128"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.1",
            "new_version": "==2.5.2",
            "old_time": "2023-07-25",
            "new_time": "2023-10-19",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_12195"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.8",
            "new_version": "==0.2.19",
            "old_time": "2021-01-12",
            "new_time": "2021-08-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3027"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.3",
            "new_version": "==1.0.8",
            "old_time": "2020-10-20",
            "new_time": "2020-11-24",
            "description": "Calculate the mean absolute error (MAE) between two tensors x and y.",
            "old_code": "mae = nn.L1Loss(reduction='mean')\nx = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmae_value = mae(x, y)\nprint(mae_value)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmean_absolute_error(x, y)\ntensor(0.2500)",
            "old_name": "mae",
            "new_name": "mean_absolute_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20931"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.3.1",
            "new_version": "==2.3.2",
            "old_time": "2022-07-01",
            "new_time": "2022-08-15",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10452"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.10",
            "new_version": "==0.2.13",
            "old_time": "2021-03-05",
            "new_time": "2021-05-04",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3149"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.2",
            "new_version": "==1.0.6",
            "old_time": "2020-10-15",
            "new_time": "2020-11-11",
            "description": "Calculate the mean absolute error (MAE) between two tensors x and y.",
            "old_code": "mae = nn.L1Loss(reduction='mean')\nx = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmae_value = mae(x, y)\nprint(mae_value)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmean_absolute_error(x, y)\ntensor(0.2500)",
            "old_name": "mae",
            "new_name": "mean_absolute_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20885"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.1",
            "new_version": "==2.1.2",
            "old_time": "2021-06-23",
            "new_time": "2021-07-30",
            "description": "The code sets up an in-memory dataset for distributed training with a batch size of 800.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_fleet_send_batch_size(800)",
            "new_code": "dataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_fleet_send_batch_size(800)",
            "old_name": "_set_fleet_send_batch_size",
            "new_name": "set_fleet_send_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_14548"
        },
        {
            "dependency": "ray",
            "old_version": "==0.8.4",
            "new_version": "==0.8.6",
            "old_time": "2020-04-01",
            "new_time": "2020-06-22",
            "description": "The code runs a function `run_me` for 100 iterations, where it sleeps for 1 second in each iteration and logs the values \"hello\" as \"world\" and \"ray\" as \"tune\" using the `track.log` function. The function is executed using Ray Tune for analysis.",
            "old_code": "import time\nfrom ray import tune\nfrom ray.tune import track\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        track.log(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "new_code": "import time\nfrom ray import tune\n\ndef run_me(config):\n    for iter in range(100):\n        time.sleep(1)\n        tune.report(hello=\"world\", ray=\"tune\")\n\nanalysis = tune.run(run_me)",
            "old_name": "log",
            "new_name": "report",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_29376"
        },
        {
            "dependency": "librosa",
            "old_version": "==0.6.1",
            "new_version": "==0.6.3",
            "old_time": "2018-05-24",
            "new_time": "2019-02-13",
            "description": "Calculate the root mean square energy of the audio signal y.",
            "old_code": "y, sr = librosa.load(librosa.util.example_audio_file())\nlibrosa.feature.rmse(y=y)\n\nS, phase = librosa.magphase(librosa.stft(y))\nrms = librosa.feature.rmse(S=S)\n\nS = librosa.magphase(librosa.stft(y, window=np.ones, center=False))[0]\nlibrosa.feature.rmse(S=S)",
            "new_code": "y, sr = librosa.load(librosa.util.example_audio_file())\nlibrosa.feature.rms(y=y)\n\nS, phase = librosa.magphase(librosa.stft(y))\nrms = librosa.feature.rms(S=S)\n\nimport matplotlib.pyplot as plt\nplt.figure()\nplt.subplot(2, 1, 1)\nplt.semilogy(rms.T, label='RMS Energy')\nplt.xticks([])\nplt.xlim([0, rms.shape[-1]])\nplt.legend(loc='best')\nplt.subplot(2, 1, 2)\nlibrosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),\n...                          y_axis='log', x_axis='time')\nplt.title('log Power spectrogram')\nplt.tight_layout()\n\nS = librosa.magphase(librosa.stft(y, window=np.ones, center=False))[0]\nlibrosa.feature.rms(S=S)",
            "old_name": "rmse",
            "new_name": "rms",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_3499"
        },
        {
            "dependency": "pytorch-lightning",
            "old_version": "==1.0.3",
            "new_version": "==1.0.4",
            "old_time": "2020-10-20",
            "new_time": "2020-10-27",
            "description": "Calculate the mean absolute error (MAE) between two tensors x and y.",
            "old_code": "mae = nn.L1Loss(reduction='mean')\nx = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmae_value = mae(x, y)\nprint(mae_value)",
            "new_code": "x = torch.tensor([0., 1, 2, 3])\ny = torch.tensor([0., 1, 2, 2])\nmean_absolute_error(x, y)\ntensor(0.2500)",
            "old_name": "mae",
            "new_name": "mean_absolute_error",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_20927"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.1",
            "new_version": "==2.5.2",
            "old_time": "2023-07-25",
            "new_time": "2023-10-19",
            "description": "The code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle.fluid as fluid\ndataset = fluid.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "new_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "old_name": "set_batch_size",
            "new_name": "_set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_4046"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.4",
            "new_version": "==0.2.16",
            "old_time": "2020-10-20",
            "new_time": "2021-06-23",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2768"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.2.1",
            "new_version": "==2.2.2",
            "old_time": "2021-11-30",
            "new_time": "2022-01-18",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11562"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.6",
            "new_version": "==0.2.19",
            "old_time": "2020-11-18",
            "new_time": "2021-08-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2899"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.4.1",
            "new_version": "==2.4.2",
            "old_time": "2022-12-05",
            "new_time": "2023-02-15",
            "description": "This code creates a dataset object using the PaddlePaddle framework and sets the batch size to 128.",
            "old_code": "import paddle\ndataset = paddle.distributed.fleet.DatasetBase()\ndataset._set_batch_size(128)",
            "new_code": "dataset = base.DatasetFactory().create_dataset()\ndataset.set_batch_size(128)",
            "old_name": "_set_batch_size",
            "new_name": "set_batch_size",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_10473"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.1.2",
            "new_version": "==2.1.3",
            "old_time": "2021-07-30",
            "new_time": "2021-09-10",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11523"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.7",
            "new_version": "==0.2.22",
            "old_time": "2020-12-05",
            "new_time": "2021-10-13",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2966"
        },
        {
            "dependency": "paddlepaddle-gpu",
            "old_version": "==2.5.1",
            "new_version": "==2.5.2",
            "old_time": "2023-07-25",
            "new_time": "2023-10-19",
            "description": "The code creates an in-memory dataset with 12 queues for distributed computing using PaddlePaddle framework.",
            "old_code": "import paddle\npaddle.enable_static()\ndataset = paddle.distributed.InMemoryDataset()\ndataset._set_queue_num(12)",
            "new_code": "import paddle.base as base\ndataset = base.DatasetFactory().create_dataset(\"InMemoryDataset\")\ndataset.set_queue_num(12)",
            "old_name": "_set_queue_num",
            "new_name": "set_queue_num",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_11625"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.1",
            "new_version": "==0.2.17",
            "old_time": "2020-10-07",
            "new_time": "2021-07-09",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2577"
        },
        {
            "dependency": "jax",
            "old_version": "==0.2.6",
            "new_version": "==0.2.27",
            "old_time": "2020-11-18",
            "new_time": "2022-01-18",
            "description": "The code defines a function that calculates the dot product of a matrix with its transpose and then waits for the result to be ready. The function is then called with a matrix of ones with dimensions 1000x1000.",
            "old_code": "@jax.profiler.trace_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\nf(jnp.ones((1000, 1000))",
            "new_code": "@jax.profiler.annotate_function\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()\n\n@partial(jax.profiler.trace_function, name=\"event_name\")\ndef f(x):\n    return jnp.dot(x, x.T).block_until_ready()",
            "old_name": "trace_function",
            "new_name": "annotate_function",
            "type": "name_change",
            "edit_order": "old_to_new",
            "language": "python",
            "task": "code_editing",
            "source": "library_source_code",
            "id": "old_to_new_2906"
        }
    ]
}