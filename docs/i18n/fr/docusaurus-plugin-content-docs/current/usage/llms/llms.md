

# ü§ñ Backends LLM

OpenHands peut se connecter √† n'importe quel LLM pris en charge par LiteLLM. Cependant, il n√©cessite un mod√®le puissant pour fonctionner.

## Recommandations de mod√®les

Sur la base d'une √©valuation r√©cente des mod√®les de langage pour les t√¢ches de codage (en utilisant le jeu de donn√©es SWE-bench), nous pouvons fournir quelques recommandations pour la s√©lection des mod√®les. L'analyse compl√®te se trouve dans [cet article de blog](https://www.all-hands.dev/blog/evaluation-of-llms-as-coding-agents-on-swe-bench-at-30x-speed).

Lors du choix d'un mod√®le, tenez compte √† la fois de la qualit√© des sorties et des co√ªts associ√©s. Voici un r√©sum√© des r√©sultats :

- Claude 3.5 Sonnet est le meilleur d'une bonne marge, atteignant un taux de r√©solution de 27% avec l'agent par d√©faut dans OpenHands.
- GPT-4o est √† la tra√Æne, et o1-mini a en fait obtenu des r√©sultats l√©g√®rement inf√©rieurs √† ceux de GPT-4o. Nous avons analys√© les r√©sultats un peu, et bri√®vement, il semblait que o1 "r√©fl√©chissait trop" parfois, effectuant des t√¢ches de configuration d'environnement suppl√©mentaires alors qu'il aurait pu simplement aller de l'avant et terminer la t√¢che.
- Enfin, les mod√®les ouverts les plus puissants √©taient Llama 3.1 405 B et deepseek-v2.5, et ils ont obtenu des r√©sultats raisonnables, surpassant m√™me certains des mod√®les ferm√©s.

Veuillez vous r√©f√©rer √† [l'article complet](https://www.all-hands.dev/blog/evaluation-of-llms-as-coding-agents-on-swe-bench-at-30x-speed) pour plus de d√©tails.

Sur la base de ces r√©sultats et des commentaires de la communaut√©, il a √©t√© v√©rifi√© que les mod√®les suivants fonctionnent raisonnablement bien avec OpenHands :

- claude-3-5-sonnet (recommand√©)
- gpt-4 / gpt-4o
- llama-3.1-405b
- deepseek-v2.5

:::warning
OpenHands enverra de nombreuses invites au LLM que vous configurez. La plupart de ces LLM sont payants, alors assurez-vous de d√©finir des limites de d√©penses et de surveiller l'utilisation.
:::

Si vous avez r√©ussi √† ex√©cuter OpenHands avec des LLM sp√©cifiques qui ne figurent pas dans la liste, veuillez les ajouter √† la liste v√©rifi√©e. Nous vous encourageons √©galement √† ouvrir une PR pour partager votre processus de configuration afin d'aider les autres utilisant le m√™me fournisseur et LLM !

Pour une liste compl√®te des fournisseurs et des mod√®les disponibles, veuillez consulter la [documentation litellm](https://docs.litellm.ai/docs/providers).

:::note
La plupart des mod√®les locaux et open source actuels ne sont pas aussi puissants. Lorsque vous utilisez de tels mod√®les, vous pouvez constater de longs temps d'attente entre les messages, des r√©ponses m√©diocres ou des erreurs concernant du JSON malform√©. OpenHands ne peut √™tre aussi puissant que les mod√®les qui le pilotent. Cependant, si vous en trouvez qui fonctionnent, veuillez les ajouter √† la liste v√©rifi√©e ci-dessus.
:::

## Configuration LLM

Les √©l√©ments suivants peuvent √™tre d√©finis dans l'interface utilisateur d'OpenHands via les param√®tres :

- `Fournisseur LLM`
- `Mod√®le LLM`
- `Cl√© API`
- `URL de base` (via `Param√®tres avanc√©s`)

Certains param√®tres peuvent √™tre n√©cessaires pour certains LLM/fournisseurs qui ne peuvent pas √™tre d√©finis via l'interface utilisateur. Au lieu de cela, ceux-ci peuvent √™tre d√©finis via des variables d'environnement pass√©es √† la [commande docker run](/modules/usage/installation#start-the-app) en utilisant `-e` :

- `LLM_API_VERSION`
- `LLM_EMBEDDING_MODEL`
- `LLM_EMBEDDING_DEPLOYMENT_NAME`
- `LLM_DROP_PARAMS`
- `LLM_DISABLE_VISION`
- `LLM_CACHING_PROMPT`

Nous avons quelques guides pour ex√©cuter OpenHands avec des fournisseurs de mod√®les sp√©cifiques :

- [Azure](llms/azure-llms)
- [Google](llms/google-llms)
- [Groq](llms/groq)
- [OpenAI](llms/openai-llms)
- [OpenRouter](llms/openrouter)

### Nouvelles tentatives d'API et limites de d√©bit

Les fournisseurs de LLM ont g√©n√©ralement des limites de d√©bit, parfois tr√®s basses, et peuvent n√©cessiter de nouvelles tentatives. OpenHands r√©essaiera automatiquement les requ√™tes s'il re√ßoit une erreur de limite de d√©bit (code d'erreur 429), une erreur de connexion API ou d'autres erreurs transitoires.

Vous pouvez personnaliser ces options selon vos besoins pour le fournisseur que vous utilisez. Consultez leur documentation et d√©finissez les variables d'environnement suivantes pour contr√¥ler le nombre de nouvelles tentatives et le temps entre les tentatives :

- `LLM_NUM_RETRIES` (Par d√©faut 8)
- `LLM_RETRY_MIN_WAIT` (Par d√©faut 15 secondes)
- `LLM_RETRY_MAX_WAIT` (Par d√©faut 120 secondes)
- `LLM_RETRY_MULTIPLIER` (Par d√©faut 2)

Si vous ex√©cutez OpenHands en mode d√©veloppement, vous pouvez √©galement d√©finir ces options dans le fichier `config.toml` :

```toml
[llm]
num_retries = 8
retry_min_wait = 15
retry_max_wait = 120
retry_multiplier = 2
```
