---
sidebar_position: 5
---

# üöß D√©pannage

Il existe certains messages d'erreur qui sont souvent signal√©s par les utilisateurs.

Nous essaierons de rendre le processus d'installation plus facile et ces messages d'erreur
mieux √† l'avenir. Mais pour l'instant, vous pouvez rechercher votre message d'erreur ci-dessous et voir s'il existe des solutions de contournement.

Pour chacun de ces messages d'erreur, **il existe un probl√®me existant**. Veuillez ne pas
ouvrir un nouveau probl√®me - commentez simplement dessus.

Si vous trouvez plus d'informations ou une solution de contournement pour l'un de ces probl√®mes, veuillez ouvrir un *PR* pour ajouter des d√©tails √† ce fichier.

:::tip
Si vous utilisez Windows et que vous rencontrez des probl√®mes, consultez notre [guide pour les utilisateurs de Windows (WSL)](troubleshooting/windows).
:::

## Impossible de se connecter √† Docker

[Probl√®me GitHub](https://github.com/All-Hands-AI/OpenHands/issues/1226)

### Sympt√¥mes

```bash
Erreur lors de la cr√©ation du contr√¥leur. Veuillez v√©rifier que Docker est en cours d'ex√©cution et visitez `https://docs.all-hands.dev/modules/usage/troubleshooting` pour plus d'informations sur le d√©bogage.
```

```bash
docker.errors.DockerException: Erreur lors de la r√©cup√©ration de la version de l'API du serveur : ('Connection aborted.', FileNotFoundError(2, 'Aucun fichier ou r√©pertoire de ce type'))
```

### D√©tails

OpenHands utilise un conteneur Docker pour effectuer son travail en toute s√©curit√©, sans risquer de briser votre machine.

### Solutions de contournement

* Ex√©cutez `docker ps` pour vous assurer que docker est en cours d'ex√©cution
* Assurez-vous que vous n'avez pas besoin de `sudo` pour ex√©cuter docker [voir ici](https://www.baeldung.com/linux/docker-run-without-sudo)
* Si vous √™tes sur un Mac, v√©rifiez les [exigences en mati√®re d'autorisations](https://docs.docker.com/desktop/mac/permission-requirements/) et envisagez particuli√®rement d'activer l'option `Allow the default Docker socket to be used` sous `Settings > Advanced` dans Docker Desktop.
* De plus, mettez √† jour Docker vers la derni√®re version sous `Check for Updates`

## Impossible de se connecter √† la bo√Æte SSH

[Probl√®me GitHub](https://github.com/All-Hands-AI/OpenHands/issues/1156)

### Sympt√¥mes

```python
self.shell = DockerSSHBox(
...
pexpect.pxssh.ExceptionPxssh: Impossible d'√©tablir une connexion avec l'h√¥te
```

### D√©tails

Par d√©faut, OpenHands se connecte √† un conteneur en cours d'ex√©cution via SSH. Sur certaines machines,
en particulier Windows, cela semble √©chouer.

### Solutions de contournement

* Red√©marrez votre ordinateur (parfois cela fonctionne)
* Assurez-vous d'avoir les derni√®res versions de WSL et Docker
* V√©rifiez que votre distribution dans WSL est √©galement √† jour
* Essayez [ce guide de r√©installation](https://github.com/All-Hands-AI/OpenHands/issues/1156#issuecomment-2064549427)

## Impossible de se connecter √† LLM

[Probl√®me GitHub](https://github.com/All-Hands-AI/OpenHands/issues/1208)

### Sympt√¥mes

```python
  File "/app/.venv/lib/python3.12/site-packages/openai/_exceptions.py", line 81, in __init__
    super().__init__(message, response.request, body=body)
                              ^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'request'
```

### D√©tails

[Probl√®mes GitHub](https://github.com/All-Hands-AI/OpenHands/issues?q=is%3Aissue+is%3Aopen+404)

Cela se produit g√©n√©ralement avec les configurations de LLM *locales*, lorsque OpenHands ne parvient pas √† se connecter au serveur LLM.
Consultez notre guide pour [LLMs locaux](llms/local-llms) pour plus d'informations.

### Solutions de contournement

* V√©rifiez votre `base_url` dans votre config.toml (si elle existe) sous la section "llm"
* V√©rifiez que ollama (ou tout autre LLM que vous utilisez) fonctionne correctement
* Assurez-vous d'utiliser `--add-host host.docker.internal:host-gateway` lorsque vous utilisez Docker

## `404 Ressource non trouv√©e`

### Sympt√¥mes

```python
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/openai.py", line 414, in completion
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/openai.py", line 373, in completion
    response = openai_client.chat.completions.create(**data, timeout=timeout)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py", line 277, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py", line 579, in create
    return self._post(
           ^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1232, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 921, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1012, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Code d'erreur : 404 - {'error': {'code': '404', 'message': 'Ressource non trouv√©e'}}
```

### D√©tails

Cela se produit lorsque LiteLLM (notre biblioth√®que pour se connecter √† diff√©rents fournisseurs de LLM) ne parvient pas √† trouver
le point de terminaison API avec lequel vous essayez de vous connecter. Cela arrive le plus souvent aux utilisateurs de Azure ou ollama.

### Solutions de contournement

* V√©rifiez que vous avez correctement d√©fini `LLM_BASE_URL`
* V√©rifiez que le mod√®le est correctement d√©fini, en fonction des [docs de LiteLLM](https://docs.litellm.ai/docs/providers)
  * Si vous √™tes en cours d'ex√©cution dans l'interface utilisateur, assurez-vous de d√©finir le `model` dans le modal des param√®tres
  * Si vous √™tes en cours d'ex√©cution sans interface (via main.py), assurez-vous de d√©finir `LLM_MODEL` dans votre env/config
* Assurez-vous de suivre les instructions sp√©ciales de votre fournisseur de LLM
  * [ollama](/fr/modules/usage/llms/local-llms)
  * [Azure](/fr/modules/usage/llms/azure-llms)
  * [Google](/fr/modules/usage/llms/google-llms)
* Assurez-vous que votre cl√© API est correcte
* Voyez si vous pouvez vous connecter au LLM en utilisant `curl`
* Essayez de [vous connecter via LiteLLM directement](https://github.com/BerriAI/litellm) pour tester votre configuration

## `make build` bloqu√© sur les installations de packages

### Sympt√¥mes

Installation de package bloqu√©e sur `En attente...` sans aucun message d'erreur :

```bash
Op√©rations de package : 286 installations, 0 mises √† jour, 0 suppressions

  - Installation de certifi (2024.2.2) : En attente...
  - Installation de h11 (0.14.0) : En attente...
  - Installation de idna (3.7) : En attente...
  - Installation de sniffio (1.3.1) : En attente...
  - Installation de typing-extensions (4.11.0) : En attente...
```

### D√©tails

Dans de rares cas, `make build` peut sembler bloqu√© sur les installations de packages
sans aucun message d'erreur.

### Solutions de contournement

* Le gestionnaire de packages Poetry peut manquer d'un param√®tre de configuration concernant
l'emplacement o√π doivent √™tre recherch√©es les informations d'identification (keyring).

### Solution de contournement

Tout d'abord, v√©rifiez avec `env` si une valeur pour `PYTHON_KEYRING_BACKEND` existe.
Sinon, ex√©cutez la commande ci-dessous pour la d√©finir √† une valeur connue et r√©essayez la construction :

```bash
export PYTHON_KEYRING_BACKEND=keyring.backends.null.Keyring
```

## Les sessions ne sont pas restaur√©es

### Sympt√¥mes

OpenHands demande g√©n√©ralement s'il faut reprendre ou commencer une nouvelle session lors de l'ouverture de l'interface utilisateur.
Mais cliquer sur "Reprendre" d√©marre toujours une toute nouvelle discussion.

### D√©tails

Avec une installation standard √† ce jour, les donn√©es de session sont stock√©es en m√©moire.
Actuellement, si le service OpenHands est red√©marr√©, les sessions pr√©c√©dentes deviennent
invalides (un nouveau secret est g√©n√©r√©) et donc non r√©cup√©rables.

### Solutions de contournement

* Modifiez la configuration pour rendre les sessions persistantes en √©ditant le fichier `config.toml`
(dans le dossier racine d'OpenHands) en sp√©cifiant un `file_store` et un
`file_store_path` absolu :

```toml
file_store="local"
file_store_path="/absolute/path/to/openhands/cache/directory"
```

* Ajoutez un secret jwt fixe dans votre .bashrc, comme ci-dessous, afin que les id de session pr√©c√©dents
restent accept√©s.

```bash
EXPORT JWT_SECRET=A_CONST_VALUE
```
