# ü§ñ Backends de LLM

:::note
Esta se√ß√£o √© para usu√°rios que desejam conectar o OpenHands a diferentes LLMs.
:::

O OpenHands pode se conectar a qualquer LLM suportado pelo LiteLLM. No entanto, requer um modelo poderoso para funcionar.

## Recomenda√ß√µes de Modelos

Com base em nossas avalia√ß√µes de modelos de linguagem para tarefas de codifica√ß√£o (usando o conjunto de dados SWE-bench), podemos fornecer algumas
recomenda√ß√µes para sele√ß√£o de modelos. Nossos resultados de benchmarking mais recentes podem ser encontrados nesta [planilha](https://docs.google.com/spreadsheets/d/1wOUdFCMyY6Nt0AIqF705KN4JKOWgeI4wUGUP60krXXs/edit?gid=0).

Com base nessas descobertas e feedback da comunidade, os seguintes modelos foram verificados e funcionam razoavelmente bem com o OpenHands:

- [anthropic/claude-sonnet-4-20250514](https://www.anthropic.com/api) (recomendado)
- [gemini/gemini-2.5-pro](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/)
- [deepseek/deepseek-chat](https://api-docs.deepseek.com/)
- [openai/o3-mini](https://openai.com/index/openai-o3-mini/)
- [openai/o3](https://openai.com/index/introducing-o3-and-o4-mini/)
- [openai/o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)
- [all-hands/openhands-lm-32b-v0.1](https://www.all-hands.dev/blog/introducing-openhands-lm-32b----a-strong-open-coding-agent-model) -- dispon√≠vel atrav√©s do [OpenRouter](https://openrouter.ai/all-hands/openhands-lm-32b-v0.1)


:::warning
O OpenHands enviar√° muitos prompts ao LLM que voc√™ configurar. A maioria desses LLMs custa dinheiro, ent√£o certifique-se de definir limites de gastos e monitorar o uso.
:::

Se voc√™ executou com sucesso o OpenHands com LLMs espec√≠ficos que n√£o est√£o na lista, adicione-os √† lista verificada. Tamb√©m incentivamos que voc√™ abra um PR para compartilhar seu processo de configura√ß√£o e ajudar outros que usam o mesmo provedor e LLM!

Para uma lista completa dos provedores e modelos dispon√≠veis, consulte a
[documenta√ß√£o do litellm](https://docs.litellm.ai/docs/providers).

:::note
A maioria dos modelos locais e de c√≥digo aberto atuais n√£o s√£o t√£o poderosos. Ao usar esses modelos, voc√™ pode observar longos
tempos de espera entre mensagens, respostas ruins ou erros sobre JSON malformado. O OpenHands s√≥ pode ser t√£o poderoso quanto os
modelos que o impulsionam. No entanto, se voc√™ encontrar modelos que funcionem, adicione-os √† lista verificada acima.
:::

## Configura√ß√£o de LLM

O seguinte pode ser configurado na interface do OpenHands atrav√©s das Configura√ß√µes:

- `Provedor LLM`
- `Modelo LLM`
- `Chave API`
- `URL Base` (atrav√©s das configura√ß√µes `Avan√ßadas`)

Existem algumas configura√ß√µes que podem ser necess√°rias para alguns LLMs/provedores que n√£o podem ser definidas atrav√©s da interface. Em vez disso, estas
podem ser definidas atrav√©s de vari√°veis de ambiente passadas para o comando docker run ao iniciar o aplicativo
usando `-e`:

- `LLM_API_VERSION`
- `LLM_EMBEDDING_MODEL`
- `LLM_EMBEDDING_DEPLOYMENT_NAME`
- `LLM_DROP_PARAMS`
- `LLM_DISABLE_VISION`
- `LLM_CACHING_PROMPT`

Temos alguns guias para executar o OpenHands com provedores de modelos espec√≠ficos:

- [Azure](llms/azure-llms)
- [Google](llms/google-llms)
- [Groq](llms/groq)
- [LLMs Locais com SGLang ou vLLM](llms/../local-llms.md)
- [LiteLLM Proxy](llms/litellm-proxy)
- [OpenAI](llms/openai-llms)
- [OpenRouter](llms/openrouter)

### Novas tentativas de API e limites de taxa

Provedores de LLM geralmente t√™m limites de taxa, √†s vezes muito baixos, e podem exigir novas tentativas. O OpenHands automaticamente
tentar√° novamente as solicita√ß√µes se receber um Erro de Limite de Taxa (c√≥digo de erro 429).

Voc√™ pode personalizar essas op√ß√µes conforme necess√°rio para o provedor que est√° usando. Verifique a documenta√ß√£o deles e defina as
seguintes vari√°veis de ambiente para controlar o n√∫mero de tentativas e o tempo entre elas:

- `LLM_NUM_RETRIES` (Padr√£o de 4 vezes)
- `LLM_RETRY_MIN_WAIT` (Padr√£o de 5 segundos)
- `LLM_RETRY_MAX_WAIT` (Padr√£o de 30 segundos)
- `LLM_RETRY_MULTIPLIER` (Padr√£o de 2)

Se voc√™ estiver executando o OpenHands no modo de desenvolvimento, tamb√©m pode definir essas op√ß√µes no arquivo `config.toml`:

```toml
[llm]
num_retries = 4
retry_min_wait = 5
retry_max_wait = 30
retry_multiplier = 2
```
