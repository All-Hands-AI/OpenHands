---
title: Cerebras
description: OpenHands uses LiteLLM to make calls to chat models on Cerebras. You can find their documentation on using Cerebras as a provider [here](https://docs.litellm.ai/docs/providers/cerebras).
---

## Configuration

When running OpenHands, you'll need to set the following in the OpenHands UI through the Settings under the `LLM` tab:
- `LLM Provider` to `Cerebras`
- `LLM Model` to the model you will be using. [Visit here to see the list of models that Cerebras hosts](https://cloud.cerebras.ai/). If the model is not in the list, enable `Advanced` options, and enter it in `Custom Model` (e.g. `cerebras/<model-name>`).
- `API Key` to your Cerebras API key. To find or create your Cerebras API Key, visit [Cerebras Cloud](https://cloud.cerebras.ai/) and sign up for an account.

## Pricing

Cerebras offers three pricing tiers:

### Exploration
Pay-as-you-go for prototyping and small-scale applications:
- No minimum commitment
- Instant access to models
- Community support via Discord
- Available through [Hugging Face](https://huggingface.co/cerebras) and [OpenRouter](https://openrouter.ai/provider/cerebras)

### Growth
Monthly subscriptions for production workloads:
- Higher rate limits (300+ RPM)
- Higher request priority
- Early access to new models and features
- Prioritized support via Slack

### Enterprise
Custom solutions for large-scale deployments:
- Highest rate limits
- Lowest latency with dedicated queue priority
- Extended context length support
- Dedicated deployment options
- Model fine-tuning and training services
- Dedicated support team

For current pricing details, visit the [Cerebras pricing page](https://www.cerebras.ai/pricing) or [contact sales](https://www.cerebras.ai/build-with-us) for Enterprise pricing.