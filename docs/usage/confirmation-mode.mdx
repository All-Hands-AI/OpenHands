# Confirmation Mode and Security Analyzers

OpenHands provides a security framework to help protect users from potentially risky actions through **Confirmation Mode** and **Security Analyzers**. This system analyzes agent actions and prompts users for confirmation when high-risk operations are detected.

## Overview

The security system consists of two main components:

1. **Confirmation Mode**: When enabled, the agent will pause and ask for user confirmation before executing actions that are flagged as high-risk by the security analyzer.

2. **Security Analyzers**: These are modules that evaluate the risk level of agent actions and determine whether user confirmation is required.

## Configuration

You can configure the security system in the **LLM Settings** tab:

- **Enable Confirmation Mode**: Toggle this to enable/disable the confirmation system
- **Security Analyzer**: Choose which analyzer to use for risk assessment

## Security Analyzers

OpenHands includes multiple analyzers. Review their exact behavior in the source code:

- LLM Risk Analyzer: Respects the security_risk provided on actions. Code: https://github.com/All-Hands-AI/OpenHands/blob/main/openhands/security/llm/analyzer.py
- Invariant Analyzer: Builds a trace of events and evaluates it against an Invariant policy to determine risk. Code: https://github.com/All-Hands-AI/OpenHands/blob/main/openhands/security/invariant/analyzer.py
- Analyzer registry (options exposed to the UI): https://github.com/All-Hands-AI/OpenHands/blob/main/openhands/security/options.py

### Invariant Analyzer (overview)

- Collects conversation events and parses them into a trace, then checks the trace against an Invariant policy to classify risk (low, medium, high).
- Manages an Invariant server container automatically if one is not already running (image: ghcr.io/invariantlabs-ai/server:openhands).
- Exposes endpoints for policy and settings, and exporting the current trace (see handle_api_request in the analyzer file).
- Supports optional browsing-alignment and harmful-content checks when configured programmatically.

## How It Works

1. **Action Analysis**: When the agent wants to perform an action, the selected security analyzer evaluates its risk level.

2. **Risk Assessment**: The analyzer returns one of three risk levels:
   - **LOW**: Action proceeds without confirmation
   - **MEDIUM**: Action proceeds without confirmation (may be configurable in future)
   - **HIGH**: Action is paused, and user confirmation is requested

3. **User Confirmation**: For high-risk actions, a confirmation dialog appears with:
   - Description of the action
   - Risk assessment explanation
   - Options to approve, deny, or modify the action

4. **Action Execution**: Based on user response:
   - **Approve**: Action proceeds as planned
   - **Deny**: Action is cancelled
   - **Modify**: User can edit the action before execution


## Best Practices

### For Most Users
- Use the **LLM Analyzer** (default) for intelligent risk assessment
- Enable **Confirmation Mode** when working with sensitive data or systems
- Review confirmation prompts carefully before approving actions

### For Security-Conscious Users
- Consider using **None** analyzer for maximum control in high-security environments
- Regularly review and understand the actions being performed
- Keep confirmation mode enabled at all times

### For Power Users
- Customize security settings based on your specific use case
- Monitor agent behavior and adjust settings as needed
- Consider using "None" analyzer for maximum control in critical environments

## Troubleshooting

### Too Many Confirmations
If you're getting too many confirmation prompts:
- Switch from "None" to "LLM Analyzer" for more intelligent filtering
- Consider disabling confirmation mode for routine tasks
- Review your security analyzer settings

### Missing Risk Detection
If risky actions aren't being caught:
- Ensure confirmation mode is enabled
- Switch to "None" analyzer for maximum coverage
- Check that your security analyzer is properly configured

### Performance Issues
If you experience slow response times:
- Check your LLM configuration and response times (LLM analyzer uses the same LLM as the agent)
- Consider switching to "None" analyzer if you prefer immediate confirmations without analysis
- Ensure your LLM provider has good response times

## Security Considerations

- **Trust but Verify**: Even with security analyzers, always review agent actions carefully
- **Context Matters**: Security analyzers may not understand your specific environment or constraints
- **Regular Updates**: Keep OpenHands updated to benefit from improved security analysis
- **Backup Strategy**: Always maintain backups when allowing agents to modify important data

## Future Enhancements

The security system is continuously being improved. Future versions may include:
- Customizable risk thresholds
- User-defined security rules
- Integration with external security tools
- Enhanced risk assessment algorithms
- Audit logging and reporting features

For the latest updates and features, check the OpenHands documentation and release notes.