version: '3.8'

services:
  openhands:
    build:
      context: ./
      dockerfile: ./containers/app/Dockerfile
    image: openhands:latest
    container_name: openhands-ollama
    environment:
      # Runtime configuration
      - SANDBOX_RUNTIME_CONTAINER_IMAGE=${SANDBOX_RUNTIME_CONTAINER_IMAGE:-docker.all-hands.dev/all-hands-ai/runtime:0.49-nikolaik}
      - WORKSPACE_MOUNT_PATH=${WORKSPACE_BASE:-$PWD/workspace}

      # Ollama configuration
      - LLM_MODEL=ollama/deepseek-coder-v2:latest
      - LLM_BASE_URL=http://host.docker.internal:11434
      - LLM_OLLAMA_BASE_URL=http://host.docker.internal:11434

      # OpenHands configuration
      - OPENHANDS_CONFIG_FILE=/app/config.toml
      - RUNTIME=docker
      - DEBUG=true

      # Disable external services
      - DISABLE_TELEMETRY=true

    ports:
      - "3000:3000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ~/.openhands:/.openhands
      - ${WORKSPACE_BASE:-$PWD/workspace}:/opt/workspace_base
      - ./config.toml:/app/config.toml:ro
    pull_policy: build
    stdin_open: true
    tty: true
    restart: unless-stopped

    # Health check to ensure the service is running
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/options/models"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
